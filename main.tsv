#separator:tab
#html:true
#notetype:Basic
#deck:main
Bundle, Grothendieck fibration	Grothendieck fibration is a functor p: E → B that has a lifting property for morphisms, analogous to lifting paths in a topological space. The category E is the total category, and B is the base category.
Bundle, fiber of fibration	object B in the base category B, the fiber is the subcategory of the total category E whose objects map to B and whose morphisms map to the identity morphism of B.
Bundle, local triviality	categorical bundle is locally trivial if it can be "trivialized" by pulling back to a simpler form over a "local" part of the base category. This corresponds to the existence of cartesian sections.
Bundle, section of fibration	section of a fibration p: E → B is a functor s: B → E such that p∘s is the identity functor on B. Sections are the categorical analogs of continuous sections of a vector bundle.
Bundle, classifying space	base category of a categorical bundle can be seen as a kind of classifying space for the fibers. This generalizes the concept of a classifying space for a topological group.
Bundle, category of elements	category of elements is a category whose objects are pairs (B,X), where B is an object of B and X is an object of the category F(B). This construction provides a standard way to form a fibration.
Bundle, right fibration	functor is a right-fibration if it has a specific lifting property for all morphisms in the base category, in a "right" direction. This is a common type of categorical bundle.
Bundle, modules	module M over a ring R can be seen as a categorical bundle over the base category with a single object and one morphism, which represents the ring. The "fibers" are the elements of the module.
Bundle, sheaves	sheaf of modules on a topological space or a scheme can be interpreted as a categorical bundle over the category of open sets of the space. The fibers are the stalks of the sheaf.
Bundle, fibre functor	functor that sends a vector bundle to the module of its sections can be seen as a fiber functor that generalizes the idea of a fiber in a topological bundle.
Torsor, formalisation of twisting of Mobius strip	A vector bundle can be seen as a deformation of a trivial bundle. The transition functions measure how the bundle is "twisted" away from being a product. Imagine a perfectly straight, product bundle. A non-trivial vector bundle is like a Möbius strip, which is locally trivial but globally twisted. The torsor perspective formalizes this twisting.
Torsor, classifying space as a master list changing objects into morphisms from a master list	For a topological group G, there is a classifying space BG whose points classify the isomorphism classes of G-torsors. A classifying space is a "master list" of all possible torsors for a given group. Any torsor can be represented by a continuous map from the base space into the classifying space.
Torsor, phase space of the dynamical system, ergodicity	A torsor can be used to model a dynamical system where a group acts freely and transitively on a phase space. The phase space of the dynamical system is a torsor. Any state can be reached from any other state by a unique group action. The system is therefore perfectly predictable and has no "fixed points" or "cycles."
Group cohomology, extension of group G by abelian group A as torsor classified by second cohomology of group	second cohomology group H2(G,A) classifies extensions of a group G by an abelian group A. Visual Intuition: A group extension is a "twisted" product of two groups. The torsor structure captures the "twisting" of these extensions.
Principal bundle, naked torsor while vector bundle is dressed torsor	A vector bundle is associated with a principal bundle, which is a torsor for the general linear group. A vector bundle is constructed by "inflating" a principal bundle by the standard representation of GLn​. A principal bundle is a "naked" torsor, a space that is just a collection of group-acting points. The vector bundle is a "dressed" torsor, where each point is given a vector space, which is then acted upon by the group.
Principal bundle, definition via schemes of right actions of group schemes of principal Z_2 bundle over circle as double cover of the circle, Z_2 acts  as right action by swapping two points, either get Mobius strip or trivial bundle	principal bundle is a scheme P with a right action of a group scheme G such that the map P × G to P × P given by (p,g) to (p,pg) is an isomorphism. The projection map P to P/G is a faithfully flat morphism of schemes. Consider a principal Z2​-bundle over the circle S1, which is a double cover of the circle. The total space is a circle, and the fibers are two points. The group Z2​ acts on the fibers by swapping the two points. This can be visualized as a Möbius strip, which is locally two sheets but globally has a twist.
Principal bundle, torsor as principal bundle with a single fibre, a vector in a vector space is a torsor since it can reach any point with the vector as a group action, similar to torsors with dates	A torsor is a principal bundle with a single fiber. The group acts freely and transitively on the fiber. Consider a vector space V. Any two vectors in V are related by a unique vector addition, so V is a torsor for the vector space itself. The visual intuition is that a torsor is a space with a perfect, uniform tiling by a group, so that from any point, you can reach any other point with a unique group action. Similarly, you can reach any date using the group action of a day.
Principal bundle, covering map exp(2 pi i x) spiral staircase where G = Z and total space R as principal Z-bundle over S1, acting by translation, orbits are the fibres	principal bundle in topology is a fiber bundle P over a base space X with a topological group G acting on the fibers from the right, and the action is free and transitive. Consider the group G=Z acting on the real line R. The map e2πix from R to the circle S1 is a covering map. The total space R is a principal Z-bundle over S1. The group Z acts by translation, x to x + n, and the orbits are the fibers. This can be visualized as a spiral staircase over a circle.
Principal bundles, set of isomorphism classes is classified by Galois cohomology group measuring obstructions to principal bundle from being a trivial bundle, example of H1(Z, Z/2)	set of isomorphism classes of principal G-bundles over a scheme X is classified by the Galois cohomology group H1(X,G). The first cohomology group measures the obstructions to a principal bundle being a trivial bundle. For the ring Z, the obstructions for a principal Z2​-bundle are the number of ways it can be a non-trivial double cover.
Principal bundle, homogenous space as principal bundle with a single fibre (torsor) example orthogonal O(3) acts as torsor over sphere S^2, sphere S^2 is homogenous space for orthogonal group O(3)	homogeneous space is a manifold on which a Lie group acts transitively. A homogeneous space is a principal bundle with a single fibre. It's a space that is perfectly tiled by a group action. For example, the sphere S2 is a homogeneous space for the orthogonal group O(3)
Moduli space, set of all lines passing through origin parameterised by angle, projective line is moduli space for set of lines through origin	A moduli space is a geometric space whose points represent isomorphism classes of some type of geometric object, such as elliptic curves, vector bundles, or Riemann surfaces. Visual Intuition: Consider the set of all lines in the plane passing through the origin. This set can be parameterized by the angle a line makes with the x-axis, but with a slight subtlety: angles θ and θ+π correspond to the same line. The space of all such lines is the projective line, P1. This is a moduli space for the set of lines through the origin.
Moduli space, moduli space of representations for commuting matrices using ring of two variables	The moduli space of representations of the ring of polynomials in two variables, k[x,y], is a space whose points correspond to pairs of commuting matrices. The geometry of this space is a reflection of the algebraic properties of the ring.
Principal bundle, visualisation of a frame of a vector space, with the general linear group acting on the frame of reference via the change of basis. Frame bundles lack a canonical choice of identity	Consider the Cartesian product X * G, for a space X and group G. Typical example is vector space X, and vector bundle E, with a group GLn(X), then F(E) is a frame bundle which is an example of a principal bundle. The general linear group acting on the frame of reference via the change of basis. Frame bundles lack a canonical choice of identity.
p-group fixed point theorem, definition	Let G be a finite p-group acting on a finite set X, Let X^G denote the subset of X consisting of elements fixed by G then |X^G| is congruent to |X| mod p, in particular if p does not divide |X|, then G has a fixed point.
p-group fixed point theorem, combinatorial counting argument	Partition a set to orbits, then use the fact that size of any non-fixed orbit must be a multiple of p, to get a congruence relation.
p-group fixed point theorem, links divisibility to the order of the group	links divisibility of the group's order to the divisibility of orbit sizes, prove existence results by showing a certain count is divisible by p.
p-group fixed point theorem, formalises group action inertia	Grop action may have some fixed points.
p-group fixed point theorem, special case of orbit stabiliser theorem	Leverages specific properties of p-groups to simplify the more complex orbit sum formula
p-group fixed point theorem, existence proofs	Define a clever group action, use the theorem to prove the existence of properties like nontrivial centers
p-group fixed point theorem, nilpotency marker	nilpotency shows how close a group is to being abelian
p-group fixed point theorem, partitioning strategy	Highlights how you can partition a set to disjoint orbits
p-group fixed point theorem, nontrivial center or X^p is nilpotent	Consider group X^p \ {0}, cardinality p^n - 1, for X, not divisible by p, nontrivial center of fixed point exists.
Ultrafilter, formalisation of almost all i in I without using measure theory	picture the natural numbers on the horizontal axis. A nonprincipal ultrafilter is like choosing one single “direction to infinity”: for every subset A of N, the ultrafilter “declares” either A is large (contains that direction) or its complement is large. Concretely, imagine a point p in the (compact, totally disconnected) space βN (the Stone-Cech compactification); that point determines which infinite subsets are neighborhoods of p — exactly the ultrafilter. Ultrafilters formalize the notion “for almost all i in I” without measure. They let you pass from sequences (a_i), for i in I​ to a single limit object (an ultralimit) by declaring equality/limit along U. This is the basis of ultraproducts, nonstandard analysis, asymptotic cones, and many combinatorial-algebraic transfer arguments.
Ultrafilter, binary choice on every question about subsets	an ultrafilter is a collection of subsets of a set I i.e. ultrafilter U is in the power set of I satisfying (1) filter, closed under supersets and finite intersections; (2) for all subsets A of I, either A is in the ultrafilter U or the complement of A is in the ultrafilter of U. This ties into the ultrafilter answering questions about subsets.
Nonprincipal ultrafilter, a direction to infinity that doesn't pass through any specific point, useful for defining the Stone Cech compactification later	an ultrafilter U on an infinite set I is a nonprincipal ultrafilter if it contains all cofinite subsets of the infinite set I (it contains no finite sets), formally, nonprincipal means it is not generated by a single element in the ultrafilter.
U-large set, set that contains chosen direction to infinity	a U-large set is a subset A of I  such that A is an element of the ultrafilter.
Stone-Cech compactification, hold all possible directions to infinity as points	unique largest compactification of a discrete space. The points of beta I are precisely the ultrafilters of I.
Ultraproduct, declaring sequences equivalent if they agree on U-large set of indices, payoff is the hyperreals in characteristing first order logic and Los's theorem	the quotient of the Cartesian product under the equivalence relation that sequences are equivalent if and only if the indices are equal, and this set of indices is U-large.
Ultraproducts, collapses the enormous product into one object by “forgetting” small (non-U-large) disagreements	Consider the cases of A_i= F_p,i (finite fields) or A_i = Z/nZ. Visualize each coordinate as a column of colored tiles (one tile per i). An element of the product is a whole tiling (a choice of tile per column). The ultrafilter draws a bold “selection lens”: two tilings are identified if they match on a U-large set of columns. The ultraproduct. Given structures (Ai)_i in I of the same signature and an ultrafilter U on I, the ultraproduct prod(i) to UAi is the quotient of the direct product prod_i (A_i) by the equivalence relation: (a_i)  equivalent to (b_i) if i is in ultrafilter I and a_i = b_i. Interpret operations coordinatewise on equivalence classes.
Ultralimit, conclusion or value we get by agreeing that "almost all" of the sequence terms belong to any neighborhood of this value	An point x in a topological space is the ultralimit if for every neighbourhood V of point x, the index set of a_i in sequence (a_i), i is in infinite set I, a_i is in neighbourhood V is U-large.
Mathematical structure (L-structure, model), type of mathematical object	M_i is a single mathematical structure indexed by element i, some examples include a list of all groups, all fields or all first model sharing a language L
Los's theorem, ultraproduct inherits all first-order logical properties that hold true for "almost all" (U-large) of the original structures	A first order sentence phi_i is true in the ultraproduct if and only if the set of indices the set of indices for i in infinite set I such that premises of a mathematical structure M_i leads to semantic consequence (entailment of) first order sentence phi_i.
Double turnstile, semantic consequence (entailment)	you simply need truths to be preserved in all models, there are no remarks on provability.
Single turnstile, syntatic consequence (provability)	this is simple implication, if P is true, and P implies Q is true, then (the word then is where it is used) Q is true.
Ultrafilters, identification combinatorial objects with topological dynamics	Picture N embedded as isolated points in a huge compact, totally disconnected space βN. Nonprincipal ultrafilters are limit points of sequences of natural numbers (but not in the metric sense). Concretely: pick subsets like the even numbers, primes, arithmetic progressions; a point p in βN is a consistent “choice” deciding for each such subset whether the neighborhood contains p. Geometrically, those decision-patterns create clopen neighborhoods that refine to the single point p. The Stone space of the Boolean algebra P(I) has points that are ultrafilters on I; for I being the natural numbers this is the Stone-Cech compactification βN. A subset A in N corresponds to the clopen set {p in βN such that A is in p}.  This identifies combinatorial objects with topological dynamics: idempotent ultrafilters in βN produce recurrence theorems (Hindman, van der Waerden). It is also the right setting for translating combinatorial statements into topological fixed-point-like theorems. This identifies combinatorial objects with topological dynamics: idempotent ultrafilters in βN produce recurrence theorems (Hindman, van der Waerden).
Spectrum, a linear transformation T in R^2 represented by a matrix. The eigenvectors are the directions (vectors) that get stretched or shrunk but not rotated. The spectrum is the set of these stretching factors of the eigenvalues. For a more general operator on an infinite-dimensional space, an element in the spectrum isn't necessarily an eigenvalue. It's a "near eigenvalue." It's a value lambda where (A−lambda I) isn't invertible. Imagine the operator A as a machine that transforms vectors. If you feed in a vector v and get a result close to lambda v for some λ, then λ is in the spectrum. The visual intuition is that the spectrum is the set of all possible "scaling factors" of the operator. For example, for the differentiation operator D=d/dx on the space of polynomials, its spectrum is the entire complex plane, because for any lambda, the equation D f− lambda f=g can be difficult to solve	The spectrum of a bounded linear operator A on a Banach space X is the set of all lambda in C for which the operator (A − lambda I)does not have a bounded inverse. This is a generalization of the concept of eigenvalues for finite-dimensional matrices.
Spectrum, electron in an atom. Its energy is an observable. The possible energy levels are discrete and quantized, forming a discrete spectrum. This is like a ladder of allowed energy levels. If you measure the electron's energy, the result must be one of the values on the ladder. For a free particle, its momentum can take on any real value, so its spectrum is continuous, like a ramp. The spectrum is a visual representation of the allowed states or outcomes of a physical system. For the position operator X on L^2(R), the spectrum is the real line R	The spectrum of a self-adjoint operator in a Hilbert space represents the set of all possible outcomes of a physical measurement. An observable, like position or momentum, is represented by such an operator, and its spectrum gives the possible values that can be measured.
Spectrum, a musical chord. It's a combination of different pure tones, each with a specific frequency and amplitude. The spectrum of the sound wave is a plot showing which frequencies are present and how strong they are. For a pure sine wave, the spectrum is a single point at its frequency. For a more complex function, the spectrum is a collection of points or a continuous curve. The Fourier transform takes a function in the time domain and gives us its spectrum in the frequency domain. For example, the function f(t)=cos(2 pi t)+cos(4 pi t) has a spectrum with two peaks, one at frequency 1 Hz and another at frequency 2 Hz	The spectrum of a function is the set of frequencies present in its Fourier transform. It tells us which sinusoidal components make up the function.
Spectrum a network of interconnected nodes, like social media users or a transportation system. The eigenvalues of the graph's adjacency matrix reveal how well-connected the graph is. A graph with a larger number of distinct eigenvalues is often more complex. For example, the spectrum of a complete graph _​ is (n−1,−1,...,−1), while the spectrum of a path graph is quite different. The spectrum can be seen as a fingerprint of the graph's structure	the spectrum of a graph is the multiset of eigenvalues of its adjacency matrix, or a related matrix like the graph Laplacian. These eigenvalues provide information about the graph's structure, like its connectivity and diameter.
Spectrum, vibrating drumhead. Its vibration pattern is a solution to the wave equation. The possible modes of vibration are the eigenfunctions of the Laplacian operator on the drumhead. Each mode vibrates at a specific frequency, which is an eigenvalue. By representing any vibration as a sum of these modes, we can solve the wave equation. The spectrum of the Laplacian gives us the fundamental building blocks for all possible solutions	The spectrum of an operator is used to solve partial differential equations (PDEs) using spectral methods. We represent the solution to a PDE as a sum of basis functions, which are the eigenfunctions of a related operator.
Spectrum, gives us information about the manifold's geometry, like its volume and curvature. For example, the eigenvalues of the Laplacian on a circle are related to integers, while the eigenvalues on a square are related to the sum of squares of integers. The spectrum is a way to "fingerprint" the geometry of a space	The spectrum of a compact Riemannian manifold is the set of eigenvalues of its Laplace-Beltrami operator. These eigenvalues are a geometric invariant of the manifold.
Spectrum, particle jumping between a finite number of states. The transition probabilities are given by a matrix. The eigenvalues of this matrix tell us how quickly the particle's long-term distribution of states stabilizes. If the second largest eigenvalue is close to 1, it takes a long time to converge. If it's close to 0, it converges quickly. The spectrum is a measure of the "mixing time" of the chain	The spectrum of the transition matrix of a finite state Markov chain provides information about its long-term behavior. The largest eigenvalue is always 1, and its corresponding eigenvector gives the stationary distribution. The other eigenvalues govern the rate of convergence to this distribution.
Spectrum, a compact operator "squishes" infinite-dimensional spaces down to something resembling a finite-dimensional space. The spectrum of such an operator reflects this. The eigenvalues are countable and tend to zero. This is like a sequence of "stretching factors" that get smaller and smaller. An example is the integral operator T f(x)= integral of 0 to 1​K(x,y)f(y)dy for a continuous kernel K. Its spectrum is a sequence of eigenvalues converging to zero	The spectrum of a compact operator is a discrete set of eigenvalues with accumulation point at zero. This means that a compact operator's spectrum behaves more like a finite-dimensional operator's spectrum than a general infinite-dimensional operator's.
Spectrum, residual spectrum is a set of "bottlenecks." For a value λ in the residual spectrum, the operator (A−e I) maps different vectors to different vectors (it's injective), but it doesn't "fill up" the entire space, not even densely. There are "holes" in the image. An example is the right-shift operator on the Hilbert space l^2. The set of points inside the unit disk is its residual spectrum	The residual spectrum of an operator A is the set of e for which (A−e I) is injective but its range is not dense in the space.
Spectrum, convex body gives information about its curvature. For a sphere, the curvature is constant, and its spectrum is a simple set of eigenvalues. For a non-spherical convex body, the curvature varies, and the spectrum provides a detailed description of these variations. The spectrum can be a "curvature fingerprint" of the convex body	The spectrum of a convex body can be defined via the eigenvalues of its Hessian of the support function.
Spectrum, family of vibrating strings whose tension is slowly changed. As the tension changes, the frequencies of vibration change. Spectral flow counts how many times a frequency becomes zero. This concept is used in index theory to count the number of zero modes of a family of operators. It's like tracking the number of times a moving target crosses a fixed line	Spectral flow is a concept from global analysis that measures how the spectrum of a family of self-adjoint operators changes as a parameter is varied. It counts the number of eigenvalues that cross zero.
Spectrum, stationary stochastic process is one whose statistical properties do not change over time. Its spectral measure tells us how much "energy" or "variance" is contained in different frequency bands. A process with a spectral measure concentrated at low frequencies is slow-moving, while a process with a spectral measure at high frequencies is fast-moving. The spectral measure is like a power spectrum of the random process	The spectral measure of a stationary stochastic process is a measure on the frequency domain that describes the distribution of power across different frequencies.
Functional, Riesz representation theorem states that any positive linear functional on the space of continuous functions with compact support can be represented as integration with respect to a measure. . For example, the functional L(f)= integral from 0 to 1 of ​f(x) dx for a function f on [0,1] is a functional. The geometric intuition is that the functional "weighs" the input function according to some underlying measure. The value of the functional is the "total weight" or "volume" of the function, where the weights are given by the measure	A functional is a linear map from a space of functions (e.g., continuous functions with compact support) to the real numbers. It can be seen as a generalized integral.
Functional, support functional of a convex body K in Rn. For a direction vector u, the support functional h_K​(u) gives the maximum distance of any point in K from the origin in the direction of u. Geometrically, this is the signed distance from the origin to the support hyperplane perpendicular to u. For a square in R^2, its support functional takes on values representing the distance from the origin to each of its four sides, depending on the direction u	A functional in convex geometry is a mapping from a convex set (e.g., a shape without indentations) to a real number, often representing a geometric property.
Functional, expected value functional E[X]= integral over outcome space Omega ​X(omega) dP(omega) for a random variable X. This functional maps a random variable to its expected value, which is a single number. Geometrically, for a random variable with a probability density function (PDF), the expected value is the "center of mass" or balance point of the PDF. For a normally distributed random variable, the functional maps the bell curve to its mean	A functional is a map from a space of random variables (or random processes) to the real numbers. It can be thought of as a statistic or a quantity derived from a random process.
Functional, Dirac delta functional δa​ is the quintessential example. It maps a test function ϕ(x) to its value at a single point a, i.e., δ_a​(ϕ) = ϕ(a). So the Dirac delta function turns a map into a point, like a reverse functor of points, as a map of a map. Geometrically, the Dirac delta can be visualized as an infinitely tall, infinitely thin spike at a point a, with a total "area" of 1. While not a true function, it acts as a functional that "picks out" the value of a function at a specific point	A functional, also known as a distribution or a generalized function, is a continuous linear map from a space of "test functions" (e.g., infinitely differentiable functions with compact support) to the real numbers.
Functional, wave front set of a distribution, which is a key concept in microlocal analysis. A functional can be used to "test" for the regularity of a distribution at a specific point and in a specific direction. For example, a functional could be designed to "look for" singularities (discontinuities or non-differentiable points) in a distribution along a certain ray in phase space. The functional maps the distribution to a value that is nonzero if there's a singularity and zero otherwise	A functional in microlocal analysis maps a distribution to a value, and its properties are studied locally in both position and frequency (or direction).
Functional, action functional in classical mechanics is a prime example. It maps a path (a function of time) to a single number, the action, which is the integral of the Lagrangian along the path. The principle of least action states that the actual path taken by a physical system is the one that minimizes or extremizes this functional. Geometrically, this means finding the "smoothest" or "most efficient" path through the function space of possible trajectories, which corresponds to a geodesic-like curve on the infinite-dimensional manifold	A functional is a mapping from an infinite-dimensional manifold (e.g., a space of functions) to the real numbers. It's often used to define a notion of energy, action, or other physical quantity.
Functional, Fourier transform can be seen as a family of functionals. For a function f(x), the Fourier transform f^​(ξ) is a new function, where each value f^​(ξ) is a functional that maps f to a complex number. . The functional is Fξ​(f) is an integral over the reals of ​f(x) exp(−2πixξ) dx. Geometrically, each such functional "projects" the function f onto a specific frequency basis function exp(−2πixξ). The value of the functional tells us how much of that specific frequency is present in the original function	A functional is a continuous linear map from a space of functions (e.g., L^p spaces) to the complex numbers. They are used to study the "frequency content" of a function.
Functional, Dirichlet energy functional is a classic example. For a function u defined on a domain Ω, the functional is E(u) = 0.5 integral over domain ​| Laplacian u |^2 dx. This looks like energy. Solutions to the Laplace equation are those that minimize this functional. Geometrically, a solution to the Laplace equation (a harmonic function) can be visualized as a surface that is "as flat as possible" while satisfying certain boundary conditions, like a soap film stretched over a wire frame. The functional gives a numerical value for the total "tension" or "energy" of the surface	A functional is a map from a space of functions to the real numbers, often representing the "energy" of a solution to a PDE.
Functional, Hahn-Banach theorem states that any continuous linear functional defined on a subspace can be extended to the entire space without increasing its norm. Geometrically, in a normed vector space, a continuous linear functional can be visualized as a hyperplane. The theorem states that if you have a convex set and a point not in the set, you can always find a hyperplane that separates them. The functional itself defines the hyperplane, and its value tells you which side of the plane a vector is on	A functional is a linear map from a vector space to its underlying field (usually the real or complex numbers). It is a fundamental building block for defining topology and geometry in infinite-dimensional spaces.
Functional, vector space of column vectors R3. A linear functional can be represented as a row vector. For example, the functional f(v1​,v2​,v3​) = (1,2,3) * (v1​,v2​,v3​)^T = v1​ + 2v2​ + 3v3​. Geometrically, this functional maps every vector to a single number. The set of all vectors that map to the same value (e.g., f(v)=c) forms a hyperplane in R3. The family of all such hyperplanes for different values of c are parallel to each other	A functional is a linear transformation from a vector space V to its field of scalars F. It's simply a linear map f: V to F.
Functional, Brachistochrone problem is a historical example. The functional to be minimized is the time it takes for a bead to slide down a curve from point A to point B under gravity. The functional is T(y) = from A to B, sqrt(1 + y'^2)/ \sqrt(2gy(x)), where y(x) is the curve. The space of "all possible curves" is an infinite-dimensional space. The functional maps each curve to a single number (time). The solution is the specific curve (a cycloid) that has the minimum value	A functional is a map from a space of functions to a real number, whose value is usually an integral involving the function and its derivatives. The goal is to find the function that minimizes or maximizes the functional.
Functional, Shannon's entropy functional is a fundamental concept. For a discrete probability distribution P=(p1​,p2​,…,pn​), the functional is H(P) = negative expectation of log p_i in base 2 over n . The value of the functional is the average number of bits needed to encode a message from a source with this distribution. Geometrically, for a simple coin flip with probability p of heads, the entropy functional can be visualized as a parabola, with its maximum at p=0.5 (maximum uncertainty)	A functional is a map from a space of probability distributions to a real number, representing a measure of information or uncertainty.
Functional, finite element method, a complex problem (like solving a PDE) is converted into finding a function that minimizes a functional. . The functional is defined on a space of functions (often piecewise polynomials). We approximate the function space with a finite-dimensional one (defined by the mesh) and find the vector of coefficients that minimizes the functional. The geometric intuition is that we are finding the "best-fit" function from a simpler, finite-dimensional space that is "closest" to the true solution in terms of minimizing the functional	A functional is a map from a function space to the real numbers, used to approximate solutions to problems by minimizing or maximizing the functional.
Functional, free energy functional in statistical mechanics. It is a functional of a probability distribution or density. . The equilibrium state of a system is the distribution that minimizes this functional. Geometrically, we can imagine the space of all possible configurations of a system as a high-dimensional landscape. The functional maps each configuration to a single value (the free energy). The system "rolls downhill" to the configuration that minimizes this functional, representing the most stable or probable state	A functional can represent a thermodynamic potential that depends on a probability distribution or configuration of a system.
Functional, thee cost functional for an optimal control problem. For a system with dynamics defined by a differential equation, the functional maps a control policy (a function of time) to a single number representing the total cost. . The goal is to find the control policy (e.g., how the rocket's thrust changes over time) that minimizes this functional. Geometrically, we are searching through the infinite-dimensional space of all possible control functions to find the single function that leads to the "cheapest" or "most efficient" trajectory	A functional can be used to model and optimize systems, where the "cost" or "objective" depends on a function.
Functional, Energy Functional of a signal x(t) is given by E integral over the real line as support of x(t)^2. This functional maps the signal to a single number representing its total energy. Geometrically, if you think of the signal as a curve in an infinite-dimensional space, the functional is a projection onto a single dimension that measures its "size" or "magnitude" in a specific sense. For a simple sine wave, this functional gives a finite value representing its power	A functional is a map from a signal (a function of time) to a single number, used to analyze or extract features from the signal.
Functional, Lyapunov functional in dynamical systems is a key example. For a given dynamical system, a Lyapunov functional is a scalar function (functional) of the state (a function of time) that decreases along the trajectories of the system. . The existence of a Lyapunov functional guarantees the stability of a fixed point. Geometrically, the level sets of the functional form nested "bowls" or "basins" around the fixed point. The system's trajectory moves from a higher level set to a lower one, eventually "falling" into the minimum of the bowl at the stable fixed point	A functional is a non-linear map from a function space to the real numbers. They are used to study the existence and properties of solutions to nonlinear equations.
Functional, dual space of a normed vector space V, denoted V∗, is the space of all continuous linear functionals on V. . For a Hilbert space, the Riesz representation theorem states that every continuous linear functional f can be represented as an inner product with a unique vector y, i.e., f(x)=⟨x,y⟩. The geometric intuition is that every "direction" in the vector space corresponds to a unique vector in the dual space. The functional "projects" any vector x onto this direction, giving a single number that tells you "how much" of x is in the direction of y	A functional is a linear map from a normed vector space to its scalar field, specifically a continuous linear functional.
Operator, linear transformation in R2 represented by a matrix. The matrix rotates, stretches, or shears a vector to a new location. An operator is a similar rule, but for functions. For example, the operator that takes a function and squares it is a nonlinear operator	An operator is a mapping between vector spaces.
Operator, subgradient operator maps a point on a convex function to a set of subgradients. For a convex function that is not everywhere differentiable, like f(x)= |x|, the subgradient at x=0 is the entire interval [−1,1]. The operator is the rule that maps x=0 to this set. The proximal map is an operator that projects a point onto a convex set	An operator can represent a proximal map or a subgradient operator.
Operator, eigenvalues of a matrix reveal its fundamental properties (e.g., whether it rotates or stretches), the spectrum of an operator reveals its underlying structure. The eigenfunctions of the Laplacian on a drumhead reveal its fundamental modes of vibration. An operator is the physical object (the drumhead) and its spectrum is the set of all its possible vibrations	"An operator is a machine whose internal workings are revealed by its spectrum."
Operator, conditional expectation operator takes a random variable and projects it onto a subspace of random variables that are measurable with respect to a sub-sigma-algebra. Imagine a random variable on a plane and a line on that plane. The operator takes the random variable and projects its distribution onto the line	An operator can represent the conditional expectation.
Operator, derivative operator D is an operator that takes a function and gives its derivative. When acting on a distribution, it gives another distribution. For example, the derivative of the Heaviside step function is the Dirac delta function. The operator is a rule that transforms one generalized function into another	An operator is a continuous linear map from a space of test functions to a space of distributions, or vice versa.
Operator, curved space, like a sphere, the concept of a derivative is generalized. The Laplacian operator on a sphere takes a function on the sphere and gives another function. The operator is the rule for "differentiation" on a curved space	An operator is a differential operator on a manifold, like the Laplacian on a sphere.
Operator, stochastic process like a random walk, the generator is an operator that describes the "infinitesimal" change in the process. For a simple random walk, the generator is the discrete Laplacian. It's the "engine" that produces the random motion	An operator is the generator of a stochastic process.
Operator, representation of a group is a way of "realizing" the group's abstract elements as operators on a vector space. For example, the group of rotations in 3D can be represented by operators (matrices) that act on vectors in R3. The operator is the "physical manifestation" of an abstract group element	An operator is a representation of a group.
Derived category, conceptual compression	Compresses it the notion of a category down to a homological core.
Derived category, quasi-isomorphisms	Quasi-isomorphisms are treated as if they are isomorphisms
Derived category, homotopy category	category, objects are chain complexes, morphisms are chain homotopies of chain maps
Derived category, localization of category of complexes	Localisation of category of complexes with respect to the class of all quasi-isomorphisms, formalises inverting a set of maps
Derived category, formal inverses	To build it, add a formal inverse for every quasi-isomorphism
Derived category, fuzzy equality	Two complexes are equal if they are related by a chain of quasi-isomorphisms, a kind of fuzzy equality
Derived category, reducing dimension	Takes a complex, sequence of object, and squash it down, retaining only the homology groups
Derived category, cohomology as invariant	Since quasi-isomorphisms are inverted in defining an invariant category, therefore cohomology does not change.
Derived category, triangulated category	Shift functors and distinguished triangles can be used to define a derived category
Derived category, generalises non-abelian categories	Do homological algebra without commutative and additive structure of abelian category
Derived category, algebraic topology	Algebra of homotopy category of topological space
Derived category, new invariants	Define derived functors that are more robust
Derived category, universal property	Unique category that inverts quasi-isomorphisms most efficiently
Derived category, formalises equivalence of non-strictly isomorphic objects	Equivalence of two non-strictly isomorphic objects
Group, set of symmetries	Set of symmetries of an object, composition of symmetries is group operation
Group, action	set of transformations that act on sets
Group, axioms	unital, associative invertible closed magma
Group, puzzle	elements are moves that change the state of a puzzle (Rubik's cube)
Group, non-empty set with single operation	Defined by one operation, unlike rings or fields
Group, cancellation laws	If ab = ac, b = c, solvability of equations
Group, monoid with inverses	They are monoids with inverses.
Group, group object	A group is a group object in the category of Sets.
Group, category of one object	Category with one object, group elements are morphisms, group operation is categorical composition
Group, holes are abelian since there is no natural order	homology groups are abelian is that the "holes" don't have a natural order or direction. A loop can be traversed clockwise or counterclockwise, and the sum of two loops is the same regardless of which one you add first.
Coset, set of elements	multiply subgroup by fixed element
Coset, equivalence class related to which element in subgroup	TFAE: xy^-1 in subgroup, x related to y. Form equivalence class
Coset, partition	Partition group into disjoint subsets, each subset same size as subgroup H
Coset, translate of subgroup	translate subgroup H by element g in G, represented by gH (left coset), or Hg (right coset). This is somewhat related to the Haar measure.
Coset, orbit of element	Coset is orbit of element g under action of subgroup H by right multiplication, gives coset gH (left coset)
Coset, homogenous space	Coset space is a homogenous space, G acts transitively on the set of cosets.
Coset, fibre of homomorphism	if the homomorphism from a group G to the quotient G/H is a canonical projection homomorphism, then the coset is fibre of this map, specifically the preimage of a single element in the quotient group.
Coset, compositional	object, elements of a group, structure is action of subgroup
Coset, state space	Coset partition the state space, each coset is equivalent states, state is group element
Coset, components of quotient group	Individual elements of a quotient group. Quotient group operation is defined on the cosets
Coset, invariant subset	Invariant subset under left or right multiplication of elements of subgroup H.
Group action, as a map	a group action is a map from the cartesian product of group G and set X such that for any group homomorphism, we have p(g_1(g_2, x))) is equal to p(g_1g_2, x).
Group action, permutations of a set	group action is equivalent to a group homomorphism from G to the group of all permutations of X. This means that every element of the group corresponds to a way of rearranging the elements of the set.
Group action, visual analogy	group action is an ontological model for the symmetries of an object. The group elements correspond to the transformations (like rotations or reflections) that leave the object unchanged. For example, the dihedral group D4​ acts on a square by its symmetries.
Group action, orbit of any element	orbit of an element x in X is the set of all elements that can be reached from x by the action of the group. The orbits partition the set X.
Group action, stabiliser of an element	stabilizer of an element x in X is the subgroup of G that leaves x unchanged. Example, imagine rotating about a fixed point of a tetrahedron, it is a cyclic subgroup of order 3.
Group action, transitive action using the visualisation with one orbit	transitive action has only one orbit. This means every element can be transformed into every other element.
Group action, action on a vector space	group can act on a vector space by a group homomorphism from G to the group of invertible linear transformations on the space. This is a representation of the group.
Group action, action on a chain complex	group can act on a chain complex of modules. This means each module in the complex is a module with a group action, and the differentials are equivariant, i.e., they respect the group action.
Group action, group cohomology	studies the group action on a module by constructing a complex whose homology groups are the cohomology groups of the group.
Group actions, action on a sheaf	a group can act on a sheaf of modules. This means the group acts on the open sets and on the sections of the sheaf in a compatible way.
Group action, act on a spectrum	group can act on a spectrum by a map from the classifying space of the group to the space of automorphisms of the spectrum.
Quotient scheme, sphere intuition quotient means you identify all points that can be glued into each other by any action	A quotient scheme is a scheme that is the result of a geometric quotient of another scheme by a group action. Imagine a sphere. A group of rotations acts on it. The quotient is a space where all the points that can be rotated into each other are considered the same point. Like collapsing plane to line is not a group action, collapsing points into each other for a sphere is a group action.
Quotient, orbit space, visual intuition of swapping pairs of points	quotient can be viewed as an orbit space, where you take a space and a group action on it and identify all the points that are in the same orbit. Visual intuition: Take a set of points on a line. A group action swaps pairs of points. The quotient space has only half the number of points, as the pairs are identified. This is like pairing up pairs of points this is the orbit space.
Quotient, spectrum of a quotient ring, carving out smaller variety or quotient by ideal means collapsing plane as variety into line as a subvariety	ring R and an ideal I, the spectrum of the quotient ring, Spec(R/I), is the closed subscheme of Spec(R) defined by the ideal I. Visual intuition: Spec(R) is an algebraic variety. Taking the quotient by an ideal is like "carving out" a smaller subvariety within it, for example, a line within a plane.
Quotient, identification done up to homotopy for a group action	homotopical quotient of a topological space by a group action is a quotient where the identification is done up to homotopy. This is often an object called a classifying space.
Induced representation in group theory, visual intuition as smaller tiled floors to larger tiled floors	Let H be a subgroup of a group G, and V be a representation of H. The induced representation IndHG​(V) is a way to "lift" the representation of the smaller group H to a representation of the larger group G. Imagine group G as a large tiled floor and the subgroup H as a single tile. The representation of H is a pattern on that tile. To get the induced representation, you replicate this patterned tile and its transformations across the entire floor, taking into account how the larger group G acts on the collection of tiles.
Group scheme, multiplying two points to get a third point	group scheme is a scheme that is also a group, with the group operations (multiplication, inverse, and identity) being morphisms of schemes. This unifies the notions of algebraic groups and groups of rational points on a variety. Imagine a smooth curve or surface (a scheme) that has a group structure on its points. This means you can "multiply" two points on the curve to get a third point, and this multiplication is compatible with the geometric structure. A complex elliptic curve is a perfect example, where the group law is defined by the intersection of lines with the curve.
Group scheme, points functor	group scheme can be defined by its functor of points. This means specifying how the group acts on every possible test space (scheme). Think of a group scheme not as a single object, but as a recipe for making a group for any geometric space you input. For example, the recipe for the multiplicative group scheme Gm​ gives you the group of units of a ring when you input a ring spectrum.
Group scheme, Hopf algebra as coordinate ring and dual of a group scheme	coordinate ring of an affine group scheme is a Hopf algebra, which is a commutative ring with additional maps (co-multiplication, co-unit, and antipode) that capture the group operations. The Hopf algebra is the algebraic dual of the group scheme. The group structure (multiplication) on the geometric space is encoded by the co-multiplication on the ring of functions, which "splits" a function into a tensor product of two functions. Recall that you imagined a group scheme as a smooth curve.
Group scheme, Lie algebra of a group scheme, imagine the Lie algebra as tangent space of identity	For a smooth group scheme, the tangent space at the identity element has a natural Lie algebra structure. Visual Intuition: The Lie algebra is the infinitesimal approximation of the group scheme near the identity. Imagine the group as a smooth manifold. The Lie algebra is the tangent space at the identity, and the Lie bracket is derived from the commutator of nearby group elements.
Group scheme, additive group scheme as line, multiplicative group scheme as line with origin removed	These are the simplest examples. The additive group scheme Ga​ has points with the group law of addition, while the multiplicative group scheme Gm​ has points with the group law of multiplication. Visual Intuition: The additive group scheme is a line where points are added like vectors. The multiplicative group scheme is the line with the origin removed, where points are multiplied.
Group scheme, example of group object in category of schemes	group scheme is an example of a group object in the category of schemes. This is a general categorical definition.
Group scheme, loop space of topological groups consists of all closed paths starting and ending at a given point	The loop space of a topological group is a group, and its properties are closely related to the original group. Visual Intuition: The loop space consists of all closed paths starting and ending at a given point. The group law on the loop space is given by "concatenating" paths.
Group scheme, elliptic curves of a finite field as scattered collection of points on a grid along an elliptic curve	elliptic curve over a finite field is a scattered collection of points on a grid, but these points form a group. The group law (addition of points) is still defined geometrically, but it is now on a finite set of points.
Group scheme, group scheme acting on another scheme generating trajectories and orbits	group scheme is a group of transformations acting on a geometric space. This action generates trajectories and orbits, which can be used to study the long-term behavior of the system.
Coset space, partitioning off group by subgroup Consider the group of integers Z under addition and the subgroup of even integers 2Z. The cosets are 0+2Z={…,−2,0,2,…} (the even integers) and 1+2Z={…,−1,1,3,…} (the odd integers). Geometrically, imagine the integers on a number line. You're "identifying" or "collapsing" all even integers to a single point and all odd integers to another point, resulting in a discrete space of two points	A coset space, also known as a quotient space, is the set of all left (or right) cosets of a subgroup H in a group G, denoted by G/H. Each coset is of the form gH={gh∣h∈H}, for some g∈G. It's a way of partitioning the group into disjoint subsets of equal size. Visual Intuition: Consider the group of integers Z under addition and the subgroup of even integers 2Z. The cosets are 0+2Z={…,−2,0,2,…} (the even integers) and 1+2Z={…,−1,1,3,…} (the odd integers). The coset space Z/2Z consists of just these two cosets. Geometrically, imagine the integers on a number line. You're "identifying" or "collapsing" all even integers to a single point and all odd integers to another point, resulting in a discrete space of two points.
Coset space, group of rotations of a circle, which is the group of complex numbers of magnitude 1, denoted U(1) or S1. Let the subgroup H be the n-th roots of unity. The coset space S1/H is also a circle. Visually, we are "collapsing" the circle by a factor of n. For example, if n=2, we identify points separated by π radians. The resulting space is still a circle, but "wrapped" around itself	In topology, a coset space is a special type of quotient space, where a topological group G is "quotiented" by a subgroup H. This results in a new topological space where the points are the cosets. Visual Intuition: Consider the group of rotations of a circle, which is the group of complex numbers of magnitude 1, denoted U(1) or S1. Let the subgroup H be the n-th roots of unity. The coset space S1/H is also a circle. . Visually, we are "collapsing" the circle by a factor of n. For example, if n=2, we identify points separated by π radians. The resulting space is still a circle, but "wrapped" around itself.
Coset space, example of general linear group GLn(C) acting on the set of all 1-dimensional subspaces of C^n	An algebraic coset space is a homogeneous space G/H where G is an algebraic group and H is a closed algebraic subgroup. It's a variety on which G acts transitively. Visual Intuition: Consider the general linear group GLn(C) acting on the set of all 1-dimensional subspaces of Cn. The stabilizer of a 1-dimensional subspace is a subgroup of GLn(C). The coset space is the set of all such 1-dimensional subspaces, which is the projective space P_{n-1}(C). This space is geometrically a collection of lines through the origin, and the coset space structure provides a powerful way to study its geometry.
Coset space, G be the group of rotations in 3D space, SO(3), and let H be the subgroup of rotations about the z-axis, SO(2). The coset space SO(3)/SO(2) can be identified with the 2-sphere S^2	in the theory of Lie groups, a coset space G/H is a homogeneous manifold, where G is a Lie group and H is a closed Lie subgroup. Visual Intuition: Let G be the group of rotations in 3D space, SO(3), and let H be the subgroup of rotations about the z-axis, SO(2). The coset space SO(3)/SO(2) can be identified with the 2-sphere S2. Each coset corresponds to a unique direction in 3D space, which is specified by a point on the sphere. We are "quotienting out" the rotations about a fixed axis to get the space of all possible axis directions.
Coset space, reduced phase space, example of a central force problem, like a planet orbiting a star. The system has rotational symmetry. The group of rotations is SO(2)	In dynamical systems, a coset space can represent a reduced phase space when a system has a symmetry group. The coset space is the space of all possible states of the system after accounting for this symmetry. Visual Intuition: Consider a central force problem, like a planet orbiting a star. The system has rotational symmetry. The group of rotations is SO(2). The coset space can be thought of as the orbit of the planet in the plane, where the angular position is "quotiented out" and all that matters is the distance from the star. The coset space is effectively the radial line segment of possible distances.
Coset space, module over a quotient ring, group algebra Fp​[G] for a finite group G and a prime p dividing the order of G. The Jacobson radical J of this ring is a subgroup. The quotient ring Fp​[G]/J is a direct sum of matrix rings	In modular representation theory, a coset space can be seen as a module over a quotient ring R/I. The elements of this module are the cosets of the ideal I. Visual Intuition: Consider the group algebra Fp​[G] for a finite group G and a prime pdividing the order of G. The Jacobson radical J of this ring is a subgroup. The quotient ring Fp​[G]/J is a direct sum of matrix rings. A module over this quotient ring is a direct sum of simple modules. Geometrically, we are "collapsing" the "non-semisimple" part of the group algebra (the Jacobson radical) to obtain a "clean" or "semisimple" structure, which is a sum of simple objects.
Coset space, cosets in the ideal class group represents a "class" of ideals that are "equivalent" up to multiplication by a principal ideal	In arithmetic number theory, the ideal class group of a number field is a coset space. It is the quotient of the group of fractional ideals by the subgroup of principal fractional ideals. Visual Intuition: The ideal class group measures the failure of unique factorization in a number ring. Each coset in the ideal class group represents a "class" of ideals that are "equivalent" up to multiplication by a principal ideal. We are "collapsing" all ideals that are "close" to being principal into a single point, to see the "non-principal" structure of the ring.
Coset space, vector bundle example and moduli spaces	A moduli space of vector bundles on a variety is a coset space. It is a space whose points parameterize the isomorphism classes of vector bundles. Visual Intuition: A vector bundle is a collection of vector spaces "glued" together over a variety. The group of automorphisms of the vector bundle acts on it. The coset space is the collection of all vector bundles that are "equivalent" up to isomorphism. This space "organizes" all possible ways to assign vector spaces to points on the variety.
Cosets, Cayley graph of the group of integers Z with generator 1	Consider the Cayley graph of the group of integers Z with generator 1. It's an infinite line of vertices. Let the subgroup be 2Z. The coset space is a graph with two vertices (corresponding to even and odd numbers) and an edge connecting them. This is a way of "folding" the infinite line into a finite graph, where the vertices are the cosets.
Coset space, upper half-plane is the complex plane with positive imaginary part. The group SL2​(Z) acts on it by fractional linear transformations	In the theory of modular forms, a coset space is a quotient of the upper half-plane H by a discrete subgroup of SL2​(Z). Visual Intuition: The upper half-plane is the complex plane with positive imaginary part. The group SL2​(Z) acts on it by fractional linear transformations. The coset space H/SL2​(Z) is a fundamental domain for this action, which is a hyperbolic surface with cusps. . We are "collapsing" the infinite repetitions of the fundamental domain to a single object, which has a finite "volume" in hyperbolic geometry.
Coset space, symplectic quotient is a new phase space where the conserved quantity is fixed	Imagine a physical system with a conserved quantity, like angular momentum. The phase space has a symmetry group (like rotations). The symplectic quotient is a new phase space where the conserved quantity is fixed. We are "collapsing" the original phase space along the orbits of the symmetry group to get a "reduced" phase space.
Coset space, ring can be thought of as a "space" of operators. A maximal left ideal is a "maximal" collection of operators that "annihilate" some vector. The simple module is the vector space itself, after "quotienting out" by the action of these operators	In non-commutative ring theory, a simple module is a coset space of a ring R by a maximal left ideal I. It is a module that has no proper submodules. Visual Intuition: A ring can be thought of as a "space" of operators. A maximal left ideal is a "maximal" collection of operators that "annihilate" some vector. The simple module is the vector space itself, after "quotienting out" by the action of these operators. It's the "smallest" non-trivial space on which the ring can act.
Coset space, deforming a sphere into a space X while keeping its "equator" inside a subspace A. The coset space is a way of "collapsing" all these deformations that are equivalent up to the "equator's" path inside A. This reveals a finer structure of the "holes" of the pair (X,A)	In homotopy theory, the relative homotopy group πn​(X,A,x0​) is a coset space. It is the quotient of the group of based maps of an n-sphere into X that map the "equator" to A, by the subgroup of those that map the "equator" to a specific point x0​. Visual Intuition: We are studying how to "deform" a sphere into a space X while keeping its "equator" inside a subspace A. The coset space is a way of "collapsing" all these deformations that are equivalent up to the "equator's" path inside A. This reveals a finer structure of the "holes" of the pair (X,A).
Surjective, the ring of 2x2 matrices with real entries, M2​(R), and the ring of real numbers, R. We can define a surjective ring homomorphism p	M2​(R) to R by taking the determinant of the matrix. This map is surjective because every real number x can be represented as the determinant of a matrix, for example, the diagonal matrix with entries x and 1. The "projection" from the space of matrices to the real line covers the entire line: a ring homomorphism ϕ: R to S is surjective if for every element s∈S, there exists an element r in R such that p(r)=s. This is equivalent to saying that the kernel of the homomorphism is a two-sided ideal I of R and S is isomorphic to the quotient ring R/I.
Surjective, a linear map from R3 to R2 that projects a point (x,y,z) to (x,y). This is a surjective map. The domain is a 3D space, and the codomain is a 2D plane. The projection "covers" the entire plane. Any point in the plane has an entire vertical line of points in 3D space that map to it	A linear transformation T:V→W between two vector spaces is surjective if its range is the entire vector space W. This implies that the dimension of the range is equal to the dimension of the codomain, dim(Im(T))=dim(W).
Surjective, the dihedral group D4​ (symmetries of a square) and the cyclic group Z2​ (rotations by 0 and 180 degrees). We can define a surjective homomorphism p	D_4​ to Z/2​ that sends all rotations to 0 and all reflections to 1. This means that we can "project" the complex symmetries of the square onto the simpler two states of Z/2​. Every element in Z/2​ has a corresponding set of elements in D4​ that maps to it, so the projection "covers" all of Z2​: a group homomorphism p: G to H is surjective if the image of p is the entire group H. This means that for every element h in H, there exists at least one element g∈G such that p(g)=h.
Surjective, a system on a circle given by rotation and a system on a line segment given by a map that wraps the segment around. A factor map is a projection from the circle to the line segment that preserves the dynamics. The surjectivity means that every point on the line segment is the image of some point on the circle. The factor map "covers" the entire codomain	A factor map between two dynamical systems (X,f) and (Y,g) is a surjective map p: X to Y such that p(f(x)) = g(p(x)). A factor map is a way to "project" a complex dynamical system onto a simpler one.
Surjective, a map from a module M to a module N. An epimorphism is a map that cannot be "factored out" by any other map. If we have two different maps from N to another module, and they agree on the image of our map, they must be the same map. This is a powerful property that tells us that our map "covers" the entire codomain	a category, a morphism f:A→B is an epimorphism if for any two morphisms g, h: B to C, the equality g * f = h * f for the same section the retractions are equal implies g = h. In the category of modules, epimorphisms are precisely the surjective homomorphisms.
Injectives, group Z (integers with addition) and the group Z2 (pairs of integers with component-wise addition). The homomorphism p	Z to Z/2 given by p(n)=(n,0) is injective. This map "embeds" the integers as a straight line in the integer lattice. No two different integers map to the same point, so the line doesn't "fold back" on itself. The kernel is only the integer 0,which maps to the origin (0,0):  An injective group homomorphism p : G to H is a homomorphism that is injective as a function. This is equivalent to stating that the kernel of the homomorphism is the trivial subgroup, ker(p) = {e}, where e is the identity element of G.
Injective, a linear map from a line in R3 to a plane in R3 that just maps the line into the plane. For example, the map from the x-axis to the xy-plane given by T(x,0,0)=(x,0,0). This map is injective because the null space is just the origin. No two points on the line are "crushed" into the same point on the plane	injective linear transformation T:V to W between two vector spaces is a linear map that is injective as a function. This is equivalent to stating that the null space of the transformation is the zero vector, null(T) = {0_V​}. This implies that the dimension of the domain is less than or equal to the dimension of the codomain, dim(V) less than or equal to dim(W).
Injective, the ring of integers Z and the ring of rational numbers Q. The inclusion map p	Z to Q is an injective ring homomorphism. This is a very natural embedding where we can visualize the integers as a discrete subset of the rational numbers. The homomorphism doesn't "collapse" any of the integers together:  injective ring homomorphism ϕ: R to S is a ring homomorphism that is injective as a function. This is equivalent to stating that the kernel of the homomorphism is the zero ideal, ker(p)={0}. In this case, R is isomorphic to the subring Im(p) of S, so we say that R is "embedded" into S.
Injective, the map from the affine line A1 to the affine plane A2 given by (x) to (x, x^2). This map "embeds" the line as a parabola in the plane. The map is injective, and the image is a subscheme of the plane. This is a geometric embedding, where no two points on the line are "crushed" together in the plane	A morphism of schemes f:X→Y is an embedding if it is a closed immersion and its image is an affine subscheme. For affine schemes, this corresponds to a surjective ring homomorphism. A more general notion of injectivity is a monomorphism in the category of schemes, where a morphism f: X to Y is a monomorphism if for any two morphisms g,h: Z to X, f * g = f * h implies g = h the sections are the same.
Injectives, inclusion of the boundary of a disk, S1, into the disk itself, D2, is a cofibration. If we have a map from the disk to some other space, and we have a homotopy on the boundary of the disk, we can extend this homotopy to the whole disk. The map is "injective" in a way that allows us to extend maps and homotopies. The boundary is "stuck" in the disk in a well-behaved way	A cofibration is a continuous map i:A to X that satisfies the homotopy extension property. This is a "dual" concept to a fibration and is a form of injective map in the category of topological spaces. A cofibration is an embedding that allows for "pushing homotopies forward."
Injective, the map on the real line given by f(x)=2x. This is an injective map. The distance between two points doubles at each step. This "stretching" is a sign of injectivity in a dynamical system	for a a dynamical system, an injective map has a positive Lyapunov exponent, which measures the rate of divergence of nearby trajectories. This is a way of saying that the map is "stretching" the space.
Injective, a division ring is a ring where every non-zero element has a multiplicative inverse. A simple module over a division ring is just a vector space. A vector space is an injective module. The vector space is so "flexible" that any map from a subspace can be extended	In the category of modules over a non-commutative ring, a simple module is a module that has no non-trivial submodules. A simple module is an injective object in a very special case, when the ring is a division ring.
Injective, a finite field as a set of points. The Frobenius map "shuffles" the points. The injectivity means that no two points are mapped to the same point. This is a very strong property that is a key to understanding the structure of finite fields	The Frobenius map on a finite field F_q​ is the map that sends an element x to x^p. This map is a permutation, so it is both injective and surjective. The injectivity is a key property of the Frobenius map.
Injective, a circle drawn on the surface of a sphere. This is an injective map. We can extend a homotopy from the circle to the whole sphere. The circle is "stuck" in the sphere in a well-behaved way	The inclusion of a lower-dimensional sphere into a higher-dimensional sphere is an injective map that is a cofibration. For example, the inclusion of S1 into S2 is an injective map that satisfies the homotopy extension property.
Wreath product, imagine H as a group of "movers" and G as a group of "actions". The base group G^H is a collection of ∣H∣ copies of G, one for each element of H. The group H then acts by permuting these copies. For instance, the symmetric group S4​ can be viewed as the wreath product S2​ wreath S2​, which permutes pairs of points. The group S2​ acts on {1,2}, and a second S2​ acts on the set of two such pairs, {{1,2},{3,4}}	The wreath product G wreath H of groups G and H is a semidirect product GH semidirect H, where GH is the group of functions from H to G, and H acts on GH by shifting the functions.
Wreath product, necklace with |X| beads, where each bead can be in one of |G| states. The group H permutes the beads, and the group G can change the state of each bead. For example, if G = Z_2​ and H = Z)n​, a wreath product element can rotate the beads of the necklace and simultaneously flip some of them. This is a common model for studying Rubik's cubes	For a group G and a set X with an action of a group H on X, the wreath product G wreath X​H is the group of permutations of the set G×X. Its elements are pairs (f,h) where f:X to G and h in H.
Wreath product, representations of G wreath H as building blocks. The representations of the base group G^H are tensor products of representations of G. The action of H on G^H permutes these tensor factors. The representation of G wreath H is then built by inducing representations from subgroups, creating a rich and intricate structure of representations	The representation theory of wreath products connects the representations of G wreath H to those of G and H. The irreducible representations of G wreath H can be constructed from the irreducible representations of its base and acting groups.
Wreath product, two stacked layers of symmetries. The lower layer, K/F, has symmetries given by H. The upper layer, L/K, has symmetries given by G. The wreath product captures the combined symmetry of this tower, where the symmetries of the lower layer "permute" the symmetries of the upper layer	The Galois group of a tower of field extensions, say L/K and K/F, can sometimes be expressed as a wreath product. If L/K is a normal extension and its Galois group Gal(L/K) is isomorphic to a group G, and K/F is a normal extension with Galois group Gal(K/F) isomorphic to H, and if the action of Gal(K/F) on the roots of a polynomial is transitive, then the Galois group of L/F is a wreath product of G and H.
Wreath product, system of cellular automata on a circle. The group of global rotations of the circle is H. At each cell, there is a local state that can be changed by a group G. The wreath product G wreath H describes the symmetries of this system, where H shifts the cells and G acts locally on each cell	The wreath product can be used to describe the symmetries of certain dynamical systems. For example, a system with two levels of hierarchy, where a set of local dynamics is governed by a global dynamics.
Wreath product, n identical particles moving in a space. The group Sn​ permutes the particles. At each particle, there can be a local symmetry group G describing an internal state (e.g., spin). The wreath product combines the global permutation symmetry with the local internal symmetries	The configuration space of a collection of points in a topological space can be modeled using the wreath product. For instance, the space of n points in a space X with some local dynamics can be described as a wreath product of the group of local symmetries with the symmetric group S_n​.
Wreath product, homology groups as measuring the "holes" in a topological space. The wreath product is a way to "build" a new space by taking copies of one space and permuting them. The homology of this new space is then determined by the homology of the components. For example, the homology of a space that is a wreath product of two spheres, S2 wreath S1, would be related to the homology of S2 and S1	The wreath product of groups can be used to construct interesting chain complexes and compute homology. The homology of G wreath H can be related to the homology of G and H using the Künneth formula and spectral sequences.
Wreath product, counting the number of ways to color the vertices of a cube with 2 colors. The group of symmetries of the cube is a wreath product of the rotations of a face with the permutations of the faces. This structure is used to analyze the symmetries and count the number of distinct colorings	In enumerative combinatorics, the wreath product is used to count the number of objects with certain symmetries. For example, the number of colorings of a graph where the colorings are invariant under the action of a group can be found using the orbit-stabilizer theorem and properties of wreath products.
Wreath product, Lie algebras are the "infinitesimal" versions of Lie groups. The wreath product of Lie algebras captures the same hierarchical structure as the wreath product of groups, but at an infinitesimal level. This is useful for studying symmetries of continuous systems	The wreath product of Lie algebras is defined by a semidirect product of Lie algebras. It is a fundamental construction in the study of infinite-dimensional Lie algebras.
Wreath product, group cohomology measures the "extensions" of a group by a module. The wreath product is a way to "stack" extensions on top of each other, creating a complex structure. The spectral sequence is a tool to "unstack" this structure and compute the cohomology	The group cohomology of a wreath product G wreath H can be computed using a spectral sequence that relates it to the cohomology of G and H.
Wreath product, graph as a network of nodes and edges. The wreath product of two graphs, say G1​ and G2​, creates a new graph where each vertex is a "copy" of the graph G2​ at each vertex of G1​. This allows for a hierarchical network structure	The wreath product of graphs is a construction that creates a new graph from two given graphs. The vertices of the new graph are pairs of vertices from the original graphs.
Uncertainty principle, physical space and frequency space are dual	Change in position * Change in momentum >= 1 is a good start, but it only captures a portion of what the principle tells us. Consider for instance the following (deliberately vague) statements, each of which can be viewed (heuristically, at least) as a manifestation of the uncertainty principle
Uncertainty principle, tradeoff between frequency and smoothness	imagine an oscillatory function that is band-limited (restricted to low frequencies) is featureless and smooth at fine scales, but can be oscillatory (i.e. containing plenty of cancellation) at coarse scales. Conversely, a function which is smooth at fine scales will be almost entirely restricted to low frequencies. A function which is restricted to high frequencies is oscillatory at fine scales, but is negligible at coarse scales. Conversely, a function which is oscillatory at fine scales will be almost entirely restricted to high frequencies
Uncertainty principle, filtering for coarse scale behaviour	projecting a function to low frequencies corresponds to averaging out (or spreading out) that function at fine scales, leaving only the coarse scale behaviour.
Uncertainty principle, number of degrees of freedom of a function is bounded by the product of its spatial uncertainty and its frequency uncertainty (or more generally, by the volume of the phase space uncertainty)	In particular, there are not enough degrees of freedom for a non-trivial function to be simulatenously localised to both very fine scales and very low frequencies.
Uncertainty principle, coarse scale (or global) averaged behaviour of a function, one essentially only needs to know the low frequency components of the function (and vice versa)	Fourier decomposition explains this.
Uncertainty principle, fine scale (or local) oscillation of a function, one only needs to know the high frequency components of the function (and vice versa)	Fourier decomposition explains this.
Uncertainty principle, localising a function to a region of physical space will cause its Fourier transform (or inverse Fourier transform) to resemble a plane wave on every dual region of frequency space	Frequency becomes drastically reduced.
Uncertainty principle, the smoother a function is, the more rapidly decreasing its Fourier transform (or inverse Fourier transform) is (and vice versa)	Sharp drop in frequency since no high frequency components.
Uncertainty principle, localisation operations in position approximately commute with localisation operations in frequency so long as the product of the spatial uncertainty and the frequency uncertainty is significantly larger than one	Change in position and change in frequency can be though as some sort of abelian relation.
Uncertainty principle, high frequency (or large scale) limit, position and frequency asymptotically behave like a pair of classical observables, and partial differential equations asymptotically behave like classical ordinary differential equations. At lower frequencies (or finer scales), the former becomes a “quantum mechanical perturbation” of the latter, with the strength of the quantum effects increasing as one moves to increasingly lower frequencies and finer spatial scales	Don't understand this.
Unceratinty principle, phase heuristic, on an interval in the real line, the linear phase x to exp(2 pi i f x) at a given frequency f in R behaves like a constant when exp << 1/R, but oscillates significantly when exp >> 1/R This is visually plausible if one graphs the real and imaginary parts cos(2 pi i f x),  sin(2 pi i f x) For now, we will take this principle as axiomatic, without further justification, and without further elaboration as to what vague terms such as “behaves as if” or << mean	If the phase f(x) of a complex exponential exp(2 pi i f(x))  fluctuates by less than 1 for some x isn a nice domain (convex set), then the phase exp(2 pi i f(x))  behaves as if it was constant on the domain. If the phase f(x) of a complex exponential exp(2 pi i f(x))  fluctuates by more than 1 for some x isn a nice domain (convex set), then the phase exp(2 pi i f(x))  behaves as if it was oscillate on the domain.
Uncertainty principle, a particle confined to a very small box. The wave function describing its position is highly localized. However, to "build" this localized wave function, one needs a superposition of many different momentum wave functions (plane waves with different frequencies). Thus, the particle's momentum is very uncertain. Conversely, a particle with a very well-defined momentum is represented by a long, oscillating wave that stretches across all of space, so its position is completely uncertain. The uncertainty principle is a geometric statement about the wave-particle duality	the more a wave is like a particle (localized), the less it is like a wave (a single frequency):  In quantum mechanics, the Heisenberg uncertainty principle states that the position and momentum of a particle cannot be simultaneously known with perfect precision. Mathematically, the position of a particle is represented by a wave function ψ(x) and its momentum by the Fourier transform ψ^​(p). The principle is expressed as the inequality ΔxΔp≥2ℏ​, where Δx and Δp are the standard deviations of the position and momentum measurements, respectively, and ℏ is the reduced Planck constant.
Uncertainty principle, box function (a function that is 1 on a finite interval and 0 everywhere else). It has compact support, but it's not smooth—it has two sharp corners. Its Fourier transform is a sinc function, which decays like 1/∣ξ∣ but has infinite support. The uncertainty principle is the geometric statement that the "roughness" of the box function is reflected in the slow decay of its Fourier transform. If we were to smooth out the box function, its Fourier transform would decay faster	The uncertainty principle can also be expressed as a trade-off between the smoothness of a function and the decay of its Fourier transform. Specifically, if a function is very smooth (e.g., C∞), its Fourier transform must decay very rapidly. Conversely, if a function's Fourier transform is compactly supported (band-limited), the function itself must be infinitely smooth. This is a powerful duality that connects regularity in one domain to decay in the other.
Uncertainty principle, a phase space diagram, with the horizontal axis representing position and the vertical axis representing frequency. A pure sine wave is a point on the frequency axis, but it's infinitely wide on the position axis. A Dirac delta function is a point on the position axis, but it's infinitely wide on the frequency axis. A wave front set of a general distribution is a cloud of points in this space. The uncertainty principle is the geometric statement that this cloud of points cannot be a single point. If a singularity exists at a point x0​, it must have a range of frequencies (directions) associated with it	Microlocal analysis provides a refined version of the uncertainty principle by analyzing functions and distributions in phase space (position and frequency). The wave front set of a distribution is a subset of phase space that describes the location of its singularities and the directions in which they propagate. The uncertainty principle is the statement that a point in phase space cannot be both in the singular support and have a singular frequency in only a single direction. The singular support must be "smeared out" in both position and frequency.
Uncertainty principle, heat source that is a single point at time t=0. This is a Dirac delta function, which is highly localized in space but has infinite frequency content. As heat diffuses, the temperature distribution becomes a smooth Gaussian, which is spread out in space and has a limited frequency range. The uncertainty principle is the geometric statement that the "localization" of the heat profile decreases over time. The energy is conserved, but it is distributed more widely	In semigroup theory, the uncertainty principle is manifested as the regularizing effect of a semigroup. For example, the heat semigroup exp(tΔ) acts on functions by convolving them with a Gaussian. This process smooths out the function. The uncertainty principle dictates that this smoothing (reducing high-frequency content) comes at the cost of spreading the function out in space.
Uncertainty principle, a function on a line that is a short, finite pulse. Its Fourier transform is a function that is non-zero everywhere. It may decay rapidly, but it never reaches zero. This is a very clean geometric statement. Similarly, a function that is a pure sine wave is localized in frequency but extends infinitely in space. The uncertainty principle is the geometric statement that you can't have a function that's a "short pulse" in both the spatial and frequency domains	One of the most basic forms of the uncertainty principle states that a non-zero function and its Fourier transform cannot both have compact support (i.e., be zero outside a finite region). This is a consequence of the fact that if a function has compact support, its Fourier transform is an entire function (a function that is holomorphic everywhere in the complex plane). An entire function can only be zero at isolated points unless it's the zero function, so it cannot have compact support.
Uncertainty principle, function that is a weak solution to the Laplace equation, Δu=0. We might know that this function is in L2. The regularity theory for the Laplace equation tells us that this weak solution must be infinitely smooth. The uncertainty principle is at work here. The "physics" of the Laplace equation (the fact that a solution must have no local extrema) forces the function to be smooth, and this smoothness is a manifestation of the uncertainty principle	the solution has limited high-frequency content, so it must be "spread out" in a certain sense:  In PDEs, the uncertainty principle is a foundational concept in the study of solution regularity. For example, the solution to an elliptic PDE is often found to be in a certain Sobolev space. The uncertainty principle (in the form of Sobolev embedding theorems) dictates a trade-off: to have a solution with high regularity (which means its Fourier transform decays rapidly), it must be spread out in space. This principle is used in bootstrapping arguments to prove that weak solutions are, in fact, classical smooth solutions.
Uncertainty principle, a probability distribution that is a sharp spike. This means the random variable is highly localized. The characteristic function of this distribution is a flat line, which has infinite bandwidth. This is a geometric statement	a distribution that is a single point in space is maximally "spread out" in the frequency domain:  In probability theory, the uncertainty principle manifests as the trade-off between the variance of a random variable and the "bandwidth" of its characteristic function (the Fourier transform of its probability density function). If a random variable has a small variance, its probability mass is highly concentrated. Its characteristic function, therefore, must have a large bandwidth. This is a fundamental concept in information theory.
Uncertainty principle, set of transformations of a space. If two transformations commute (e.g., rotating a sphere and translating it), you can apply them in any order. If they do not commute (e.g., rotating and dilating), the order matters. The uncertainty principle is the geometric statement that the position and momentum operators do not commute, which means you cannot have a function that is "perfectly well-behaved" under both operations	The uncertainty principle is a statement about the duality between two non-commuting operators, such as position and momentum. The non-commutativity of these operators, [X,P]=0, implies that they do not share a common set of eigenfunctions. This means that a function cannot be an eigenfunction of both operators, which is a mathematical statement of the uncertainty principle.
Uncertainty principle, a function on a line. The number of "bumps" or oscillations you can fit into a given interval is limited. The uncertainty principle is the geometric statement that the number of "degrees of freedom" of a function (the number of independent parameters needed to describe it) is limited. You can't have a function that has a high resolution in both the spatial and frequency domains	The uncertainty principle can be interpreted as a statement about the limited number of degrees of freedom of a function. A function's degrees of freedom are bounded by the product of its spatial uncertainty and its frequency uncertainty. This is a core concept in information theory and signal processing, as it relates to the number of samples required to perfectly reconstruct a signal.
Uncertainty principle, an operator as a "blurring" filter. A function that is a sharp spike (highly localized) is passed through this filter, and the output is a smooth, spread-out function. The uncertainty principle is the geometric statement that the operator cannot make the function both more localized and smoother. The "smoothing" effect of the operator necessarily comes at the cost of "localization."	The uncertainty principle can be seen as a statement about the properties of a compact operator. A compact operator often has a "smoothing" or "regularizing" effect. The uncertainty principle is manifested as the trade-off between the localization of a function and the localization of its image under a compact operator.
Uncertainty principle, a solution to the heat equation. An initial condition that is a sharp spike is a highly localized function. Over time, the solution becomes a smooth Gaussian function that is spread out in space. The uncertainty principle is the geometric statement that the "smoothing" of the function is accompanied by a "spreading." You can't have a solution that is both a localized spike and a smooth function	In the study of PDEs, the uncertainty principle is a foundational concept in the study of a PDE's solution regularity. It dictates a trade-off between the spatial localization of a solution and its smoothness. For example, a solution to a PDE that is highly localized in a small region must have a certain level of "roughness," while a very smooth solution must be "spread out" in space. This principle is a key tool in proving existence and regularity of solutions.
Uncertainty principle, a sphere. The eigenfunctions of the Laplacian on the sphere are the spherical harmonics. The uncertainty principle is the statement that a function on the sphere cannot be both a sharp spike (highly localized) and a single spherical harmonic (a single frequency)	In global analysis, the uncertainty principle can be generalized to manifolds. It states that a function on a manifold cannot be simultaneously localized in position and have a limited range of frequencies (eigenvalues of the Laplacian). This is a deep result that connects the geometry of the manifold to the properties of the functions on it.
Uncertainty principle, smoothness of f in the physical domain corresponds to decay of f in the Fourier domain, and conversely. (More generally, fine scale properties of f tend to manifest themselves as coarse scale properties of f, and conversely.)	
Uncertainty principle, constant coefficient differential operators such as d/dx in the physical domain corresponds to multiplication by polynomials such as 2 pi i f in the Fourier domain, and conversely	
Uncertainty principle, frequency modulation in the physical domain corresponds to translation in the frequency domain, and conversely	
Haar measure, using length invariance under rotations to prove the Plancherel theorem	imagine the group of rotations of a circle, G = S^1. The Haar measure corresponds to the usual arc length measure. If you take a segment of the circle of length a and rotate it by any angle, the new segment will also have length a. The Haar measure is this notion of length that is invariant under all rotations. In the context of the representation theory of a locally compact group G, the Haar measure is a left-invariant measure on G that allows for the definition of the Hilbert space L_2(G). This measure is essential for defining unitary representations and for the Plancherel theorem, which describes the spectral decomposition of the regular representation.
Haar measure, translational (read	group action) invariance: the group of real numbers under addition, G = (R,+). The Haar measure is the standard Lebesgue measure. If you take an interval [a,b] of length b - a and "translate" it by adding a number c, the new interval [a+c,b+c] still has the same length. This translation invariance is the key property of the Haar measure. The Haar measure on a locally compact group G is a non-zero, regular Borel measure m that is left-invariant, meaning m(gA)=m(A) for all g in G and all Borel sets A subset of group G.
Haar measure, uniform distribution probability distributions on group of rotations of a sphere, SO(3)	The Haar probability measure on SO(3) corresponds to a uniform distribution of rotations. If you choose a rotation "at random," the probability of it falling into a certain region of the group space is proportional to the Haar measure of that region. This is how a spacecraft's orientation can be modeled as a random variable uniformly distributed over the space of all possible orientations. For a compact group, the Haar measure can be normalized to have a total measure of 1, making it a Haar probability measure. This measure represents the uniform distribution on the group, providing a natural way to choose a "random" element of the group.
Haar measure, use in defining a family of distributions on a locally compact group	Consider the Dirac delta "function" at the identity element of a group, delta_e​, can be seen as a distribution that "senses" a function's value at the identity. The Haar measure helps generalize this to other points. The convolution of a function with the Haar measure is a constant function, reflecting the invariance of the measure, For a test function p, the integral over G of p(g) dm(g) is a distribution, recall dm is a density kernel. The left-invariance of the Haar measure translates into an invariance property for these distributions.
Haar measure, canonical measure of phase space	consider a group like SO(3), the phase space is the cotangent bundle. The Haar measure on the group, combined with a natural measure on the fibers of the cotangent bundle, gives a canonical measure on the entire phase space. This measure is invariant under left-translations of the group, which is a geometric manifestation of the group's action The Haar measure on the tangent bundle of a Lie group provides a natural measure for the phase space (cotangent bundle), which is the domain for microlocal analysis. This allows for the definition of the symbol of a pseudodifferential operator on the group.
Haar measure, notion of volume to study invariant differential operators	Consider the group U(n) of unitary matrices is a compact Lie group. The Haar measure on U(n) is a specific volume form. The integral of a function over the group with respect to this measure gives its "average" value. The Haar measure's invariance is reflected in the fact that this average is the same regardless of how we "shift" the function. On a compact Lie group, the Haar measure is a natural volume form. It gives a notion of "total volume" for the group and is a key ingredient in the study of invariant differential operators, such as the Laplacian. It is used to define inner products on function spaces, which in turn are used to study the spectrum of these operators.
Haar measure, the heat equation on a torus (a compact group). The Haar measure is a multiple of the standard Lebesgue measure. The solution represents a heat distribution. If you shift the entire heat distribution to a different part of the torus, it will still evolve in the same way, because the underlying geometry and measure are translation-invariant	In the context of solving PDEs on groups (e.g., the heat equation on a Lie group), the Haar measure provides the measure space for the function space where the solution lives. The left-invariance of the measure ensures that if a solution is found, any left-translated version of that solution is also a solution.
Haar measure, a random walk on the circle. At each step, you take a small random turn. As you take more and more steps, your position becomes "uniformly" distributed over the circle. The Haar measure on the circle (arc length) is this uniform distribution. It's the "equilibrium" state for the random walk	The Haar measure is used to define a random walk on a compact group. For a random walk where each step is a random variable distributed according to a measure on the group, the Haar measure is the stationary distribution of the Markov chain. This means that as the number of steps increases, the distribution of the position of the random walker converges to the Haar measure.
Haar measure, a function on a Lie group. The Sobolev norm involves the L2-norm of the function and its derivatives. The Haar measure provides the volume element for this integral. The invariance of the measure ensures that the Sobolev norm of a function and its left-translated version are the same. This is crucial for studying the action of the group on these function spaces	The Haar measure provides the measure space for function spaces used in nonlinear functional analysis on Lie groups. It allows for the definition of Sobolev spaces and other function spaces that are crucial for studying non-linear PDEs and variational problems on groups. The invariance of the measure simplifies the analysis.
Haar measure, heat semigroup on a group corresponds to a convolution of an initial heat distribution with a heat kernel. The Haar measure is the measure used in this convolution integral. The left-invariance of the Haar measure implies that the heat kernel itself is invariant under left-translation, which means that heat diffuses in the same way everywhere on the group	The Haar measure is used to define contraction semigroups on Lie groups, such as the heat semigroup. The heat kernel is a function on the group, and its evolution is a semigroup. The Haar measure provides the volume element for the convolution operation that defines the semigroup.
Haar measure, you want to find the maximum value of a function on the group of rotations of a sphere. If you want to use a Monte Carlo method, you need to sample rotations uniformly. The Haar measure on SO(3) provides the correct way to do this	While not a core concept, the Haar measure can be used to define a uniform distribution over a compact set in a Lie group. For example, one might want to optimize a function over the group. The Haar measure can be used to sample points uniformly from the group for use in a stochastic optimization algorithm.
Haar measure, the group R and its subgroup Z, the quotient space is the circle S1. The Haar measure on R (Lebesgue measure) induces a measure on the circle (arc length). The length of any interval [a,b] on the circle is a measure of its size, and it is invariant under rotation	The Haar measure provides a way to quantify the "size" of subgroups and quotients. For a closed subgroup H in G, a measure on the coset space G/H can be constructed using the Haar measure on G.
Haar measure, a compact group acting on a sphere. The Haar measure can be used to define a uniform measure on the sphere that is invariant under the action of the group. If the group is SO(3), the measure is the standard area measure. This shows that the Haar measure is a source of invariant measures on homogeneous spaces	For a topological group G acting on a measure space (X, m), the Haar measure on G can be used to define a measure on the space of orbits. In particular, for a compact group G acting on a space X, the Haar measure can be used to construct a G-invariant measure on X.
Haar measure, Haar measure on a Lie group gives a notion of volume that is consistent with the group's structure. On the group R^n under vector addition, the Haar measure is the standard Lebesgue measure. The volume of a cube is invariant if you shift it. The Haar measure is the generalization of this to other groups	The Haar measure is a special case of a more general concept of a measure on a manifold. On a Lie group, it is a canonical volume form, and it is a fundamental object in geometric measure theory.
Haar measure, algebra of functions on a group with convolution as multiplication is a non-commutative algebra. The Haar measure is the measure used to define the convolution integral. It is essential for defining the inner product and norm that give rise to the Hilbert spaces on which these operator algebras act	In the theory of operator algebras, the Haar measure is used to define the group von Neumann algebra VN(G) and the group C*-algebra C∗(G). These algebras are completions of the convolution algebra of functions on G and are central to the study of group representations.
Haar measure, random variable uniformly distributed over a group has a certain amount of "randomness." The Haar measure provides the reference against which this randomness is measured. The more "volume" the group has, the more "random" a uniform element is	Haar measure can be used to quantify the information content of a random element from a compact group. For a random variable uniformly distributed with respect to the Haar measure, its entropy is proportional to the volume of the group.
Haar measure, a system on a torus. The Haar measure on the torus is the Lebesgue measure. If a dynamical system, like a flow, preserves this measure, it means that the "volume" of any region is conserved as the system evolves. This implies that the system is neither "contracting" nor "expanding" on average	In dynamical systems, the Haar measure on a compact group can be used to define an invariant measure for a dynamical system. If a system is defined by an action of the group, and a measure is invariant under this action, it provides a tool for studying the long-term behavior of the system.
Haar measure, a finite group, the Haar measure is the counting measure, assigning a measure of 1 to each element. The "integral" is just a sum. For a rotation group, the Haar measure gives a notion of "averaging" over all possible rotations, which is a powerful tool for studying the properties of the group	In a purely algebraic context, Haar measure provides a bridge between abstract group theory and analysis. It allows us to perform "integration" and "averaging" over groups, which is a powerful tool for studying group structure.
Locally compact abelian group, consider the circle group, S1, which consists of complex numbers of modulus 1 under multiplication. A neighborhood of any point on the circle, such as a small arc, is a compact set. The dual group consists of characters,which are maps of the form χ_k​(z) = z^k for integer k. The duality says that the group of these characters, Z, is the "correct" dual space for the circle	A locally compact abelian group (LCAG) is a group G that is abelian (the group operation is commutative) and also a topological space that is locally compact (every point has a compact neighborhood). The theory of LCAGs is fundamental because the Pontryagin duality theorem establishes a perfect duality between the group and its dual group of continuous characters. This duality is the cornerstone for generalizing Fourier analysis.
Locally compact abelian group, abelian, locally compact real interval, and any closed interval like [a,b] is a compact set and serves as a compact neighborhood for any point inside it. The Lebesgue measure on R is the unique translation-invariant measure. The existence of this measure is what makes Fourier analysis on the real line possible	An LCAG is a topological group G where the group operation is commutative, and the topology is Hausdorff and locally compact. This structure allows for the existence of a unique, up to a scalar multiple, translation-invariant Haar measure, which is essential for defining the Lp spaces and the Fourier transform on the group.
Locally compact abelian groups, the group R acting on L2(R) by translation operators, Ty​f(x)=f(x−y). The Stone-von Neumann theorem shows that this family of operators has a spectral decomposition. The Plancherel theorem, which is central to this, says that the Fourier transform diagonalizes these operators, mapping them to multiplication operators on L2(R^), where R^ is the dual group. The geometry of this is a direct translation from a "spatial" shift to a "frequency" multiplication	In the context of the spectral theory of operators, an LCAG is the underlying space on which a group of unitary operators acts. Specifically, for an LCAG G, its regular representation on L2(G) is a unitary representation. The spectral theorem for these operators relies on the structure of the LCAG and its dual.
Locally compact abalian groups, heat semigroup on R is given by convolution with a Gaussian. The operators are shifts and scalings. The geometry of the LCAG is what makes these operators well-defined and allows for the application of the spectral theorem. The space is "flat" in a sense, and the shifts are rigid transformations	An LCAG is the underlying space for the study of translation semigroups. A translation semigroup on L^p(G) is a family of operators that acts on functions by shifting them. The theory of such semigroups is fundamental to the study of PDEs like the heat equation.
Schwartz space, Fourier transform is automorphism on this space	one can define a perfect duality for tempered distributions. This is characterized by all derivatives rapidly decreasing, which is a strange property to have.
Ring of differential operators, Sobolev space	take single index (so it is derivatives to a single variable) ring of linear differential operators this is simply a linear combination of finitely many partial derivatives of regularity parameter m, take the root of m, and you get the Hilbert norm or L^p norm or the Sobolev norm. Is there a cheap connection between algebra and analysis here?
Hilbert norm, Sobolev spaces	one study L^p spaces because one wants to make a L into some sort of variable term in a polynomial. From considerations of Euclidean geometry, it seems very natural to consider the sum of p powers normalised by a root. You can pick L to be anything you wish, in this case L is an operator, and then study norms on polynomial like objects on it for some striking objects to study. If I am not mistaken, the main idea behind Sobolev spaces are when you pick the operator L as the differential operator D.
Distributions, example of the methodology of adopting weak solutions	one of the most interesting things you can do once you have no possible conception of a solution to a problem is to weaken the notion of a solution. With the right weakening, one can still derive insight and define objects worth studying from a situation where there is no true solution to the problem. This is the approach of many a business analyst, and in the real world where there is too much complexity.
Test functions, imagine a bell curve that is not only smooth (infinitely differentiable) but also "dies off" to exactly zero outside a finite region. It's a "blip" or a "bump." For example, the function p(x)=exp(−1/1-x^2)​ for norm(x) < 1  and 0 otherwise. It's perfectly smooth everywhere, even at the boundary of its support, where it flattens out to zero. These functions are ideal "probes" to "test" the properties of more general objects	A test function is a smooth function with compact support. The space of test functions, denoted D(Rn), consists of all infinitely differentiable functions p: R^n→C such that the closure of the set {x in R^n | p(x) is nonzero} is compact.
Distribution, distribution as a "machine" that takes in a test function "blip" and spits out a number. The output number is the "average" of the distribution "measured" by the test function. For a regular function f(x), the distribution it defines is the integral ∫ f(x) p(x) dx. The famous Dirac delta function d is a distribution, not a regular function. It takes a test function p(x) and outputs its value at the origin	d(p) = p(0). Visually, it's a "probe" that measures a function at a single point: A distribution (or generalized function) is a continuous linear functional on the space of test functions. This means it's a linear map T:D(R^n) to C that is continuous with respect to the specific topology of D(R^n).
Distribution, a "rough" function, like a step function. Convolving it with a small, smooth bump function ρ_eps ​(x) is like "blending" or "smoothing" the sharp edges. It produces a perfectly smooth function that is very close to the original rough one. This process, called regularization, is critical in proving results in PDEs where a smooth approximation is needed	A mollifier is a special kind of test function, a "bump function" often denoted ρ_esp (x), with integral 1 and support shrinking to a point as esp →0. We can use convolution with a mollifier to approximate any function with a smooth one.
Weak derivatives, take the derivative of "functions" that are not differentiable in the classical sense. For example, the Heaviside step function H(x), which is 0 for x<0 and 1 for x>0, is not differentiable at x=0. Its distributional derivative is the Dirac delta function d(x), a spike at the origin. This makes intuitive sense	the "change" in the Heaviside function is an infinite jump at a single point:  The derivative of a distribution T is defined via integration by parts. For a test function d, the distributional derivative T′is defined as T′(d)=−T(d′). This formula holds for all test functions and can be extended to all distributions.
Test functions, the Schwartz space as including functions like exp(-x^2). They are infinitely smooth and "die off" to zero very quickly, but their support is the entire real line, so they aren't test functions. The space of "tempered distributions" is the dual of the Schwartz space, a much broader class of distributions that includes all regular functions that don't grow too fast, as well as the Dirac delta function	The Schwartz space S(R^n) is a larger space than D(R^n). It consists of all smooth functions that, along with all their derivatives, decay faster than any polynomial. Test functions are a subset of the Schwartz space.
Distributions, Fourier transform is a powerful tool for analyzing frequency content. By extending it to distributions, we can find the frequency content of things like the Dirac delta function. The Fourier transform of d(x) is the constant function 1. This makes intuitive sense	a spike at one point contains all frequencies equally:  The Fourier transform can be extended to tempered distributions. For a tempered distribution T, its Fourier transform T^ is defined by T^(d) =T(d^​), where d is a test function in the Schwartz space.
Test functions, topology, a sequence of "bumps" that are getting closer and closer to another "bump." For them to converge in this space, they can't just converge in value; their derivatives must also converge, and they must all stay within a single, bounded region. This ensures that the distributions defined on this space are well-behaved	The space of test functions D has a special topology that makes it a locally convex topological vector space. A sequence of test functions d_n​ converges to d if all their derivatives converge uniformly and their supports are contained in a common compact set.
Test function, fundamental solution is like the "response" of a system to a single, concentrated "poke" (the Dirac delta). The log function in R^2 blows up at the origin, just like the response to a single-point heat source or charge. This is a very powerful concept for solving PDEs, as the solution for any given right-hand side can be found by convolving with the fundamental solution	The fundamental solution of a linear PDE is a distribution E that solves the equation when the right-hand side is the Dirac delta function. For the Laplacian, the fundamental solution in R^2 is E(x)= 1/2 pi log(|x|).
Test functions, manifold, like a sphere. We can cover it with a finite number of overlapping "patches." We can create a set of test functions, one for each patch, that are 1 in the middle of their patch and smoothly go to 0 at the boundary. These functions can be used to break down a global problem into local problems. The sum of all these functions is exactly 1 everywhere	A smooth partition of unity is a collection of smooth functions with compact support (test functions) that sum to 1 over a manifold.
Test functions, distributions as an algebraic completion of the space of continuous functions. Just as we add "ideal numbers" (like the root of -1​) to the real numbers to get the complex numbers, we add "ideal functions" (like the Dirac delta) to the space of functions to get the space of distributions	Distributions provide a way to work with "ideal" objects that are not functions, such as the Dirac delta function. They are abstract, but their properties are well-defined.
Distribution, a regular function f, the distribution is the integral, integral of f(x) p(x)dx. This is like a weighted average of f(x) with the test function p(x) as the weight. Distributions allow us to do this "averaging" even for objects that aren't functions	A distribution is a way to generalize the process of integration. Instead of integrating a function against a measure, a distribution "integrates" a test function.
Distribution, as "points" in a very abstract, infinite-dimensional space. The geometric Hahn-Banach theorem says we can find a hyperplane (defined by a test function) that separates two disjoint convex sets of distributions	The space of distributions can be viewed through the lens of functional analysis. The dual of the space of test functions is the space of distributions. The geometric Hahn-Banach theorem can be applied to separate convex sets of distributions.
Test functions, a membrane stretched over a boundary. We can apply a point load (a Dirac delta function) at a specific point. The solution to this problem is a distribution	Distributions can be used to formulate and solve boundary value problems in a weak sense.
Distribution, probability of a random variable taking on a specific value in a continuous distribution is zero. However, we can describe this event using the Dirac delta distribution, which represents the probability mass at a single point	A probability density function is a distribution. The Dirac delta function can represent a discrete probability measure at a point.
Distribution, graph of an operator is the set of all input-output pairs. The closed graph theorem states that for a well-behaved space like distributions, if the graph of an operator is a "complete" set (it doesn't have any holes), then the operator must be continuous	The closed graph theorem is a fundamental result in functional analysis. It can be used to show that a linear operator on the space of distributions is continuous.
Distribution kernel, consider the identity operator on a space of functions. Its kernel is the Dirac delta distribution, K(x,y)=δ(x−y).This functional "picks out" the value of the input function at the point x. Geometrically, imagine the kernel as a "point-source" or "spike" at every point on the diagonal line x=y in the (x,y)-plane. When you integrate (or more accurately,"convolute") with an input function, the spike at each point (x,x) instantaneously transfers the value of the input function at x to the output function at x. The action of the operator is to leave the function unchanged	A distribution kernel K(x,y) is an element of a space of distributions that defines a linear operator T mapping functions from one space to another, as given by the integral of K(x, y) * phi(y) dy in a general sense for phi(y) test function.
Distribution kernel, manifold (a curved space), solving a differential equation for a point source gives a Green's function. This function, which is a distribution kernel, tells you how a disturbance at one point propagates to all other points. For example, on a sphere, the Green's function for the Laplacian is a kernel that describes the potential from a point charge	A distribution kernel is a Green's function on a manifold.
Distribution kernel, imagine a space where each point has both a position and a momentum (like a particle). A distribution kernel in this context isn't just a function of position but also of momentum. It acts on a function by transforming it not just locally but also in terms of its oscillatory behavior. This allows it to model phenomena like wave propagation, where both position and frequency are critical	A distribution kernel is a pseudodifferential operator on the cotangent bundle.
Distribution kernel, space of test functions, say smooth functions with compact support, is a kind of vector space. A distribution kernel is a "generalized vector" in the dual space. It takes a function as input and outputs a number, like a dot product. The Dirac delta kernel δ(f)=f(0) is a simple example	it takes a function and "selects" its value at the origin: A distribution kernel is a continuous linear functional on a space of test functions.
Distribution kernel, a random variable can be discrete, continuous, or a mix of both. A distribution kernel can represent the probability density for all three cases. For a discrete variable, the density is a sum of Dirac delta functions, one for each possible value, with a weight equal to its probability. For a continuous variable, the density is a smooth function. The kernel provides a unified framework to handle both	A distribution kernel is a probability density function, but extended to include impulses.
Distribution kernel, "mass distribution" on a line. This mass isn't necessarily concentrated at a point but can be smeared out. A distribution kernel is the mathematical object that describes this mass. When a smooth function (the test function) is "dropped" onto this mass distribution, the output is the total weighted mass. A Dirac delta is a point mass. Its action on a test function is simply to "weigh" the function at the location of the point mass	A distribution kernel is a signed measure that acts on continuous functions with compact support.
Distribution kernel, simple operator like the Laplacian on a circle, its "eigenvectors" are the sines and cosines. For a more general operator, the "eigenvectors" are not necessarily functions but distributions. The distribution kernel represents these "eigen-distributions," which are the generalized functions that are only scaled by the operator. For example, the Dirac delta function δ is an "eigen-distribution" of the convolution operator with itself, because δ∗δ=δ	A distribution kernel is the "eigen-distribution" of an operator.
Distribution kernel, convex function like f(x)=|x|, the subgradient at x=0 isn't a single number but a set of all slopes between −1 and 1. A distribution kernel can represent this set as a generalized function. Imagine the graph of f(x)= |x| as a V-shape. At the sharp point (the origin), the "tangent line" isn't unique. The subgradient is the set of all possible slopes of lines that lie below the graph and pass through the origin. A distribution kernel is a formal way to describe this "set of slopes."	A distribution kernel represents a subgradient of a convex function.
Distribution kernel, a stochastic process like a random walk, the transition density tells you the probability of a particle moving from one location to another. This density is a distribution kernel. For example, for a standard Brownian motion, the transition density is a Gaussian function centered at the starting point, whose variance increases with time	A distribution kernel is the transition density of a stochastic process.
Distribution kernel, Gâteaux derivative is the "directional derivative" of an operator in an infinite-dimensional space. It tells you how the operator changes as you move a small distance in a specific direction. The Gâteaux derivative is often a linear operator, and its kernel is the distribution kernel	A distribution kernel is a Gâteaux derivative of a nonlinear operator.
Distribution kernel, semigroup is a family of operators that describes evolution over time, like the heat semigroup. The generator is the "infinitesimal" operator that tells you how the system evolves from one moment to the next. For the heat equation, the generator is the Laplacian operator, and its kernel is the fundamental solution	A distribution kernel is the generator of a semigroup of operators.
Distribution kernel, character is a special type of function that helps to decompose a representation of a group into simpler pieces. The character is a distribution kernel because it acts as a "probe" that measures how a function on the group is transformed by a group action. For example, the characters of the group of rotations in the plane are the functions exp(inθ), which are kernels that pick out the n-th harmonic of a function	A distribution kernel is a character of a locally compact group.
Distribution, convex function like f(x)= |x|, the subgradient at x=0 is a set of all possible slopes between −1 and 1. The Dirac delta distribution can represent this subgradient. It's a way of representing a "sharp change" or "singularity" in the derivative as a well-defined object	A distribution can be the subgradient of a convex function at a point of non-differentiability.
Distribution, operator like the derivative operator, its eigenfunctions are not always functions in the classical sense. The eigenfunctions of the momentum operator are exp(iξx), which are not in any L2 space. These are generalized eigenfunctions (distributions). The operator "acts" on these distributions by simply scaling them, revealing its spectrum	A distribution is a generalized eigenfunction of an operator.
Distribution, space of test functions is a vector space of "nice" functions. A distribution is a linear map from this space to the real or complex numbers. The "space of all distributions" is the dual space of the space of test functions	A distribution is a continuous linear functional on the space of smooth functions with compact support, C_c^\infty.
Distribution, manifold (a curved space), the concept of a function is generalized to a section of a vector bundle. A distribution is a generalized section. For example, the Dirac delta function on a sphere is a distribution on the sphere that can be defined intrinsically	A distribution is a section of a vector bundle over a manifold.
Distribution, stochastic process like a random walk can be described by its distribution. The position of the walker is a random variable. The distribution of this random variable is a generalized function that can have point masses	A distribution is a generalized random variable.
Distribution, heat equation describes the diffusion of heat. The initial temperature distribution can be a point source, which is a Dirac delta distribution. The semigroup of heat operators takes this initial distribution and produces a smooth function that describes how the heat spreads out over time	A distribution can be the initial state of a system described by a semigroup.
Distribution, Fourier transform of a distribution (e.g., a singular object like the Dirac delta) can be a well-behaved function (e.g., a constant function). The distribution is an object that, when viewed in the frequency domain, becomes a simple function	A distribution is an object whose Fourier transform is a function.
Distribution, impulse response is the output of a system when the input is a Dirac delta function (a perfect impulse). This response, which is a distribution, completely characterizes the system's behavior	A distribution is the impulse response of a linear time-invariant system.
Modulated rescale bump function, standard "bump" on a flat surface, centered at the origin, representing the function ψ(x). The rescaling by λ acts like a zoom lens. If λ is large, the bump becomes very narrow and tall, localized in position but spread out in frequency. If λ is small, the bump becomes wide and flat, spread out in position but localized in frequency. The modulation by exp(iξx()acts as a "wave" that rides on top of the bump. The function ψ_{λ,ξ}​(x) is a wave of frequency ξ that is localized within a region of size 1/λ and centered at the origin. We can use this family of functions to test the regularity of a distribution by "probing" it at different scales and frequencies. The Sobolev norm of a distribution can be characterized by how well it can be "seen" by these bump functions	In distribution theory, a modulated rescaled bump function is a smooth function with compact support (a "bump function," ψ) that is transformed by a change of scale and a modulation. Specifically, it is a function of the form ψ_{λ,ξ}​(x)=exp(iξ⋅x)ψ(λx)), where λ>0 is a scaling parameter and ξ in R^n is a modulation parameter. This family of functions is crucial because it forms a "wavelet-like" basis that can probe the regularity of a distribution at a specific point in both position (x) and frequency (ξ) space.
Modulated rescaled bump function, imagine a "phase space" where the horizontal axis represents position and the vertical axis represents frequency. The wave front set of a distribution is a cloud of points in this space that tells you where and in what "frequency" (or direction) the distribution is "not smooth." A modulated rescaled bump function is a small "probe" that we can move around in this phase space. The function ψλ,ξ​(x) is a probe that is localized at a certain position and a certain frequency. By seeing how the distribution "responds" to this probe, we can determine if a point (x0​,ξ0​) is in the wave front set. If the distribution "blows up" when we test it with a probe at (x0​,ξ0​), then that point is in the wave front set. If the response is "tame," then the distribution is smooth at that point and in that direction	In microlocal analysis, the modulated rescaled bump function is a fundamental tool for analyzing the wave front set of a distribution. The wave front set is a set of points in the phase space (T∗R^n is isomorphic R^{2n}), which captures the location and direction of the singularities of a distribution. The function ψ_{λ,ξ}​(x) is used to test the behavior of a distribution near a point (x0​,ξ0​) in phase space. The scaling parameter λ controls the size of the neighborhood in position and frequency space, while the modulation ξ controls the direction of the frequency.
Modulated rescaled bump function, a distribution as a complex signal. We want to analyze its components at different frequencies. A modulated rescaled bump function is a "filter" that isolates a specific frequency band at a specific location. The operator that maps a distribution u to the family of coefficients {⟨u,ψλ,ξ​⟩}λ,ξ​ is like a time-frequency analyzer. This analyzer tells us how much "energy" the signal has at a particular location and frequency. A regular distribution would have very little "energy" at high frequencies, which means that the coefficients ⟨u,ψ_{λ,ξ}​⟩ would decay quickly as ξ becomes large. The Sobolev norm is essentially a weighted sum of these coefficients, and the decay rate of the coefficients tells us about the regularity of the distribution	From a functional analysis viewpoint, the modulated rescaled bump function can be seen as an element of a function space, and its use in distribution theory can be formalized as the action of a probing operator. For a distribution u, the value ⟨u,ψ_{λ,ξ}​⟩ is a coefficient that measures the "content" of the distribution at a certain scale and frequency. This family of coefficients, as λ and ξ vary, forms a kind of "fingerprint" of the distribution's regularity.
Modulated rescaled bump function, piece of music with a bass drum beat and a high-pitched flute melody. The Fourier transform gives us the overall frequency content but doesn't tell us when each sound occurs. The STFT, using a window function, allows us to analyze the frequency content of the music in short time intervals. The modulated rescaled bump function is the perfect window for this. It is a "time-limited" sinusoid. We slide this window along the signal, and for each position, we calculate the Fourier transform of the windowed signal. This gives us a spectrogram, which is a 2D plot of time versus frequency, and the brightness of the plot tells us the energy of the signal at that time and frequency. A smooth signal would have a spectrogram with "low-frequency" content, while a jagged signal would have a spectrogram with "high-frequency" content	In signal processing, a modulated rescaled bump function is a "windowed sinusoid," which is used to perform a short-time Fourier transform (STFT). The STFT is a time-frequency analysis technique that is used to analyze non-stationary signals. The bump function acts as a window that localizes the signal in time, and the modulation provides the frequency component.
Modulated rescaled bump function, shock wave propagating through a medium. The shock wave is a discontinuity in the pressure or density. It is a singularity in the solution to the PDE. The modulated rescaled bump function can be used to "interrogate" this singularity. We can use a bump function with a high frequency (ξ) that is localized near the shock wave to determine its exact location. The direction of the modulation vector ξ would align with the direction of the shock wave's normal vector. The regularity of the solution is then the property that it is smooth everywhere except for a set of points that are "detected" by these probes	From the perspective of PDEs and hyperbolic equations, the modulated rescaled bump function is used to study how singularities (e.g., shock waves) propagate. The regularity of a solution is often a function of both position and direction. A singularity is a point where the solution is not smooth, and the modulated rescaled bump function can be used to probe this singularity to determine its location and direction of propagation.
Modulated rescaled bump function, curved surface, like a sphere. We can't use a standard bump function that is defined on R^n directly. Instead, we use a local chart to "flatten" a small part of the sphere. On this flat part, we can use a standard modulated rescaled bump function. This allows us to "probe" the regularity of a function on the sphere at a specific point and in a specific direction. The regularity of the function on the manifold is its property of being smooth in every local chart, and the Sobolev norm on the manifold is a combination of the Sobolev norms of the function in each local chart	In global analysis, we study objects on manifolds. A modulated rescaled bump function on a manifold is a smooth function with compact support that is modulated by a function that is "close" to a linear function in a local chart. The family of these functions forms a basis for a manifold, which can be used to study the regularity of objects (e.g., sections of bundles, solutions to PDEs) on the manifold.
Modulated rescaled bump function, random landscape, where the height at each point is a random variable. The covariance function of the random field tells us how the height at one point is correlated with the height at another point. If the covariance function is smooth, the landscape is likely to be smooth. A modulated rescaled bump function can be used to probe the regularity of the landscape. We can use a bump function with a high frequency (ξ) that is localized at a point to "test" for roughness. If the variance of the integral of the random field against this probe is small, then the field is likely to be smooth at that point and in that direction	In probability theory, the modulated rescaled bump function can be used to study the regularity of random fields or stochastic processes. For example, in the study of a Gaussian process, the covariance function determines the "smoothness" of the sample paths. The modulated rescaled bump function can be used to probe the regularity of the sample paths at a specific point in both position and frequency.
Modulated rescaled bump function, imagine the Fourier transform of the picture gives us the frequency content, but it doesn't tell us where the features are. A wavelet transform gives us a representation of the picture in both space and frequency. A modulated rescaled bump function is like a tiny "pixel" that we can use to analyze the picture. The scale parameter λ controls the size of the pixel, and the modulation parameter ξ controls the "texture" that the pixel is looking for. The regularity of the picture is related to how much "energy" is in the high-frequency pixels. A smooth picture would have very little energy in the small, high-frequency pixels	The modulated rescaled bump function is a close relative of a wavelet. A wavelet is a function that is localized in both time and frequency, and a family of wavelets can be used to represent any function in a function space. The modulated rescaled bump function is a special type of "wavelet" that is particularly useful for analyzing the regularity of functions and distributions.
Modulated rescaled bump function, the a nonlinear PDE as a complex machine that takes a function and outputs another function. The solution to the PDE is a fixed point of this machine. We want to know how "smooth" the solution is. We can use a modulated rescaled bump function to "test" the solution for smoothness. The regularity of the solution is the property that it behaves "nicely" when we test it with these bump functions. The Sobolev embedding theorem, for example, says that if the solution is in a certain Sobolev space, then it must be continuous, which is a type of regularity that can be probed with these bump functions	In nonlinear functional analysis, the modulated rescaled bump function can be used to study the regularity of solutions to nonlinear PDEs. The solutions to these equations are often in Sobolev spaces, and the regularity of the solution is a key property. The modulated rescaled bump function can be used to probe the regularity of the solution in a very localized way.
Modulated rescaled bump function, an operator as a "vibrating string." The eigenvalues of the operator are the fundamental frequencies of the string. The eigenfunctions are the shapes of the vibrations. The modulated rescaled bump function can be used to create a "wave packet" that is localized in space and frequency. We can "probe" the operator with this wave packet to study how it affects functions with a specific regularity. The regularity of the eigenfunctions is a key property that can be studied using these wave packets	In spectral theory, the modulated rescaled bump function can be used to study the spectral properties of an operator. The spectrum of an operator is the set of its eigenvalues, which are related to the operator's properties. The modulated rescaled bump function can be used to construct a "wave packet" that is localized in both position and frequency. This wave packet can be used to study the operator's action on functions with a specific regularity.
Modulated rescaled bump function, two-dimensional plot with position on the x-axis and frequency on the y-axis. The modulated rescaled bump function is a "blob" in this space. The Heisenberg uncertainty principle says that the area of this blob is always greater than or equal to a certain constant. If we try to make the blob very narrow in position (by making λ large), it becomes very wide in frequency. If we try to make it very narrow in frequency (by making λ small), it becomes very wide in position. The regularity of a function is its property of having a "small" blob in this phase space	The modulated rescaled bump function is a concrete example of a function that demonstrates the Heisenberg uncertainty principle in signal processing. The uncertainty principle states that it is impossible to perfectly localize a function in both position and frequency. The bump function is a compromise: it is localized in both, but its localization is not perfect
Pullback, universal intersection	given morphisms f from X to Z and g from Y to Z, the pullback is a universal object P with projections p_x : P to X and p_Y from P to Y such that f * p_X = g * p_Y i.e. these projections are sections. The universal property means that for any other Q that maps to X and Y commuting over Z, there is a unique isomorphism from Q to P.
Covering, using morphisms and relevant stability properties to generalise open covers to create sheaves later	using category, generalise open covers as a family of morphisms such that for any compatible local data on the moprhisms can be uniquely glued to U, these must satisfy isomorphism invariance, stability under pullbacks, and refinement (these are conditions for sheafification later)
Grothendieck topology, open cover to define sheaves on categories	a Grothendieck topology on a category C assign each object U (glued) a family of morphisms {U_i -> U} such that isomorphisms are coverings, and coverings are stable under pullbacks and refinements, one can then sheaves on categories.
Sites, categories that can be sheafified	a site is a category with a Grothendieck topology i.e., a specification of “covering families” for each object, such that pullbacks of coverings exist and coverings are stable under composition; it formalizes the notion of which collections of morphisms allow sheaves to be defined and glued consistently over category C.
Stack, tracking automorphisms in objects using families	a stack is a category (often fibred in groupoids) over a base site (need sites to have coverings that track automorphisms) such that for any covering, objects and morphisms can be glued consistently, and isomorphisms form a sheaf; it generalizes moduli spaces by encoding both objects and their automorphisms, allowing a well-behaved notion of “families of objects with symmetries.”
Mellin transform, analyses the power law (moments, generalisation of moment generating function) content of a function rather than frequency	A Mellin transform maps a function f(x) on the positive real axis to a new function F(s) in the complex plane, where F(s)= integral over positive real axis of x^{s-1} f(x) dx. Note that the annoying -1 comes from considerations of dx/x, see lecture on Haar measure by Borcherds.
Mellin transform, generalised moment	The Mellin transform of a density function is E[X^{s - 1}]. Useful in probability as a generalised moment.
Mellin transform, handles singularities with distributions (key example	Dirac delta at x = 1 is constant):  The Mellin transform extends to distributions, especially those with power-law singularities. The Mellin transform of the Dirac delta at x = 1 is simply a constant, which is a testament to its power to handle singularities. Imagine a function with a sharp spike at x = 1. The Mellin transform "smooths out" this spike and represents it as a simple function in the complex plane.
Mellin transform, relates Dirichlet series to Riemann zet function	Riemann zeta function is defined as a Dirichlet series, and its properties are deeply linked to number theory. The Mellin transform provides a way to express the zeta function as an integral, making it possible to use the tools of complex analysis to study it
Integral transform, linear operator, its eigenfunctions are the functions that are only scaled by the operator. The integral transform is the "change of coordinates" that takes a function and represents it as a linear combination of these eigenfunctions. For example, the Fourier transform takes a function and represents it as a sum of sines and cosines, which are the eigenfunctions of the Laplacian operator on a periodic domain	An integral transform is a change of basis from the position basis to the eigenbasis of an operator.
Integral transform, measure can be thought of as a distribution of "mass" or "charge." An integral transform takes this distribution and creates a new one. For example, the Fourier transform of a measure of point masses is a sum of oscillating functions. The transform maps the discrete mass points to a continuous function, revealing its periodic structure	An integral transform is a linear map between spaces of measures.
Integral transform, probability density function describes the likelihood of a random variable taking a certain value. The characteristic function is its Fourier transform. It's a complex-valued function that encodes all the statistical moments of the distribution, such as the mean, variance, etc. . The transform is a tool that "compresses" all the statistical information into a single function	An integral transform of a probability density function is a moment-generating function or characteristic function.
Integral transform, Distributions are generalized functions, like the Dirac delta. The Fourier transform of a Dirac delta function is a constant function. The transform takes a "point-like" object in one domain and transforms it into a "flat" object in the other. It's a way of representing a singular object in a more well-behaved form	An integral transform maps a distribution to another distribution.
Integral transform, a curved manifold, the heat equation describes how heat diffuses. The heat kernel is an integral transform kernel that maps an initial temperature distribution to the temperature distribution at a later time. The kernel, often a Gaussian-like function, encapsulates how heat "spreads" over the curved space	An integral transform is a heat kernel or propagator on a manifold.
Integral transform, Fourier and Laplace transforms are particularly useful for this. They convert a PDE into a simpler algebraic equation in the transform domain. For example, the heat equation dt/du = k d^2u / dx^2​ transforms into a simple first-order ODE in the frequency domain, which is easily solved	An integral transform is a tool for solving certain PDEs, especially those with constant coefficients.
Integral transform, semigroup describes the evolution of a system over time. The Laplace transform maps the time-domain evolution to a frequency-domain representation. The transform is a "snapshot" of the system's dynamics at a given "frequency."	The integral transform is the Laplace transform, which is used to analyze semigroups of operators.
Integral transform, harmonic analysis, an integral transform (like the Fourier transform) acts as a "decomposition" tool for a function on a group. It breaks down the function into its "building blocks," which are the characters of the group. It's a way of understanding a complex object by looking at its simpler components	An integral transform is the process of decomposing a representation of a group into its irreducible representations.
Integral transform, system's stability is determined by the poles of its transfer function in the Laplace domain. The transform maps the system's behavior over time to a complex plane. By looking at the location of the poles in this plane, one can determine if the system will be stable or unstable	The Laplace transform is used to analyze the stability of control systems.
Kernel, image processing filter. The kernel is a small matrix of numbers, like a 3×3 grid, that slides over the image. The value of the new pixel at position (i,j) is a weighted sum of the old pixel values in the neighborhood, where the weights are given by the kernel. The kernel dictates how the image is transformed, whether it's blurred, sharpened, or edge-detected	In integral transforms, the kernel K(s,x) is the weighting function that defines the transformation.
Kernel, two-dimensional plot. The kernel can be a measure, which is a distribution of "mass" over this plot. When you apply the operator, you are essentially "integrating" the input function against this mass distribution. For example, a measure concentrated on the diagonal y=x would correspond to the identity operator	An integral kernel is a measure on the product space of the domain and codomain.
Integral kernel, stochastic process, the kernel p(y∣x) gives the probability density of transitioning from state x to state y. For a simple Markov chain, the kernel is a transition matrix. For a continuous process, the kernel is a function that, at a given x, describes the bell-shaped curve of possible future positions y	An integral kernel is a conditional probability density function.
Integral kernel, microlocal analysis, we study operators that are not necessarily local, but "almost" local. The kernel of such an operator is not just a function of two variables but also of frequency. The kernel, often called the symbol, can be visualized in phase space (position and momentum). The kernel tells you how the operator transforms a function based on both its value and its oscillations	The kernel is the symbol of a pseudodifferential operator.
Integral kernel, in a curved manifold, the fundamental solution to a differential equation (e.g., the Laplacian) is the kernel that describes the response to a point source. For example, on a sphere, the fundamental solution to the Laplacian is the potential from a point charge. This kernel, which is a distribution, encapsulates the geometry of the manifold and the behavior of the operator	A kernel is the fundamental solution of a differential operator on a manifold.
Integral kernel, for a stochastic process (e.g., Brownian motion), the kernel p(x,t | y,t0​) represents the probability density of being at point x at time t given that the process started at point y at time t0​. For Brownian motion, this kernel is a Gaussian function that broadens with time	A kernel is the transition density of a stochastic process.
Integral kernel, operator can be defined by a kernel, but the relationship is not always linear. For example, in a Urysohn operator, the kernel K(x,y,f(y)) depends on the value of the function being integrated, making the operator nonlinear. The kernel is like a "filter" whose properties change based on the input signal	A kernel can be used to define a nonlinear operator.
Integral kernel, semigroup is a family of operators that describes how a system evolves over time. The generator of this semigroup is a kernel that describes the "infinitesimal" change in the system. For the heat equation, the generator is the Laplacian, and its kernel is the heat kernel	The kernel is the generator of a semigroup of operators.
Integral kernel, character is a special type of function on a group that is constant on conjugacy classes. It can be viewed as a distribution kernel that "probes" a representation and reveals its internal structure. For example, the character of a rotation group tells you how many times each irreducible representation appears	The kernel is the character of a representation.
Integral kernel, system's behavior is completely characterized by its response to a single, sharp input (an impulse, or Dirac delta). This response, which is a distribution kernel, is the "DNA" of the system. By "convolving" any input with this kernel, you can predict the output	The kernel is the impulse response of a linear time-invariant system.
Integral kernel, numerical integration scheme like the trapezoidal rule, the integral is approximated by a weighted sum of function values. The kernel is the set of weights you use. For the trapezoidal rule, the kernel is a triangular shape that weights the endpoints less than the middle points	The kernel is the weight function for numerical integration.
Laplace transform, a continuous signal over time, like the voltage in an electronic circuit after a switch is flipped. The Laplace transform is like taking a "snapshot" of the signal's decay behavior and representing it as a point in a complex plane. . The real part of the complex variable s corresponds to the decay rate, and the imaginary part corresponds to the oscillation frequency	The Laplace transform maps a function f(t) to F(s) via the integral F(s) over real line ​exp(−st) f(t)dt.
Convex optimisation, Laplace transform of a convex function is its convex conjugate. Imagine a convex function like a bowl. The Laplace transform describes this bowl not by its surface but by the set of all its tangent planes. The transform encodes the relationship between the function and its "dual" representation	The Laplace transform is related to convex optimization through the concept of convex conjugation and the Legendre-Fenchel transform.
Laplace trasnform, semigroup of operators describes the evolution of a system over time. The Laplace transform maps this continuous time evolution to a family of operators in the complex plane. The poles of the transformed operator (the resolvent) correspond to the eigenvalues of the generator. This allows us to find the "resonant frequencies" or "eigenmodes" of the system	The Laplace transform of a semigroup is the resolvent of its generator.
Laplace transform, "moment-generating function" for this mass distribution. It gives you a function in the complex plane that encodes information about how the mass is distributed on the real line	The Laplace transform of a measure on R is the integral over positive real line ​exp(−st) dμ(t).
Laplace transform, distribution, like the Dirac delta function δ(t), can be thought of as a generalized function. The Laplace transform of δ(t) is simply 1. The transform converts a singular, "point-like" object in the time domain into a simple, constant function in the complex frequency domain	The Laplace transform can be extended to tempered distributions with support on the positive real axis.
Laplace transform, random variable X with density f(x), its moment-generating function is M_X​(s)=E[exp(sX) ] = over real line ​exp(sx) f(x)dx. This is essentially the Laplace transform with s replaced by −s. It's a single function that encodes all the statistical moments of the random variable	The Laplace transform is the moment-generating function of a non-negative random variable.
Laplace transform, study the singularities of functions. The Laplace transform helps to analyze singularities that have an exponential decay. It provides a way to "zoom in" on the singularities and study their behavior in the complex plane	The Laplace transform is related to the Fourier integral operator when analyzing functions with exponential decay.
Laplace transform, heat kernel on a manifold is the fundamental solution to the heat equation. The Laplace transform of the heat kernel with respect to time is the resolvent of the Laplacian operator on the manifold. This provides a way to study the geometry of the manifold by analyzing the spectrum of the Laplacian	The Laplace transform is a tool for studying the heat kernel on a manifold.
Laplace transform, semigroup is a family of operators that describes continuous evolution, like the heat semigroup. The Laplace transform of this semigroup, a family of operators that describes the "frequency domain" behavior, is the resolvent of the semigroup's generator. It's a way to move from the continuous evolution of a system to a static representation that encapsulates all its properties	The Laplace transform is a primary tool for studying one-parameter semigroups of operators.
Laplace transform, Laplace transform can be viewed as a specialization of the Fourier transform. The Fourier transform analyzes signals in a frequency space, while the Laplace transform analyzes signals in a complex frequency space that includes a decay component. This makes it a natural tool for analyzing representations of Lie groups that have a "cone-like" structure	The Laplace transform is related to the Fourier transform on a cone.
Laplace transform, system's stability can be determined by the location of the poles of its transfer function in the complex s-plane. The Laplace transform maps the system's differential equations to this plane. If all the poles are in the left half of the plane, the system is stable	The Laplace transform is the primary tool for analyzing the stability of linear time-invariant systems.
Laplace transform, impulse response is a signal's output when a short, sharp pulse is input. The Laplace transform of this response, called the transfer function, describes how the system's output responds to different frequencies. It's a way of representing a system's behavior as a simple algebraic function	The Laplace transform of an impulse response is the transfer function of a system.
Laplace transform, electrical circuits, components like resistors, capacitors, and inductors have complex frequency-domain representations. The Laplace transform converts a differential equation for a circuit into a simple algebraic equation involving impedances and admittances, which is much easier to solve	The Laplace transform is a tool for circuit analysis.
Convolution, infimal convolution of two convex functions, (f□g)(x)=infy​{f(y)+g(x−y)}, represents the lower envelope of the sum of the two functions. Imagine two convex bowls. The infimal convolution is a new bowl that you get by "summing" them in a specific way. It's the lowest possible surface you can get by sliding one bowl under the other and adding their heights	Convolution can be used in convex analysis to define the infimal convolution of convex functions.
Convolution, Convolution Theorem states that the Fourier transform of a convolution is the product of the individual Fourier transforms, F(f∗g)=F(f)⋅F(g). This is a change of perspective from a complex "smearing" operation to a simple point-wise multiplication. It's like switching from the time domain (where a filter convolves a signal) to the frequency domain, where the filter just scales the frequency components of the signal	Convolution is an operation that becomes a simple multiplication in the frequency domain.
Convolution, discrete set of masses (a discrete measure). Convolving this with a continuous probability density (another measure) "spreads" each point mass into a continuous distribution, like a sum of bell curves. The resulting convolution is a continuous measure	Convolution is the operation of "smearing" one measure with another.
Convolution, X and Y be two independent random variables. The probability density function of their sum, Z=X+Y, is the convolution of their individual densities, fZ​=fX​∗fY​. Imagine a random variable representing the height of a person and another representing the height of their shoes. The convolution gives you the distribution of their total height	The convolution of two probability density functions gives the density function of their sum.
Convolution, convolution of a test function with the Dirac delta function δ(t) is simply the original test function, (f∗δ)(x)=f(x). This shows that the Dirac delta acts as the identity element for convolution. The Dirac delta is a "point-like" distribution that, when convolved with a function, doesn't change it	Convolution extends to distributions, allowing us to define operations on generalized functions.
Convolution, model how singularities propagate and interact. The wave front set of a convolution is contained within the sum of the wave front sets of the individual distributions. This means that a convolution can "smooth out" some singularities or create new ones in a predictable way	Convolution is a form of multiplication in phase space.
Convolution, with a heat kernel or a smoothing kernel can be used to average a function over a neighborhood. This is a form of geometric "blurring" that is intrinsic to the manifold's geometry. For example, on a sphere, convolving a function with a smoothing kernel averages the function over a small patch of the sphere's surface	Convolution is a way of "smearing" a function on a manifold.
Convolution, fundamental solution to a linear PDE is the solution for a point source (a Dirac delta function). The solution to the PDE for an arbitrary source is the convolution of the fundamental solution with the source term. For example, the solution to the heat equation with a given initial temperature distribution is the convolution of that distribution with the heat kernel	Convolution with the fundamental solution is a way to solve linear PDEs.
Convolution, mollifier is a smooth function with a compact support and an integral of 1. Convolving a non-smooth function (e.g., a square wave) with a mollifier "blurs" the sharp edges and turns it into a smooth function. This is a common technique to prove results about non-smooth functions by first proving them for smooth ones	Convolution can be used to mollify a function, turning a non-smooth function into a smooth one.
Convolution, semigroup of operators describes a system's evolution. The composition of two evolution operators is a convolution in the time domain. For example, the heat semigroup, T(t), is such that T(t1​)T(t2​)=T(t1​+t2​). This corresponds to the convolution of the heat kernels	
Convolution, harmonic analysis on groups, convolution is the natural way to multiply functions. It's a generalization of polynomial multiplication. The Fourier transform on a group turns this convolution into a simpler operation in the dual space of the group	Convolution is the multiplication of functions on a Lie group.
Fejer kernel, smooth version of Dirichlet kernel	a standard Fourier series partial sum for a square wave. Near the discontinuity, it overshoots and oscillates, a phenomenon known as the Gibbs phenomenon. The Fejér kernel is a "smoother" version of the Dirichlet kernel, which is used for standard partial sums. The convolution with the Fejér kernel "blurs" the Gibbs phenomenon, resulting in a more regular and well-behaved approximation that converges uniformly
Baire category theorem, the real line as a space. The nowhere dense closed sets are like a countable collection of "isolated points." The Baire Category Theorem says that the real line cannot be written as a countable union of these "isolated points." It is a powerful result that says that the real line is "big" in a topological sense	In topology, the Baire Category Theorem is a result about the topological properties of a space. It states that in a complete metric space, every non-empty open set is of the second category. A set is of the first category if it is a countable union of nowhere dense sets. A set is of the second category if it is not of the first category. The theorem is a key tool for proving the existence of a wide range of objects. For example, the space of all real numbers is of the second category.
Baire category theorem, the real line R. A single point is nowhere dense. A countable union of points, like the rational numbers Q, is also nowhere dense. The theorem says you cannot "fill up" a complete space like R with a countable number of these "thin" sets. For instance, the union of all rational numbers is not a complete space. The set of integers Z is a countable union of nowhere dense sets, but it's not a complete space. The theorem applies to spaces that are "full," like the closed interval [0,1]. You can't write [0,1] as a countable union of sets whose closures have no interior	A complete metric space cannot be written as a countable union of nowhere dense sets. A set is nowhere dense if its closure has an empty interior.
Baire category theorem, an infinite number of linear transformations from R^2 to R. If you pick any single vector v and apply all these transformations to it, and the set of results is bounded, then the set of norms of the transformations themselves must be bounded. The Baire Category Theorem is used to show this	The Uniform Boundedness Principle (or Banach-Steinhaus Theorem) is a direct consequence of the Baire Category Theorem. It states that if a family of continuous linear operators from a Banach space to a normed space is pointwise bounded, then the family is uniformly bounded.
Baire category theorem, graph of a function is a way to visualize it. A closed graph means there are no "jumps" or "tears." The theorem says that for operators between complete spaces, having a "no-tear" graph is enough to guarantee that the operator is continuous. The Baire Category Theorem provides the machinery to prove this	The Closed Graph Theorem, which states that a linear operator between Banach spaces with a closed graph is continuous, can be proven using the Baire Category Theorem.
Baire category theorem, Open Mapping Theorem says that a surjective bounded linear operator doesn't "collapse" open sets into "thin" sets. The Baire Category Theorem is used to prove this by showing that the image of an open ball cannot be a countable union of nowhere dense sets	The Open Mapping Theorem, which states that a surjective bounded linear operator between Banach spaces is an open map, is also a consequence of the Baire Category Theorem.
Baire category theorem, a solid sphere. You cannot make a countable list of "flat" or "thin" closed convex sets (like lower-dimensional shapes) and have their union be the entire sphere	A closed convex set in a Banach space cannot be written as a countable union of nowhere dense closed convex sets.
Baire category theorem, rational numbers Q are a good example. They are a "meager" set, but their Lebesgue measure is zero. However, the Cantor set is a "nowhere dense" set, but it has measure zero. The Baire Category Theorem deals with the "meager" sets, not just the measure zero ones	The Baire Category Theorem is a topological analog of measure theory. A "meager" set (a countable union of nowhere dense sets) is a topological notion of a "small" set. A set of measure zero is a measure-theoretic notion of a "small" set.
Baire category theorem, Morse function has a finite number of non-degenerate critical points. The theorem says that you can get arbitrarily close to any smooth function with a Morse function. This is a powerful result because Morse functions are much easier to study than general smooth functions	The theorem is a tool for proving the existence of certain objects in spaces of functions on manifolds. For instance, the set of Morse functions is dense in the space of smooth functions on a compact manifold.
Baire category theorem, completeness means the space has "no holes." The theorem says that you cannot build up a whole, hole-less space by stacking up "thin" sets	The completeness of the space is a crucial assumption. The theorem fails for incomplete spaces. For example, the rational numbers Q are a countable union of singletons {q}, which are nowhere dense in Q.
Baire category theorem, Cantor set is formed by repeatedly removing the middle third of a line segment. The remaining set is "fractal" in nature. It's an example of a set that is nowhere dense but is not meager	The Cantor set is a classic example of a closed, nowhere dense set. It's a "thin" set that is uncountable.
Baire category theorem, a large space of possible input functions (forcing functions) for a PDE. The theorem can be used to show that the set of "bad" inputs that lead to non-unique or non-existent solutions is "small" in a topological sense	The theorem can be applied to the study of solutions to PDEs. For example, it can be used to show that for a "generic" forcing function, a PDE has a unique solution.
Open mapping theorem, a linear transformation in 2D space, represented by a matrix. The unit open disk in X is a circular region. A bounded linear map stretches and rotates this disk, but it remains a continuous, connected shape. If the map is surjective, it "covers" the entire target space Y. The key insight is that this stretching is powerful enough to ensure that the image of the unit disk, which is an open ellipse, contains an open ball in Y. This property generalizes	any open ball in X gets mapped to an open ellipsoid in Y that contains an open ball: A bounded linear surjective operator T: X to Y between Banach spaces X and Y is an open map. This means that for any open set U⊆X, the image T(U) is an open set in Y.
Open mapping theorem, map from R2 to R1. A projection, for example, (x,y)↦x, is a bounded, surjective linear map. However, it's not an open map because it maps the open unit disk in R2 to the open interval (−1,1) in R1, which is open. Now, consider a map from R3 to R2 that projects a 3D ball onto a 2D disk. This is a surjective bounded linear map, and it is open. However, if we were to map a 3D ball to a line segment in R3, the image is not open. The theorem says this "collapse" is impossible when both the domain and codomain are Banach spaces and the map is surjective. A surjective map between Banach spaces must preserve the "openness" property of sets	The theorem guarantees that a surjective bounded linear map between Banach spaces does not "collapse" open sets into lower-dimensional or "thin" sets.
Open mapping theorem, Sobolev spaces Hk(Ω) are Banach spaces. The Laplacian operator "smooths" functions. A surjective Laplacian operator means that for any "rough" function f in L2(Ω), there is a "smoother" function u in H2(Ω) such that Δu=f. The Open Mapping Theorem implies that small changes in the function f lead to small changes in the solution u (in their respective norms). The visual intuition is that the "roughness" of the solution u is controlled by the "roughness" of the source function f	The theorem applies to operators between function spaces. For example, consider the operator L = Δ (the Laplacian) mapping a subset of the Sobolev space H2(Ω) to L2(Ω). If the domain of this operator is well-defined and the operator is surjective, then it is an open map. This has profound implications for existence and regularity of solutions.
Open mapping theorem, Hilbert transform, for example, maps a function to another function. Imagine a function as a signal. The Hilbert transform shifts the phase of this signal by 90 degrees. If the operator is surjective, it means every possible phase-shifted signal can be produced. The Open Mapping Theorem guarantees that this process is "stable" – a small change in the input signal produces only a small change in the output signal	The theorem can be applied to operators acting on spaces like Lp or Hardy spaces. For example, a singular integral operator (like the Hilbert transform) might be a bounded linear operator from Lp(R) to itself. If it is surjective, the theorem applies.
Open mapping theorem, "nowhere dense" set is a set whose closure has an empty interior. It's "thin" everywhere. The Baire Category Theorem says that you can't build up a whole Banach space by adding up a countable number of these "thin" sets. The Open Mapping Theorem uses this principle to show that the image of an open ball, which is a union of such sets, must itself contain an open set, preventing the "collapse" into a thin set	The Open Mapping Theorem can be proven using the Baire Category Theorem. The Baire Category Theorem states that a complete metric space cannot be written as a countable union of nowhere dense sets. This is a very powerful result.
Open mapping theorem, system modeled by a linear operator. The theorem says that if the system can generate any output, then the relationship between input and output is "stable." A small error in the input will not cause a catastrophic, large error in the output. This is a crucial concept in numerical analysis and control theory	The theorem implies a form of stability. Small changes in the domain map to small changes in the codomain.
Open mapping theorem, closed range for the dual map means that the range of T′ is a "complete" subspace of X′. It contains all its limit points. This property is closely tied to the openness of the original map T	The theorem has a dual formulation related to the closed graph theorem. A continuous linear map T:X to Y is an open map if and only if its dual map T′:Y′ to X′ is injective and has a closed range.
Open mapping theorem, three theorems as a trinity that underpins the structure of linear operators on complete normed spaces. They guarantee that certain "good" properties (like continuity, openness, and completeness) hold under specific conditions	In operator theory, the theorem is one of the "big three" results (along with the Uniform Boundedness Principle and the Closed Graph Theorem) that characterize the behavior of linear operators on Banach spaces.
Open mapping theorem, dual space X′ of a Banach space X "probes" the space with continuous linear functionals. The Open Mapping Theorem ensures that there's a good correspondence between the properties of operators on X and the properties of their duals on X′	he theorem helps establish the relationship between a Banach space and its dual space (the space of all continuous linear functionals).
Open mapping theorem, map is "strong" enough to project open sets onto open sets. It's not like a projection from a 2D plane onto a line segment, which "loses" a dimension and collapses open sets to non-open ones	The theorem implies that if a bounded linear operator from a Banach space X to another Y is surjective, then it is "non-degenerate" in a certain sense. It doesn't "lose information" about the openness of sets.
Open mapping theorem, Fourier transform maps a function to its frequency components. It is a linear, continuous, and bijective operator on the Schwartz space. By the Open Mapping Theorem, its inverse is also continuous. This means that a small change in the function leads to a small change in its Fourier transform, and vice versa. This is a very useful property in signal processing	The Schwartz space of rapidly decreasing functions is a Fréchet space. The Fourier transform is an isomorphism from the Schwartz space to itself.
Open mapping theorem, completeness means that all Cauchy sequences converge. It's like a space without "holes." The theorem's conclusion relies on this property to ensure that the image of an open ball, which is a complicated set, is "well-behaved" enough to contain an open ball itself	The completeness of the domain and codomain (i.e., being Banach spaces) is a crucial prerequisite for the theorem to hold. The theorem fails for non-complete spaces.
Open mapping theorem, graph of a function is a visual representation of the function itself. A "closed graph" means that there are no "jumps" or "tears" in the function. The theorem states that for linear operators on Banach spaces, this property of having a "no-tear" graph is equivalent to being bounded. This is a very powerful result, as it allows us to check for continuity by simply checking the "completeness" of the graph	The Open Mapping Theorem is a dual of the Closed Graph Theorem. The Closed Graph Theorem states that a linear operator T:X to Y between Banach spaces is bounded if its graph, G(T)={(x,Tx) for x in X}, is a closed subspace of X×Y.
Bounded inverse theorem, a bijective map. For every point y in Y, there is a unique x in X. This is a one-to-one correspondence. The Bounded Inverse Theorem says that if this map is continuous (it doesn't "tear" things apart), then its inverse is also continuous (the reverse process also doesn't "tear" things apart). A linear transformation in R2 that maps a square to a parallelogram is a good example. The inverse map, which maps the parallelogram back to the square, is also a continuous linear transformation	A direct consequence of the Open Mapping Theorem is the Bounded Inverse Theorem: if a bijective bounded linear operator T:X to Y between Banach spaces has a continuous inverse T−1:Y to X.
Hahn-Banach theorem, linear functional on a subspace as a hyperplane in a small part of a normed vector space. The Hahn-Banach theorem says that this hyperplane can be "extended" to a larger hyperplane that spans the entire space without becoming "steeper." This is a geometric intuition that visualizes the extension of a linear functional as the extension of a hyperplane	The Hahn-Banach theorem states that for any normed vector space, any linear functional on a subspace can be extended to a linear functional on the whole space without increasing its norm. This is a fundamental result in functional analysis that guarantees the existence of a "sufficiently rich" set of linear functionals. For example, a linear functional on the subspace of continuous functions on [0,1] that vanish at 0 can be extended to the entire space of continuous functions on [0,1].
Hahn-Banach theorem, two disjoint convex sets, like a circle and a triangle. The Hahn-Banach theorem says that you can draw a straight line that separates them. This is a very powerful geometric intuition that visualizes the separation of convex sets	A geometric form of the Hahn-Banach theorem states that if A and B are two non-empty disjoint convex subsets of a normed vector space, and at least one of them is open, then there exists a closed hyperplane that separates them. This is a powerful result that is used to prove a wide range of separation theorems. For example, two disjoint balls in a normed vector space can be separated by a hyperplane.
Hahn-Banach theorem, optimization problem is about finding the "best" point in a set. The Hahn-Banach theorem says that if a point is outside of a convex set, you can find a "hyperplane" that separates them. This is a key step in finding the "best" point	The Hahn-Banach theorem is a key tool in optimization theory. It is used to prove the existence of a separating hyperplane between a convex set and a point outside of it. This is a key tool for finding the optimal solution to an optimization problem.
Hahn-Banach theorem, linear function f(x) defined only on a line segment M in a plane R2 that lies "below" a convex curve p(x) (e.g., a parabola). The theorem says we can extend this line segment into a full line F(x) that still stays "below" the convex curve p(x) for the entire plane. This is like drawing a tangent line to a curve from a point within a subspace	Let X be a real vector space, p: X to R a sublinear functional, and M in X a linear subspace. If f:M to R is a linear functional such that f(x) less than p(x) for all x in M, then there exists a linear extension F:X→R such that F(x) less than p(x) for all x in X and F|M​ = f.
Hahn-Banach theorem, the most geometrically intuitive form. It states that two disjoint convex sets can be separated by a hyperplane. In R2, this means two convex shapes that don't overlap can be separated by a line. In R3, they can be separated by a plane. The functional f defines the normal vector to the separating hyperplane, and c defines its position. For example, consider two non-overlapping circles. The theorem guarantees you can always draw a straight line that separates them	Let  A, B be two non-empty, disjoint convex subsets of a normed linear space X. If A is open, then there exists a continuous linear functional f : X to R and a real number c such that f(a) < c <= f(b) for all a in A and b in B.
Hahn-Banach, dual space X∗ is "rich" enough to "see" every vector. The functional f acts as a perfect "measuring stick" for the vector x0​. It measures the length of x0​ precisely while keeping its own "size" normalized to 1. For example, if x0​ is a vector in R3, there's a functional (a linear map from R3 to R) that points exactly in the direction of x0​ and measures its length	For any non-zero vector x0​ in a normed space X, there exists a continuous linear functional f in X∗ (the dual space of X) such that norm of f =1 and f(x0) is norm of x0​.
Hahn-Banach theorem, you have a rule to measure the length of all intervals on the real line. The theorem implies you can extend this rule to a much larger class of "measurable" sets (like the Borel sets) without any contradictions, so long as the original rule was well-behaved	the theorem can be used to extend a measure (a way of assigning size to sets) from a smaller algebra of sets to a larger one.
Hahn-Banach theorems, a closed, solid ball in a very abstract space. If you have a point outside this ball, the theorem says you can find a "hyperplane" that separates the ball from the point. The "hyperplane" is defined by a continuous linear functional. This shows that the separation principle isn't just a Euclidean concept; it's a fundamental property of well-behaved topological spaces	The theorem extends to more general topological vector spaces, specifically locally convex spaces. In these spaces, it guarantees that a closed convex set can be separated from a point not in the set by a continuous linear functional.
Hahn-Banach theorem, Dirac delta "function" is an infinite spike at x=0. It's not a function in the classical sense. It's a functional that "selects" the value of a function at x=0. The theorem guarantees the existence of such a functional on the space of test functions, showing that these strange, non-function objects can be constructed and exist in a precise mathematical sense	The Dirac delta function d(x) is a distribution, which is a continuous linear functional on a space of test functions, like the Schwartz space S(R). The Hahn-Banach theorem ensures the existence of such functionals.
Hahn-Banach, Hahn-Banach theorem guarantees that a functional exists, while the Riesz theorem gives it a concrete form in a Hilbert space. The Riesz theorem says that the "measuring stick" is a specific vector, whereas Hahn-Banach just says that some measuring stick exists	The Riesz Representation Theorem states that for a Hilbert space, every continuous linear functional can be represented as an inner product with a vector.
Uniform Boundedness Principle, a family of linear maps from a vector space to another, represented by "rubber bands." The Uniform Boundedness Principle says that if for every single point in the source space, the set of images of that point under all the rubber bands is contained within a finite disk, then there's a single, large disk that contains the images of the entire unit ball under all the rubber bands. The pointwise boundedness prevents any single rubber band from stretching to infinity. The theorem ensures that this boundedness extends to the whole family of rubber bands	The Uniform Boundedness Principle (also known as the Banach-Steinhaus theorem) states that for a family of continuous linear operators from a Banach space X to a normed vector space Y, if the operators are pointwise bounded, they are uniformly bounded. That is, if for each x in X, the set {T(x):T in F} is bounded, then the set of operator norms {||T||:T in F} is bounded. This theorem is a cornerstone of functional analysis, providing a powerful way to deduce uniform properties from pointwise ones. For example, for a family of continuous linear operators Tn​:C([0,1]) to R, if for each function f in C([0,1]), the sequence Tn​(f) is bounded, then the sequence of norms ||Tn​|| is bounded.
Uniform boundedness principles, the Fourier series of a function as a sum of waves. The partial sums are a family of linear operators. The Uniform Boundedness Principle says that if the sequence of partial sums of the Fourier series of a function is bounded for every function, then the family of partial sum operators is uniformly bounded. This is a visual way of saying that the "oscillations" of the partial sums are not "growing" without bound	The Uniform Boundedness Principle can be applied to families of operators in harmonic analysis, such as Fourier series. For a family of convolution operators Tn​(f)= f ∗K_n​, if the sequence Tn​(f) is bounded for every function f in a suitable space, then the family of operator norms ||Tn​|| is bounded. This is a key tool for proving convergence of Fourier series. For example, the Dirichlet kernel in Fourier series is not uniformly bounded, which implies that the Fourier series of a continuous function may fail to converge pointwise.
Uniform boundedness principle, a Banach manifold is a "generalized" manifold. The Uniform Boundedness Principle says that a family of linear maps between the tangent spaces is uniformly bounded if it is pointwise bounded. This is a visual way of saying that the manifold is "well-behaved" in a uniform way	In global analysis, the Uniform Boundedness Principle can be used to prove the existence of a continuous linear map from a Banach manifold to another. A Banach manifold is a manifold that has a Banach space as a tangent space at each point. The Uniform Boundedness Principle is a key tool for studying the geometry of these manifolds.
Uniform boundedness principle, in Fréchet space is a "nicer" topological vector space. The Uniform Boundedness Principle says that in a "nicer" space, pointwise boundedness of a family of linear maps implies that the maps are "equally well-behaved." This is a visual way of saying that the maps are not "exploding" in a way that is not controlled	There are stronger versions of the Uniform Boundedness Principle that hold for more general topological vector spaces, such as Fréchet spaces. A Fréchet space is a complete, metrizable, locally convex topological vector space. For a family of continuous linear maps from a Fréchet space to a locally convex space, if the maps are pointwise bounded, then they are equicontinuous.
Weak solutions of differential equations, imagine trying to solve a PDE on a domain. You can't find a perfectly smooth solution, but you can find a "bumpy" function that satisfies the equation in an average, integrated sense. The theorem guarantees the existence of a "probe" (the test function) that "tests" the solution and confirms its validity in this weaker sense. The probe is a functional that measures the solution's properties	The theorem is used to prove the existence of weak solutions to partial differential equations. A weak solution is not necessarily differentiable in the classical sense, but it satisfies the equation when integrated against a "test function."
Abelian variety, projective variety that is a group	one can see this via the chord tangent process on x^3 + y^3 = 9 since a + b + c = 0, a, b, c collinear. Not birational to the affine line A^1 since it has genus 1 not 0 as a Riemann surface. Projective coordinates (x, y, z) mod lambda or x^3 + y^3 = 9z^3, z is not 1. Associativity is hard to prove directly, follows from sum of a_1 to a_n = sum of b_1 to b_n if and only if there is a rational function with zeroes at 'a's, poles at 'b's.
Abelian varieties, varieties that are abelian contrasting symplectic groups	a proof strategy for complex numbers, any map from projective variety to the complex numbers is constant by the maximum principle, so the adjoint map to the automorphism group of tangent space of origin is 0. Abelian linear groups are not abelian, this is old names for symplectic group, an affine algebraic group.
Enumerative geometry, surprising answers with scheme theory	27 lines on cubic surface is a classical example, example w^3 + x^3 + y^3 + z^3 = 0 in projective spaceP^3, typical line is (1, -1, t, -t), the order is 3^3 * 4! (exercising), surprisingly when this is thought of a group, there are 27 images under this group, acted on permutation group.
Hausdorff condition, affine line over field is not Hausdorff	affine line over field k is not Hausdorff, counterexample, consider set of generic point in V(I) for variety of ideal I. If this is the case, then the ideal I is in the zero ideal, the algebraic set cut out is the affine line, therefore the closure of the generic point is the whole affine line, this means there exists a nonclosed point {0}. The topological space is not Hausdorff, but the affine line over k is separated as a scheme.
Stalk, germ of section	Germ is equivalence class of section on open neighbourhood, same section if agree on smaller, stalk of sheaf is set of all germs
Stalk, local data	captures local data
Stalk, colimit of sections over all open neighbourhoods	formalises closer and closer to the point, related to germs equivalence class if agree on smaller neighbourhood
Stalk, extension of section	set of all possible ways to germ-wise extend a section, recall that the stalk is the filtered colimit to some point.
Stalk, colimit algebra	colimiting object of directed system of restriction maps on the sheaf sections
Stalk, functorial construction	Functor from sheaves to category of algebraic objects (etale space, use sets, but generalises to groups and rings). Maps a sheaf to collection of stalks
Stalk, homomorphism of sections over neighbourhood to stalk	map from section over neighbourhood of p to the stalk is universal homomorphism respecting restriction maps
Stalk, local rings	sheaf of rings on a scheme, stalk at point p is local ring with a unique maximal ideal
Stalk, adjoint to constant sheaf functor. Recall that you can first look at a section from the constant sheaf to the codomain to turn it into a stalk functor into a representable functor	constant sheaf functor is left adjoint to stalk functor, see example of stalk of sheaf F on local U is stalk morphism on U as constant sheaf to sheaf F. Recall that you can first look at a section from the constant sheaf to the codomain to turn it into a representable functor of the stalk.
Stalk, geometric point as a ringed space	ringed space, whose ring is a field
Stalk, irreducible components or points	stalk is field, point is closed (maximal ideal), stalk is integral domain, irreducible component (prime ideal)
Stalk, local property on manifold	stalk of sheaf of smooth function, germs of smooth function
Stalk, pointwise sheaf	Sheaf is completely determined by its stalks and restriction maps between sections
Stalk, gluing	compatability of sections checked on level of stalks
Stalk, filtered colimit	filtered colimit over the category of open neighbourhood of a point
Stalk, fibre of point of cospan	Fibre of cospan, so it is a pullback
Stalk, localised object	localisation of sheaf with respect to multiplicative set of non-vanishing functions at a point
Stalk, representation of presheaf under sheafification	stalk, sheafification of presheaf at a point p is identical to the stalk of the original presheaf at p. Sheafification only changes global glueing.
Section, right inverse	Right inverse of a map f * s is identity on codomain, s is section
Section, choice function	Choose single element from each preimage set by having the section be applied first
Section, splits a surjection	section for surjection means codomain can be embedded back into the domain.
Section, embedding	embedding of codomain in domain. Codomain is now subobject of domain
Section, continuous maps for each point in fibre to base space (global slice)	section is continuous map that assigns a point in the fibre to each point in the base space (codomain) a.k.a fibre bundle
Section, direct sum	Category of modules, map has section, means can be composed as direct sum domain M is isomorphic to ker(f) ++ im(s), ++ direct sum, splitting lemma
Section, basis of free modules	surjective module homomorphism from free module F to module M, section is choice of basis in codomain M that can be lifted to generators for F
Section, representation of coset	f: G -> H, H is coset space, section s: H to G, choses unique element from each coset of the kernel in the domain group G
Section, projective object	module P is projective if every surjection on module P has a section
Section, homomorphism	section for homomorphism means it has trivial cokernel, domain splits into direct sum
Section, inverses to compare section versus retractions	section is a map that has a right inverse retraction, map that has left inverse Context: model categories
Section, short exact sequence	0 -> A -> B -> C -> 0, splits if B -> C has a section
Section, morphism in slice category (see also functor of point construction with base scheme [or base category of Set to get scheme maps], here you have a base category)	Section of f from X to Y is object in slice category over Y
Section, global section of a sheaf	Section of entire space is global section of the sheaf
Section, sheaf morphism when considering section of sheaf F over U, and constant sheaf of U, to make this representable	Section of a sheaf F over open U is sheaf morphism from constant sheaf of U to sheaf F, representable, recall that it is the step before thinking about the domain (which in this case it is the sheaf F over U)
Section, projective variety	section of line bundles on projective variety, map from variety into projective space
Section, vector field as sections of the tangent bundle	Vector field is section of tangent bundle (imagine fibres extending out of a tangent line), assigned to each tangent vector of manifold in a smooth way
Germ, equivalence class	germ of a function at a point p is an equivalence class of functions, where the equivalence relation is defined by f is equivalent to g if there exists an open neighborhood U of p on which f and g are equal.
Germ, stalk of presheaf	collection of all germs of a presheaf F at a point p forms an algebraic object called a stalk, denoted Fp​. This is the direct categorical definition.
Germ, direct limit	stalk (as collection of all germs) of a presheaf at a point p is the direct limit of the values of the presheaf on all open neighborhoods of p. The direct limit formalism gives a precise categorical construction of the stalk.
Germ, local ring	local ring at a point of a scheme is the ring of germs of regular functions at that point. This is a fundamental link between germs and local rings.
Germ, sheaf of rings	local ring at a point p of a scheme is the stalk of the sheaf of rings OX​ at p, where the "functions" are regular functions.
Germ, function on neighbourhood	function defined on an "infinitesimal neighborhood" of a point, a concept made precise by the direct limit.
Germ, of morphisms	germs of morphisms between topological spaces are equivalence classes of continuous maps that agree on a neighborhood of a point.
Germ, algebraic	germ can be defined in a purely algebraic way as an element of a local ring, without explicit reference to topological neighborhoods.
Germ, local property	germ embodies the local property of an object or function at a point. It discards all global information and focuses solely on the behavior near a single point.
Germ, stalk of a complex	stalk generalizes to complexes of sheaves, where the stalk of a complex is a complex of modules.
Germ, homological stalk	suppose you have a complex of sheaves F^, its homological stalk at a point p is the stalk of the homology sheaf, denoted Hq​(F^)p​.
Germ, stalks as derived functor of the global sections functor	stalk (recall that stalks are collections of germs) functor, which takes a sheaf to its stalk, is the derived functor of the global section functor.
Germ, etale sheaf	étale cohomology, the concept of a stalk is generalized to an étale stalk, where the neighborhoods are not just Zariski open sets, but are more general étale neighborhoods.
Germ, spectra of a ring spectrum	"local ring" at a prime of a ring spectrum is defined using a homotopical localization process, where a germ of a function corresponds to an element in the localized ring spectrum.
Sheaf, generalises continuity	generalises continuity by ensuring local data can be smoothly and consistently patched together with no issues
Sheaf, generalises continuous functions	Instead of assigning a value, assign a set of sections to each open set.
Sheaf, abstraction of vector bundles	Local trivialisations are sections, transition maps are restrictions
Sheaf, as a functor	From category of open sets of a topological space, inclusions as morphisms to other category
Sheaf, etale space, etale looks like locally	Sheaf isa sheaf of sections of an etale space, etale space locally looks like a product of open set and discrete space OR local homeomorphism
Sheaf, model of constructive logic	Proposition is considered true if it has a proof consistent across all local domains
Generic point, affine line A_k^1​ as a one-dimensional space. The closed points correspond to the roots of the polynomials. The generic point is a special, non-closed point that "sees" all the other points. It can be visualized as a "shadow" of all the other points. It is not a specific point, but a concept that captures the "generic" behavior of the scheme	In algebraic geometry, a generic point of an irreducible scheme X is a point whose closure is all of X. For an affine scheme X=Spec(R), the generic point corresponds to the zero ideal (the set of all functions that are zero everywhere on the scheme). This point "sees" all the other points in the scheme. For example, the affine line A_k^1​ has a generic point corresponding to the zero ideal in the polynomial ring k[x].
Generic point, ring of polynomials k[x] as a geometric object. The prime ideals are the "points" of the object. The generic point is a special point that is "contained" in every other point. It is a "shadow" of all the other points	In commutative algebra, a generic point of a variety corresponds to the zero ideal in the ring of functions on the variety. This point is a prime ideal that is contained in every other prime ideal. It is the minimal prime ideal of the ring. For example, the ring of polynomials k[x] has a generic point corresponding to the zero ideal.
Generic point, the number field Q as a single point. The generic point is this point. The prime ideals are the "closed" points. The generic point is the "unclosed" point that sees all the other points	In number theory, the generic point of the spectrum of the ring of integers of a number field is the zero ideal. This point corresponds to the field itself. It is the "generic" point of the number field.
Generic point, category as a collection of objects with arrows between them. A generic object is an object that has an arrow to every other object. It is a "universal" object	In homological algebra, the concept of a generic point can be generalized to the concept of a "generic object" in a category. A generic object is an object that is "contained" in every other object.
Pushforward, vector on the surface of a sphere. If we have a map from the sphere to a plane (e.g., a map projection), the pushforward is how that vector "stretches" or "squashes" as it's projected onto the plane. The direction and magnitude of the projected vector are the pushforward	in differential geometry, the pushforward of a tangent vector is the map induced by a smooth function between two manifolds. For a smooth map f: M to N, the pushforward f∗​ maps a tangent vector at a point p in M to a tangent vector at the image point f(p) in N.
Pushfoward, group of rotations of a square. We can represent these rotations as 2 by 2 matrices. If we rotate our coordinate system, the matrices change. The pushforward is the new set of matrices that describes the same rotations in the new coordinate system	In group theory, the pushforward can be seen as the change of basis for a representation. If we have a representation p: G to GL(V), and we choose a new basis for V using a change-of-basis matrix T, the new representation is the pushforward of p by T.
Pushfoward, map from a torus to a sphere. The fundamental group of the torus is Z ++ Z, and the fundamental group of the sphere is trivial. The pushforward map sends any loop on the torus to a contractible loop on the sphere. The pushforward tells you how the "holes" of one space get mapped to the "holes" of another	In homotopy theory, a continuous map f: X to Y induces a pushforward map f∗​: pi_n​(X) to  pi_n​(Y) on the homotopy groups. This map sends an n-sphere in X to an n-sphere in Y.
Pushfoward, map from a solid torus to a solid cylinder. The pushforward maps the cycles of the torus (e.g., the longitude and meridian) to cycles of the cylinder. The homology of the torus is non-trivial, while the homology of the cylinder is non-trivial for loops, but trivial for 2-cycles. The pushforward tells you how the "holes" of one object are mapped to the "holes" of another	In homological algebra, a continuous map f:X→Y induces a pushforward map f∗​:H_n​(X,A) to H_n​(Y,f(A)) on homology groups. This is a covariant functor.
Pushfoward, module is like a vector space over a ring. The pushforward is the new vector space we get when we extend the ring. For example, extending the scalars from the integers Z to the rational numbers Q. We are "pushing forward" the integer vectors to become rational vectors	In non-commutative ring theory, the pushforward can be seen as the induction of a module. If we have a module M over a ring R and a ring homomorphism p: R to S, the pushforward is the new module S tensor_R ​M over the ring S.
Pushforward, sheaf is a way of assigning data to open sets of a space. The pushforward is how that data is "pushed" from one space to another. For example, a map from a sphere to a point collapses all the data on the sphere to a single point	In algebraic geometry, a map of schemes f: X to Y induces a pushforward functor f∗​: Sh(X) to Sh(Y) from the category of sheaves on X to the category of sheaves on Y. It's a way of transporting sheaves along a map.
Pushforward, ideal can be thought of as a collection of lattice points. The pushforward is the new collection of lattice points that we get by extending the number field. The pushforward "spreads out" the ideal to a larger field	In arithmetic number theory, the pushforward of an ideal from a number field K to a number field L (where K is in L) is the ideal of L generated by the ideal of K.
Pushforward, module for a group is like a vector space with a group action. The pushforward is the new vector space we get by "blowing up" the representation to a larger group	In modular representation theory, the pushforward is the induction of a module. If H is a subgroup of G and M is a module for F_p​[H], the pushforward is the induced module Ind_H^ G ​M = F_p​[G] tensor_{F_p​[H]} ​M.
Pushforward, coherent sheaf can be thought of as a family of vector spaces over a variety. The pushforward is the new family of vector spaces we get when we "push" the variety onto a new space	In algebraic geometry, a map of schemes induces a pushforward functor for coherent sheaves. This is a very powerful tool that allows us to move geometric objects from one space to another.
Pushforward, vector field on a sphere. The pushforward is the new vector field on a plane that you get by projecting the sphere onto the plane. The vectors are "pushed" to new locations	In differential geometry, the pushforward of a vector field X on a manifold M to a vector field Y on a manifold N is defined such that it satisfies a specific commutativity property with the map f: M to N.
Presheaf, visual intuition, space with open patches on it	for a space, say a sphere, with open patches on it. A presheaf assigns a set of "functions" to each patch. For example, for a presheaf of smooth functions, each patch has all the smooth functions defined on it. As you move from a larger patch to a smaller one inside it, you just "restrict" your functions to the smaller patch.
Scheme, ring spectrum	irreducibles of an affine scheme (but in this case points) of Spec(R) are the prime ideals of R, and the topology, known as the Zariski topology, is defined by the closed sets corresponding to the vanishing loci of ideals.
Scheme, locally ringed space	topological space equipped with a sheaf of rings, called the structure sheaf, such that the stalks are local rings. This structure captures the local properties of the geometric object.
Scheme, gluing	gluing process is defined by an isomorphism of locally ringed spaces over the intersections of the open sets.
Scheme, ring of regular functions	ring of regular functions on an affine scheme Spec(R) is precisely the ring R itself. This establishes a deep correspondence between rings and affine schemes.
Scheme, generic point	irreducible closed subset of a scheme has a unique generic point, which is the point whose closure is that entire subset. This concept generalizes the notion of a generic point of an irreducible variety.
Scheme, reduced	reduced if its structure sheaf has no nilpotent elements in its stalks. Geometrically, this means the scheme has no "infinitesimal fuzziness."
Scheme, projective	projective scheme is a scheme that can be embedded in a projective space, which is constructed from a graded polynomial ring. These are the algebraic counterparts of projective varieties.
Scheme, motivation	study sets of solutions to polynomial equations over any commutative ring, not just algebraically closed fields. This allows algebraic geometry to be applied to number theory.
Scheme, category of schemes	morphisms are maps of locally ringed spaces that are compatible with the ring structure.
Schemes, derived	derived algebraic geometry that generalizes a scheme by allowing its structure sheaf to be a sheaf of differential graded algebras or commutative ring spectra. This framework is crucial for studying derived moduli spaces.
Schemes, stacks	scheme, which allows for families of objects with symmetries. A scheme is a special case of a stack.
Scheme, local ring as functors	local rings of a scheme can be defined as a functor on the category of affine schemes, which provides a categorical view of localization.
Scheme, etale sheaves	étale cohomology, schemes are studied using sheaves on the étale site, which is a more refined topology than the Zariski topology. This is key for studying arithmetic properties.
Scheme, ring spectra in homotopy theory	concept of the prime spectrum Spec(R) is generalized to the spectrum of a ring spectrum, which is a "space" that reflects the homotopical properties of the ring.
Scheme, homological	homological scheme is an object in homological algebra whose structure is given by a complex of modules. This is a first step towards derived schemes.
Schemes, A-infinity spaces	generalized to objects in the category of A_infinity-spaces, which are a kind of "homotopy-coherent" ring.
Schemes, functor of points	functor from the opposite category of affine schemes to the category of sets taking affine schemes to set of scheme maps
Schemes, formal scheme	scheme that has been "infinitesimally thickened." This concept is used in formal geometry to study local properties of schemes near a point or a subscheme.
Generic point, dense point	point p in a topological space X is a generic point if its closure, {p}​, is the entire space X.
Generic point, point of irreducible algebraic variety	irreducible algebraic variety has a unique generic point. This point is the set of all polynomials that vanish on the variety.
Generic point, prime ideal	algebraic counterpart of a generic point of an irreducible affine variety is a prime ideal of its coordinate ring. A prime ideal p is a generic point of the irreducible closed set V(p).
Generic point, minimal prime ideal	prime ideal is a generic point of its closure if and only if it is a minimal prime ideal.
Generic point, context of spectrum of a ring	context of the spectrum of a ring Spec(R), the points are the prime ideals. The generic point of an irreducible component is the prime ideal that corresponds to it.
Generic point, generic property	property is true "at the generic point" if it holds for the entire irreducible variety except for a lower-dimensional subset. This is a powerful way to make statements about the "general" case.
Generic point, generic filter	generic point of an algebraic variety corresponds to a generic filter on the lattice of ideals of the coordinate ring.
Generic point, dimension zero	dimension zero in the Zariski topology, meaning it does not have any proper non-empty closed subsets.
Generic point, stack	generic point is a point that is dense in a stack. The concept is more complex as it involves the presence of automorphisms at the point.
Generic point, derived	derived generic point is a point that is dense in a derived scheme. This concept is richer as it captures homotopical information.
Generic point, equivalent in localisation	two objects are equivalent "at the generic point" if they are equivalent in the localization of the category at that point.
Generic point, prime spectrum in spectral algebraic geometry	the points of the prime spectrum of a ring spectrum are the prime ideals. The generic points of the irreducible components are the minimal prime ideals.
Integral scheme, reduced and irreducible	scheme is integral if and only if its underlying topological space is irreducible and its structure sheaf has no non-zero nilpotent elements in its stalks.
Integral scheme, definition for affine schemes via integral domain	affine scheme Spec(R) is integral if and only if the ring R is an integral domain. This is the most fundamental algebraic definition.
Integral scheme, generic point	unique generic point, which is a point whose closure is the entire scheme. This point corresponds to the zero ideal of the coordinate ring.
Integral scheme, no infinitesimal fuzziness, single piece	geometrically "clean." The "reduced" property means it has no infinitesimal fuzziness or non-trivial higher-order behavior at any point. The "irreducible" property means it is a single piece with no "cracks."
Integral scheme, subscheme of a variety	irreducible algebraic variety is an integral scheme. This is how the concept generalizes to modern algebraic geometry.
Integral scheme, function ring	ring of regular functions on a connected component of an integral scheme is an integral domain.
Integral scheme, morphisms to affine line	set of morphisms from an integral scheme to the affine line A1 can be identified with the ring of regular functions on the scheme, which is an integral domain.
Integral scheme, dimensions	non-empty affine integral scheme has a well-defined dimension, which is the Krull dimension of its coordinate ring.
Integral scheme, reduced means nilradical vanishing	scheme is reduced if and only if its nilradical is zero. The nilradical is the ideal of all nilpotent elements.
Integral scheme, intersection of components	integral scheme cannot be written as the union of two or more proper closed subschemes. Geometrically, it means it is not a composite object.
Integral scheme, derived integral scheme	integral scheme is a scheme with a structure sheaf of derived algebras that is "homotopically integral." This means the derived ring has no non-trivial derived nilpotents.
Integral scheme, homotopically reduced	homotopically reduced if its structure sheaf has no homotopical nilpotents. These are elements that are "eventually zero" in a derived sense.
Integral scheme, homotopically irreducible	derived scheme is homotopically irreducible if its prime spectrum is a single connected component in a homotopical sense.
Integral scheme, prime spectrum of integral ring spectrum	integral scheme generalizes to the prime spectrum of an integral ring spectrum, which is a ring spectrum whose prime spectrum is irreducible.
Integral scheme, Homological duality	important in homological algebra because they admit strong homological properties, such as being Gorenstein or Cohen-Macaulay, which are properties of their local rings.
Integral scheme, generic flatness theorem	generic point of an integral scheme is used to formulate the generic flatness theorem, which states that a module over a Noetherian integral domain is locally free on a dense open set.
Integral scheme, function field	field of fractions of its coordinate ring. This is a fundamental invariant that captures the generic properties of the scheme.
Normal scheme, normal Noetherian integral domains	Noetherian integral domain R is normal if it is integrally closed in its field of fractions. This means any element of the field of fractions that is a root of a monic polynomial with coefficients in R must already be in R.
Normal scheme, integrally closed where concept of being normal is a refinement of integrality	ring is integrally closed if it contains all the "algebraic integers" from its field of fractions.
Normal scheme, definition of local domains	scheme X is normal if all its local rings are normal domains. This means the scheme is "normal at every point."
Normal schemes, regular local ring and normal rings	regular local rings is always a normal ring. Geometrically, a smooth scheme is always normal.
Normal scheme, unmixed dimension of irreducible components	all their irreducible components have the same dimension.
Normal scheme, Krull's criterion (with two conditions) on Noetherian integral domains	Noetherian integral domain is normal if and only if it satisfies two conditions: it is a Krull domain and it is a unique factorization domain (UFD).
Normal scheme, singularity analogy	normal singularity is a singularity that is "as mild as possible" in the sense that it has no "infinitesimal" or "sub-dimensional" components that are not accounted for.
Normal scheme, definition commutative factorial ring or unique factorisation domain	commutative ring is a factorial ring, or a unique factorization domain (UFD), if every non-zero, non-unit element can be written as a product of prime elements, and this factorization is unique up to order and units.
Normal scheme, prime means irreducible in factorial ring	factorial ring, every prime element is irreducible. This simplifies the study of factorization.
Normal scheme, regular implies factorial links smoothness to unique factorization	regular local ring is a unique factorisation domain / factorial ring. This is a fundamental result that links smoothness to unique factorization.
Normal scheme, normality as no bumps where cone example as not normal	normal variety or scheme has no "bumps" or "creases" of codimension one. For example, a cone is not normal at its vertex, as it is singular there.
Normal scheme, factoriality as algebraic and geometric (geometric visualising unique decomposition)	factoriality is a purely algebraic property that corresponds to a very strong geometric property: the unique decomposition of functions into prime functions.
Normal scheme, codimension 1 condition of Noetherian domains	Noetherian domain is normal if and only if it satisfies a few conditions on its prime ideals of height one, which are analogous to subvarieties of codimension one.
Normal scheme, normality is a local property on the level of stalks of a scheme	scheme is normal if and only if all its stalks are normal domains. This means we can check for normality "locally."
Normal scheme, uniqueness of irreducible components	factorial ring corresponds to a geometric object where functions have a unique decomposition into irreducible components.
Normal scheme, smoothness/regular as stronger than normality and factoriality	normality and factoriality are consequences of a scheme being smooth (or regular). Normality is a weaker condition than regularity, and factoriality is a weaker condition than regularity.
Normal scheme, Cohen-Macaulay	Normal and factorial rings are a special case of Cohen-Macaulay rings, which have nice homological properties.
Morphism of schemes, continuous map with ring homomorphism	a morphism of a schemes, it is a map of topological spaces and map of sheaves of rings
Morphism of schemes, collection of locally affine morphisms for each open subset in codomain	a collection of locally affine morphisms of affine schemes for each open subset in codomain that are glued together
Morphism of schemes, contravariant functor from category of rings	contravariant functor from category of rings to the category of affine schemes, maps of affine schemes Spec(B) to Spec(A) corresponds to ring homomorphism A to B.
Morphism of schemes, functor of points relative to a base scheme	a map of morphism of schemes from X to Y can be understood as how it acts on all possible morphisms from other schemes T to X and Y
Morphism of schemes, closed immersion	a closed immersion is a morphism that embeds a scheme as a closed subscheme, map from scheme X to scheme Y that is a homeomorphism onto a closed subset of Y, and induces a surjetive map on the sheaves
Morphism of schemes, open immersion	morphism that embeds a scheme as an open subscheme. It is a homeomorphism onto an open subset of the target scheme. This allows us to think of affine schemes as the basic building blocks that are glued together to form a general scheme.
Morphism of schemes, flat morphisms	induced map on local rings makes the target a flat module over the source. Geometrically, this means the fibers of the morphism are "well-behaved" and don't experience "unexpected jumps" in dimension. Think of a family of schemes parameterized by Y where the fibers have a consistent dimension.
Morphism of schemes, smooth morphisms	smooth morphism is a flat morphism whose fibers are "geometrically nice" or smooth manifolds. This is the algebraic counterpart of a submersion in differential geometry. A smooth morphism has no singular points in its fibers.
Morphism of schemes, etale morphisms	flat, unramified morphism. Geometrically, it is an algebraic analog of a local isomorphism in topology. It preserves the local ring structure and is key to defining étale cohomology for schemes.
Morphism of schemes, finite morphisms	finite morphism if it is affine and the induced map on rings makes the source a finitely generated module over the target. This is the algebraic analog of a finite covering map in topology.
Morphism of schemes, proper morphisms	proper morphism is the algebraic counterpart of a compact map in topology. A morphism is proper if it is separated, of finite type, and universally closed.
Morphism of schemes, chain maps	chain map between chain complexes. A chain map is a sequence of module homomorphisms that commutes with the differentials. This preserves the homological structure of the complexes.
Morphism of schemes, derived morphisms	a derived morphism between derived schemes is a morphism of the corresponding ring spectra. These maps are defined up to homotopy and are much more flexible than classical morphisms.
Morphism of schemes, morphism of stacks	stacks is a more general type of morphism that allows for maps that have nontrivial automorphisms. This is a key concept in moduli theory, where the objects can have symmetries.
Morphism of schemes, morphism of ring spectra	morphism of ring spectra is a map that preserves the multiplicative and additive structure up to homotopy. This is a powerful tool for studying higher algebraic structures.
Moduli space, space of geometric objects	geometric space whose points are in one-to-one correspondence with isomorphism classes of some type of geometric or algebraic object. For example, a point in the moduli space of ellipses represents a unique ellipse.
Moduli space, moduli problems	moduli problem is the task of classifying a collection of objects. For example, the problem of classifying all elliptic curves is a moduli problem. The solution is the moduli space.
Moduli space, fine moduli space	moduli space that has a "universal object." This is a single object that lives over the moduli space itself, and any other object in the collection can be obtained by pulling back this universal object. This is a very strong, and rare, condition.
Moduli space, coarse moduli space	course moduli space is a moduli space that classifies the objects set-theoretically but doesn't have a universal object. It's a "near perfect" catalog, but it may not have a single master object from which all others can be built.
Moduli space, orbit space	constructed as a quotient space or an orbit space of a larger space by a group action. Think of the space of all possible shapes, and you "mod out" by a group of transformations (like rotations and translations) that leave the shape unchanged.
Moduli space, stable object	moduli spaces often classify "stable" objects. Stability is a technical condition that ensures the objects are well-behaved and have a finite automorphism group. This helps in forming a geometric quotient.
Moduli space, moduli stack	moduli stack is a generalization of a moduli space that accounts for objects with non-trivial automorphisms. It's like a moduli space, but with "extra data" at each point that tells you about the symmetries of the object.
Moduli space, catalogue of symmetry data	catalog of shapes, but on each page, there is a small diagram showing the symmetries of that particular shape. That's a moduli stack. The "stackiness" is that extra data.
Moduli space, fuzzy catalogue for derived moduli space	derived moduli space is like a catalog where the pages are "fuzzy" or "blurry." Each point in the catalog is not a single, crisp object but a collection of objects that are equivalent up to a homotopy.
Moduli space, perfect obstruction theory	geometry of a derived moduli space is governed by a perfect obstruction theory, which is a complex that measures the "obstructions" to deforming an object. The existence of a perfect obstruction theory allows one to compute the virtual fundamental class of the moduli space.
Moduli space, homological	homological algebra, a moduli space can be defined as the classifying space for certain types of chain complexes. The points of the moduli space are the isomorphism classes of these complexes.
Moduli space, categorical moduli space	categorical moduli space is a solution to a moduli problem in the context of category theory. The moduli space is itself a category whose objects are the objects being classified.
Moduli space, D-modules	theory of D-modules, which are modules over the ring of differential operators.
Cotangent space, rulers of the tangent vector	cotangent space Tp∗​M at a point p on a smooth manifold M is the dual vector space of the tangent space Tp​M. Visual Intuition: If the tangent space is the space of all possible directions (velocity vectors) you can go in, the cotangent space is the space of all possible linear measurements you can make on those directions. Think of it as a set of "rulers" that can measure the length of a tangent vector.
Cotangent space, directions and measurements	tangent space captures the "first-order" directions, while the cotangent space captures the "first-order" measurements. They are dual concepts. Visual Intuition: A tangent vector is a direction, like a compass arrow. A cotangent vector is a way of measuring a direction, like a ruler that measures distance along a compass arrow.
Cotangent space, obstruction theory with deformation	cotangent space plays a key role in obstruction theory, where cotangent vectors correspond to first-order deformations. Higher-order obstructions to deformations lie in higher cohomology groups. Visual Intuition: The cotangent space is the "space of constraints," and obstructions are the things that prevent you from satisfying those constraints.
Tangent space, smooth surface	Imagine a smooth surface; the tangent space at a point is a flat plane that just touches the surface at that point, representing all the directions one could move in instantaneously.
Tangent space, derivations	the tangent space at a point p on a variety is defined as the space of derivations at that point. A derivation is a linear map D: O_{X,p}​ to k that satisfies the Leibniz rule, where O_{X,p}​ is the local ring at p and k is the residue field. Visual Intuition: A derivation measures the "rate of change" of functions at a point, which is exactly what a tangent vector does.
Tangent space, Zariski tangent space	Zariski tangent space Tp​X of a scheme X at a point p is the dual of the vector space mp​/mp2​, where mp​ is the maximal ideal of the local ring at p. Visual Intuition: mp​ represents the functions vanishing at p. mp2​ represents functions vanishing to a higher order. The quotient captures the first-order behavior, which is the linear approximation of the geometry around the point—exactly what a tangent space is.
Tangent space, cotangent space	dual vector space of the tangent space. It is the space mp​/mp2​. Visual Intuition: If the tangent space is the space of all possible directions, the cotangent space is the space of all possible "infinitesimal measurement tools" at that point.
Tangent space, A_infty algebra	tangent space at a point is not just a vector space but a more complex object that captures higher-order information. The tangent space is a differential graded vector space, reflecting the homotopical nature of the algebra. Visual Intuition: It's like a fuzzy, multi-layered version of a tangent plane, with each layer representing a different level of "infinitesimal" information.
Tangent space, tangent bundle	tangent bundle TX of a manifold X is the union of all the tangent spaces at all points, with a natural manifold structure. It's a vector bundle over the manifold. Visual Intuition: It's like a a "hairy" surface, where each hair is a tangent vector.
Tangent space, cotangent bundle	cotangent bundle is the dual vector bundle to the tangent bundle. It's the union of all the cotangent spaces. Visual Intuition: It’s the "space of all possible infinitesimal measurements" on the manifold.
Tangent bundle, tangent sheaf	tangent bundle is generalized to the tangent sheaf. It's the sheaf of derivations, which is a key object for studying the geometry of schemes. Visual Intuition: It’s a "sheaf of hairs," where the "hairs" are tangent vectors.
Tangent sheaf, normal sheaf subscheme Y of a scheme X as a quotient, measuring extent of embedding	subscheme Y of a scheme X, the normal sheaf is the quotient of the tangent sheaf of X by the tangent sheaf of Y. It measures how Y is embedded in X. Visual Intuition: It’s like the space of all directions perpendicular to a sub-manifold.
Tangent sheaf, obstruction theory	tangent space plays a key role in obstruction theory, where tangent vectors correspond to first-order deformations, and higher-order obstructions to deformations lie in higher cohomology groups. Visual Intuition: The tangent space is the "space of possibilities," and obstructions are the things that prevent you from realizing those possibilities.
Tangent space, derived tangent space in derived algebraic geometry	the tangent space at a point on a derived scheme is no longer just a vector space. It is a chain complex, which captures higher-order homotopical information. Visual Intuition: The tangent "plane" is now a "fuzzy" or "homotopically-structured" object.
Tangent sheaf, tangent complex	tangent complex is the correct categorical generalization of the tangent sheaf. It is a chain complex of sheaves that encodes the first-order information of a scheme or stack. Visual Intuition: It’s a multi-layered object that measures the "rates of change" of a scheme, where each layer is a different type of rate of change.
Tangent sheaf, tangent cone at a singular point of the variety	tangent cone at a point p of an algebraic variety is the set of all tangent lines to the variety at p. It's a cone in the tangent space. Visual Intuition: At a singular point on a variety, the tangent space is often too large. The tangent cone is the true "tangent approximation" of the variety at that point.
Tangent sheaf, local ring	local ring at a point p on a scheme contains all the information about the geometry of the scheme in an "infinitesimal" neighborhood of p. The tangent space is extracted from this local ring. Visual Intuition: The local ring is the "universe of functions" around a point, and the tangent space is the "linearization" of that universe.
Ramification, prime ideals, imagine the prime ideals of Z as points on a number line. When we extend to a larger number field, this line is "unfolded" into a higher-dimensional space. The prime ideals in the larger field are also points, but some of them might "pile up" on top of the original prime ideal. In the case of Q(root 5)/Q, the prime (5) splits into (5) twice, which can be visualized as two points "collapsing" onto the original point. This is the geometric intuition of ramification	In algebraic number theory, ramification describes the behavior of a prime ideal p in a number field K when it is extended to a larger number field L. The ideal pO_L​ factors into a product of prime ideals in the ring of integers of L. Ramification occurs when at least one of these prime factors appears with a power greater than 1. This "bunching up" or "confluence" of prime factors is a fundamental concept. For example, in the extension Q(root 5)/Q, the prime ideal (5) of Z"ramifies" as it becomes the ideal (root 5​)^2 in the ring of integers Z[1 + root(5) / 2]
Ramification, domain P^1 as a sphere. The map z to z^2 wraps the sphere around itself twice. The points z=0 and z= infity are ramification points. This is where the wrapping "bunches up," and the pre-image of the image point is not a single point but a single point with multiplicity	For a non-constant morphism of smooth curves f: X to Y, a point p in X is a ramification point if the corresponding map on local rings is not an isomorphism. This is a geometric phenomenon where the map "folds" or "pinches" the curve at a point. The degree of ramification is measured by the ramification index, which is a key invariant. For example, the map f: P^1 to P^1 given by z to z2 is ramified at the point z = 0.
Ramification, real place is a point on a line. A complex place is a pair of points. The ramification of a real place into a complex one can be visualized as a single point on a line "splitting" into two points in a higher-dimensional space	In the theory of valuations, ramification describes the behavior of a place of a number field in an extension. A place can be a prime ideal (finite place) or an embedding into the real or complex numbers (infinite place). Ramification of a finite place means the valuation of an element changes in a non-trivial way, while for infinite places it means a real place becomes a complex one. For example, in Q(root(-1))/Q, the real place of Q is ramified because it becomes a complex place.
Ramification, Galois group as a group of symmetries of the extension. The decomposition group of a prime ideal is a subgroup that fixes the ideal. Ramification means that this subgroup is not trivial, so there are some "symmetries" that leave the ideal unchanged	In a Galois extension of number fields L/K, ramification occurs when the decomposition group of a prime ideal is not trivial. This means that there are elements in the Galois group that fix the prime ideal but not the elements in its ring. This is a subtle but deep concept that links the algebraic properties of the extension to its number-theoretic properties.
Ramification, imagine a sheet of paper. A branched cover is like folding the paper and then projecting it onto a line. The folds are the ramification locus, and the line they are projected onto is the branch locus. The map from the curve to the line is a branched cover that folds the curve at the points where the tangent is vertical	A branched cover is a surjective map of varieties with ramification. The set of ramification points is called the ramification locus, and its image is the branch locus. The map from a variety to its base is a local isomorphism everywhere except at the ramification locus. For example, the map from the curve y^2 = x(x−1)(x−2) to the affine line given by projection to the x-axis is a branched cover.
Ramification, imagine a map from a disk to a disk. A critical point is a point where the map "flattens" or "folds" the disk. The dynamics around this point are very complex and can lead to chaotic behavior	In dynamics, ramification occurs in complex dynamics when a map has critical points. A critical point is a point where the derivative of the map is zero. This is a point where the map "folds" or "pinches." For example, the map z to z^2 has a critical point at z=0.
Ramification, canonical divisor is a geometric object that is a "dual" to the tangent bundle. It is a line bundle that is related to the ramification of the map	The canonical divisor of a curve is a divisor that is related to the ramification of the curve. The degree of the canonical divisor is related to the genus of the curve and the ramification of the map.
Ramification, Hilbert symbol is a "map" that measures the ramification. It is a way of "quantifying" the ramification	The Hilbert symbol is a symbol that measures the ramification of a number field extension. The Hilbert symbol is a key tool in class field theory.
Ramification, Serre duality is a "duality" between two geometric objects. The ramification of the map is a key ingredient in this duality	The concept of ramification is used to formulate Serre duality, which is a duality theorem for coherent sheaves on a scheme. The duality is between the cohomology of a sheaf and the cohomology of its dual.
Ramification, covering space is a "bundle" of spaces. A ramified covering space is a covering space that "folds" or "pinches" at some points	A ramified covering space is a generalization of a covering space. A covering space has the property that the fibers are discrete sets. A ramified covering space has the property that the fibers can have "ramification."
Ramification, moduli space of curves is a geometric object. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms	The concept of ramification is used to study the moduli space of curves. The moduli space is a geometric object that classifies curves. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms.
Functor of points, imagine the affine line A1 as a set of points. The functor of points view says, don't look at the points, look at all the maps into the line. A map from a scheme T to A1 is just a function on T. The functor of points for A1 is the rule that says, for any ring R, give me the set of all polynomials with coefficients in R. This is a "generalized" way of viewing the line	The functor of points perspective views a scheme X not as a set of points, but as a rule that assigns a set of maps to X from any other scheme T. This rule is a functor from the category of schemes to the category of sets, denoted as Hom(−,X). This allows one to study a scheme by studying its relationship with all other schemes, providing a more robust and flexible definition of a "geometric object." For example, the affine line A1 is the functor that assigns to each ring R the set of its elements.
Functor of points, group Z as a number line. The functor of points view says, don't look at the numbers, look at all the maps into the number line. A map from a group H to Z is a homomorphism. This is a "generalized" way of viewing the group	In group theory, a group G can be viewed as a functor of points. This functor assigns to each group H the set of all group homomorphisms from H to G. This generalizes the idea of a group as a set with a multiplication rule. It is a more abstract way of thinking about groups. For example, the group Z is the functor that assigns to each group H the set of its elements.
Functor of points, a chain complex as a tower of vector spaces. The functor of points view says, don't look at the spaces, look at all the maps into the tower. A map from a chain complex D*​ to C*​ is a chain map. This is a "generalized" way of viewing the chain complex	In homological algebra, a chain complex C*​ can be viewed as a functor of points. This functor assigns to each chain complex D*​ the set of all chain maps from D*​ to C*​. This generalizes the idea of a chain complex as a sequence of modules with maps between them.
Functor of points, ring as a space with a non-commutative multiplication rule. The functor of points view says, don't look at the points, look at all the maps into the space. A map from a ring S to R is a ring homomorphism. This is a "generalized" way of viewing the ring	In non-commutative ring theory, a ring R can be viewed as a functor of points. This functor assigns to each ring S the set of all ring homomorphisms from S to R. This generalizes the idea of a ring as a set with two operations.
Functor of points, a group algebra as a geometric object. The functor of points view says, don't look at the points, look at all the maps into the object. A map from an algebra A to kG is an algebra homomorphism	In modular representation theory, a group algebra kG can be viewed as a functor of points. This functor assigns to each algebra A the set of all algebra homomorphisms from A to kG. This generalizes the idea of a group algebra as a ring with an action of a group.
Functor of points, sphere. The functor of points view says, don't look at the points, look at all the maps into the sphere. A map from a space Y to the sphere is a continuous map. This is a "generalized" way of viewing the sphere	In homotopy theory, a topological space X can be viewed as a functor of points. This functor assigns to each topological space Y the set of all continuous maps from Y to X. This generalizes the idea of a topological space as a set with a topology.
Functor of points, a number field as a space of numbers. The functor of points view says, don't look at the numbers, look at all the maps into the space. A map from a field L to K is a field homomorphism. This is a "generalized" way of viewing the number field	In arithmetic number theory, a number field K can be viewed as a functor of points. This functor assigns to each field L the set of all field homomorphisms from L to K. This generalizes the idea of a number field as a field extension of Q.
Functor of points, a dynamical system as a flow on a manifold. The functor of points view says, don't look at the flow, look at all the maps that preserve the flow. A map from a dynamical system (Y,g) to (X,f) is a map that commutes with the dynamics. This is a "generalized" way of viewing the dynamical system	In dynamics, a dynamical system (X,f) can be viewed as a functor of points. This functor assigns to each dynamical system (Y,g) the set of all maps that preserve the dynamics. This generalizes the idea of a dynamical system as a space with a map.
Functor of points, projective space as a space of lines through the origin. The functor of points view says, don't look at the lines, look at all the maps into the space. A map from a scheme T to Pn is a line bundle on T. This is a "generalized" way of viewing projective space	The functor of points for projective space Pn assigns to each ring R the set of all "line bundles with a basis" on Spec(R). This is a very abstract way of defining projective space.
Functor of points, derived functor is a functor that is a "homological" version of a normal functor. The functor of points view is a way of "seeing" this	The concept of a functor of points can be used to define derived functors. A derived functor is a functor that is "homological." The functor of points view is a way of "seeing" the derived functors.
Functor of points, a module as a vector space with a ring action. The functor of points view says, don't look at the points, look at all the maps into the space. A map from a module N to M is a module homomorphism	In non-commutative ring theory, a module M can be viewed as a functor of points. This functor assigns to each module N the set of all module homomorphisms from N to M. This generalizes the idea of a module as a vector space with a ring action.
Functor of points, a module as a geometric object. The functor of points view says, don't look at the points, look at all the maps into the object. A map from a module N to M is a module homomorphism	In modular representation theory, a module M over a group algebra kG can be viewed as a functor of points. This functor assigns to each kG-module N the set of all module homomorphisms from N to M.
Stack, a way into automorphims by considering the moduli space of elliptic curves. An elliptic curve has a finite number of automorphisms (usually two). If we try to build a moduli space as a scheme, the points where the elliptic curve has more automorphisms will be singularities.A stack is a way of "smoothing out" these singularities. It is a space where the points are not just elliptic curves, but elliptic curves with their group of automorphisms. For example, a point in the moduli space of elliptic curves is not just a curve, it is a curve together with its group of automorphisms, which can be thought of as a "fiber" over the point	A stack is a generalization of a scheme or manifold that allows for the presence of non-trivial automorphisms of the objects being classified. Instead of classifying objects up to isomorphism (as a moduli space does), a stack classifies objects with their full group of automorphisms.
Stack, a base space, like a manifold, and over each point, we have a "fiber" which is a groupoid. The groupoid over a point is the collection of all objects that correspond to that point, and the morphisms are the isomorphisms between them. A stack is a way of "gluing" these groupoids together in a consistent way. The stack of elliptic curves is a category fibered in groupoids over a moduli space. The fiber over a point is the groupoid of elliptic curves isomorphic to that point	A stack is a category fibered in groupoids over a base category, satisfying certain descent conditions. This means that for a given object in the base category, the fiber over it is a groupoid whose objects are the objects being classified and whose morphisms are the isomorphisms between them.
Stack, the category of objects as a collection of points. The isomorphisms are arrows between these points. The automorphisms are loops from a point to itself. A stack is a way of "dividing out" these loops. For example, the stack of elliptic curves is the quotient of the category of all elliptic curves by the action of the isomorphisms between them. The resulting object is a stack, which "remembers" the automorphisms of each curve	A stack can be viewed as the quotient of a category by a groupoid. For a category of objects, we can form a groupoid where the objects are the objects of the category and the morphisms are the isomorphisms between them. The stack is the "quotient" of this groupoid by the action of the automorphisms.
Stack, consider the affine line A1 and the multiplicative group Gm​ acting on it by multiplication. The quotient scheme A1/Gm ​is just a point. However, the quotient stack [A1/Gm​] is a more complex object. It has a point for the origin, and a point for every other point on the line. The automorphism group of the point for the origin is the entire group Gm​, and the automorphism group for every other point is trivial. The stack is a way of "remembering" these automorphisms	A quotient stack [X/G] is a stack that is the quotient of a scheme X by the action of an algebraic group G. The objects of the stack are the points of X, and the morphisms are the elements of G that act on them. The stack "remembers" the group action.
Stack, a quiver, which is a directed graph. A representation is a collection of vector spaces and linear maps. We can form a moduli space of these representations. However, some representations have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms. It is a space where the points are representations together with their group of automorphisms	In modular representation theory, we can use stacks to study the moduli space of representations of a quiver. The group of automorphisms of a representation is the group of all invertible matrices that commute with the action of the quiver. A stack is a way of "classifying" these representations with their automorphisms.
Stack, the field of rational numbers Q. We can form the adelic ring, which is a product of all the completions of Q. We can use stacks to study the moduli space of elliptic curves over the adeles. This is a way of "gluing" the local moduli spaces together to get a global object. The stack remembers the automorphisms of the elliptic curves at each prime	In arithmetic number theory, we can use stacks to study the moduli space of elliptic curves with a level structure. This is a stack that classifies elliptic curves with their automorphisms, which are "local" at each prime.
Stack, a cone. A cone is an orbifold, but it has a singularity at the vertex. The group of rotations around the vertex is a finite group. A stack is a way of "remembering" this group action. The stack of the cone is a space that has a point for every point on the cone, but the vertex has a "fiber" which is the group of rotations	An orbifold is a space that is locally the quotient of a Euclidean space by a finite group action. A stack is a generalization of an orbifold, where the group can be an algebraic group. A stack is a space that is locally the quotient of a scheme by a group action.
Stack, the moduli space of elliptic curves is a geometric object with singularities. A stack is a way of "smoothing out" these singularities. The stack of elliptic curves is a space that has a point for every elliptic curve, but the points with non-trivial automorphisms have "fibers" that are the group of automorphisms	A moduli stack is a stack that "classifies" a family of geometric objects. It is a generalization of a moduli space, where the objects are classified with their automorphisms. For example, the moduli stack of elliptic curves M1,1​ is a stack that classifies elliptic curves with their automorphisms.
Stack, scheme is like a geometric space that is built from rings. A stack is a geometric space that is built from categories. A scheme is a 0-stack. A stack is a way of generalizing the concept of a geometric space to include higher-dimensional information	A stack is a generalization of a scheme. A scheme is a space that is locally a ring. A stack is a space that is locally a category. This is a very deep generalization that allows us to study objects with non-trivial automorphisms.
Stack, a non-commutative algebra as a space of "rules" for multiplication. A module is a vector space with an action of the algebra. We can form a moduli space of these modules. However, some modules have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms	In non-commutative ring theory, we can use stacks to study the moduli space of modules over a non-commutative algebra. The group of automorphisms of a module is the group of all invertible endomorphisms. A stack is a way of "classifying" these modules with their automorphisms.
Stack, a Galois group. A Galois representation is a way of "representing" the group as matrices. We can form a moduli space of these representations. However, some representations have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms	In arithmetic number theory, we can use stacks to study the moduli space of Galois representations. A Galois representation is a group homomorphism from a Galois group to a group of matrices. The group of automorphisms of a Galois representation is the group of all invertible matrices that commute with the action of the Galois group. A stack is a way of "classifying" these representations with their automorphisms.
Stack, the moduli space of curves of genus 0, which is just a point. A curve of genus 0 is a sphere. The group of automorphisms of a sphere is a very large group. A stack is a way of "remembering" this group. The stack of curves of genus 0 is a more complex object than just a point	A stack is a way of generalizing the concept of a moduli space. A moduli space is a geometric object that classifies a family of objects up to isomorphism. A stack classifies a family of objects with their full group of automorphisms.
Stack, a topological space. The loop space of the space is a space of all loops. A stack is a way of "remembering" the automorphisms of these loops. It is a space where the points are loops together with their group of automorphisms	in homotopy theory, a stack can be seen as a way of generalizing the concept of a loop space. A loop space is the space of all loops from a point to itself. A stack is a way of generalizing this concept to include automorphisms.
Stack, a dynamical system with a group action. We can form a moduli space of these systems. However, some systems have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms. It is a space where the points are equivariant dynamical systems together with their group of automorphisms	In dynamics, we can use stacks to study the moduli space of equivariant dynamical systems. An equivariant dynamical system is a dynamical system with a group action. The group of automorphisms is the group of homeomorphisms that commute with the dynamics and the group action. A stack is a way of "classifying" these systems with their automorphisms.
Stack, two surfaces that intersect. The intersection is a curve. The points on the curve can have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms. The stack of the intersection is a more complex object than just the curve	Stacks can be used to describe the intersection of two schemes. The intersection of two schemes can have non-trivial automorphisms. A stack is a way of "remembering" these automorphisms.
Singularity, example y2=x3+x2 in the real plane. This curve has a node at the origin (0,0). . At this point, the curve intersects itself. As you approach the origin from different directions, the "tangent line" seems to have multiple possibilities. This non-uniqueness of the tangent line is a visual manifestation of the singularity	A singularity on an algebraic variety is a point where the variety fails to be a smooth manifold. This means that at this point, the tangent space is not well-defined or has a dimension different from the variety's dimension. Visual Intuition: Consider the algebraic variety defined by the equation y2=x3+x2 in the real plane. This curve has a node at the origin (0,0). At this point, the curve intersects itself. As you approach the origin from different directions, the "tangent line" seems to have multiple possibilities. This non-uniqueness of the tangent line is a visual manifestation of the singularity.
Singularity, failure of analyticity example	f(z)=1/z. It is analytic everywhere except at z=0. As you approach the origin, the magnitude of the function, |f(z)|, blows up. The point z=0 is a pole, a type of singularity. This "blow-up" behavior is a key visual characteristic: A singularity of a complex function f(z) is a point z0​ where the function is not analytic (i.e., not complex differentiable). Such points can be isolated (removable, pole, essential) or non-isolated.
Singularity, cone tip fails to resemble the Euclidean point	Imagine the surface of a cone. The apex of the cone is the singular point. In a topological space, a singularity can be thought of as a point that locally resembles a cone. A cone has a "pointy" tip, which is a singularity, while the rest of the space is smooth. No matter how you zoom in on this point, it never flattens out to resemble a Euclidean plane. This "pointedness" is a hallmark of a singularity in this context.
Singularity, failure of prime ideals to be regular, consider regular local ring corresponds to a "smooth" point on an algebraic variety. A non-regular local ring corresponds to a singular point. Think of the origin of the nodal curve y2=x3+x2. The local ring at this point, k[x,y](x,y)​/(y2−x3−x2), is not regular	In the context of commutative ring theory, a prime ideal p of a Noetherian local ring (R,m) is singular if the ring is not a regular local ring. A regular local ring is one where the dimension of the ring is equal to the minimal number of generators of its maximal ideal. Visual Intuition: A regular local ring corresponds to a "smooth" point on an algebraic variety. A non-regular local ring corresponds to a singular point. Think of the origin of the nodal curve y2=x3+x2. The local ring at this point, k[x,y](x,y)​/(y2−x3−x2), is not regular. The "irregularity" of the local ring is a way of algebraically encoding the geometric irregularity of the point.
Singularity, fixed points of flows, example of a pendulum swinging back and forth	In a dynamical system defined by a vector field, a singularity is a point where the vector field is zero. These are also known as fixed points or equilibrium points. The flow of the system "stalls" at these points. Visual Intuition: Consider a pendulum swinging back and forth. The fixed points are when it is hanging straight down (stable equilibrium) and when it is balanced perfectly upright (unstable equilibrium). . At these points, the velocity of the pendulum is zero, and the "flow" of the system stops.
Singularity, modular representation theory	In modular representation theory, a module M for a finite group G is called singular if it is not a direct sum of projective modules. A projective module is a "nice" module that lifts homomorphisms. The singularity of a module reflects its inability to "behave nicely" in a complex. Visual Intuition: Think of the representation of a group as a collection of linear transformations. A non-projective representation is like a set of transformations that has a "defect" or "hole." When you try to extend a linear map from a submodule, the map cannot be extended smoothly, indicating the "singularity" or "non-smoothness" of the representation.
Singularity, noninjectivity of differential df_p, singularity of a smooth map f	M to N between manifolds is a point p in M where the differential df_p​ is not injective (i.e., its rank is less than the dimension of M):  Consider the map f(x,y)=(x2,y) from R2 to R2. The differential at the origin is not injective. The origin is a singular point of the map because the local neighborhood is "folded" or "squashed" onto itself, causing a loss of dimension.
Singularity, degenerate critical point for f(x) = x^3, x = 0, Hessian is not invertible in Morse theory	In Morse theory, a critical point of a function is where its derivative is zero. A singularity is a degenerate critical point, where the Hessian matrix at that point is not invertible. Visual Intuition: Consider the function f(x) = x3. The point x=0 is a critical point where the derivative is zero. However, the second derivative is also zero, so it is a degenerate critical point. Unlike a local minimum or maximum, the function is "flat" at this point, and you can't classify it based on the second derivative. This "flatness" is a visual cue for the singularity.
Singularity, extension of local sections. Example on a punctured disk cannot be extended to a section on the entire disk if the function has a pole at the center. The "hole" in the domain where the extension fails is the singular point	In sheaf theory, a singularity of a sheaf can be thought of as a point where a section defined on a small open set cannot be extended to a larger open set. This is a local-to-global problem. Visual Intuition: Consider the sheaf of holomorphic functions on the complex plane. A section defined on a punctured disk cannot be extended to a section on the entire disk if the function has a pole at the center. The "hole" in the domain where the extension fails is the singular point.
Singularity, D-module fails coherent, a singular point is where the solutions to the system exhibit "pathological" behavior, such as a logarithmic singularity. The failure of coherence is the algebraic manifestation of this pathological behavior	In the theory of D-modules, which studies systems of linear partial differential equations, a singularity is a point where the module is not coherent, meaning it doesn't behave like a module over a polynomial ring. Visual Intuition: Think of a system of differential equations. A singular point is where the solutions to the system exhibit "pathological" behavior, such as a logarithmic singularity. The failure of coherence is the algebraic manifestation of this pathological behavior.
Singularity, bad reduction modulo prime number to get a singular curve. Imagine the elliptic curve defined by y2 = x3 − x. When you reduce it modulo 2, the equation becomes y2 = x3 + x over the field with two elements. This curve has a singular point at (0,0), which corresponds to the "bad reduction" of the original curve	In arithmetic geometry, a singularity of an elliptic curve over a number field is a point of bad reduction. This means that when you reduce the curve modulo a prime number, the resulting curve is singular. Visual Intuition: Imagine the elliptic curve defined by y2=x3−x. When you reduce it modulo 2, the equation becomes y2=x3+x over the field with two elements. This curve has a singular point at (0,0), which corresponds to the "bad reduction" of the original curve.
Divisor, subvariety of codimension 1	divisor is a subvariety of codimension one. Visual intuition: A divisor is a "hypersurface" or a "wall" within a higher-dimensional space. In 3D space, a divisor is a 2D surface; on a surface, a divisor is a 1D curve.
Divisor, principal divisor	principal divisor is a divisor that is the zero set of a single function. Visual intuition: A principal divisor is a "wall" defined by one simple equation, like a plane in 3D space defined by x = 0.
Divisor, Weil divisor	Weil divisor on a normal scheme X is a formal sum of irreducible subvarieties of codimension 1. It’s like a combination of different walls, each with a specific "multiplicity" or weight.
Divisor, Cartier	Cartier divisor is a collection of functions on open sets that are compatible on their overlaps. This is a more refined notion than a Weil divisor. Visual intuition: It's a "wall" that is defined by local equations that are "glued" together consistently. This is a powerful idea that generalizes to non-normal varieties.
Divisor, divisor class groups	divisor class group of a ring is the group of Weil divisors modulo the group of principal divisors. Visual intuition: It's the set of all "walls" that can't be defined by a single global function. It measures how far the ring is from being a unique factorization domain (UFD).
Divisor, unique factorisation domain	unique factorization domain (UFD), every Weil divisor is principal (elements or codimension one are uniquely factorised). The divisor class group is trivial. Visual intuition: In a UFD, every wall can be defined by a single global function. There are no "exotic" walls.
Divisor, invertible sheaf and Cartier divisors	in algebraic geometry, a Cartier divisor is equivalent to a line bundle or an invertible sheaf. Visual intuition: An invertible sheaf is a "line bundle," a geometric object that looks like a product of the space and a line at every point. The sections of this bundle are the functions that define the divisor. Recall that a Cartier divisors are walls that are defined by local equations that are "glued" consistently.
Divisor, intersection theory, classical example of two lines intersecting at a point of codimension 2	main objects of study in intersection theory, which is concerned with how subvarieties intersect. Visual intuition: Divisors are the fundamental geometric objects whose intersections can be counted. For example, two lines in a plane intersect at a point, which has codimension 2.
Divisor, rational functions of positive and negative weight	divisor of a rational function is a Weil divisor that measures the zeros and poles of the function. Visual intuition: It’s a "map" of where a function is zero (a positive weight) and where it blows up (a negative weight). Weil divisors are combination of different walls, there are zero walls, and blow up walls.
Divisor, valuation ring	valuation rings, which are local rings that have a unique maximal ideal. The divisor is related to the valuation on the field of fractions. Visual intuition: The valuation ring is a way of "measuring" the order of a zero or a pole of a function at a point.
Divisor, derived divisor	derived divisor is a generalization of a divisor to a derived scheme. Visual intuition: It’s a "wall" in a "homotopically fuzzy" space, where the wall itself might be "fuzzy" and defined up to homotopy.
Divisor, sheaf cohomology	deeply connected to sheaf cohomology. For a line bundle L, the first cohomology group H1(X,L) measures the "obstructions" to a section of the line bundle.
Divisors, canonical divisor	canonical divisor is a fundamental divisor on a smooth variety that is related to the differential forms. Visual intuition: It is the "wall" that encodes the geometry of the variety.
Divisors, ideal sheaf visualisation of sheaves as identification as to where the sheaves are	ideal sheaf of a divisor is a quasicoherent sheaf that locally is an invertible ideal. Visual intuition: The ideal sheaf is the "data" that tells you where the divisor is in the space. Sheaves are like consistently glued sticky notes.
Divisors, principal divisors and rational functions	one-to-one correspondence between principal divisors and rational functions up to a constant. Visual intuition: A single rational function defines a specific "wall" in the space, a place where it is zero or infinite.
Divisors, effective divisors	effective divisor is a Weil divisor where all the coefficients are non-negative. It's a "wall" that has a positive "weight."
Monodromy, f(z) = root(z) . Let's start at z=1 with root(1) = 1. If we travel a full circle around the origin (a singularity) in the complex plane, we arrive back at z=1 but now the value is root(1) ​= −1. This "change" from 1 to −1 is the monodromy. It's like a spiral staircase where you end up on a different floor even though you've made a full circle	In complex analysis, monodromy describes how a multi-valued function, like the complex logarithm, changes value when its argument is analytically continued along a closed path around a singularity.
Monodromy, consider singular algebraic curve, such as y2=x3−x. This curve has a singular point. If we take a family of nearby smooth curves, and move around the singular curve in a loop, the local geometry of the fiber will "twist." This twisting is the monodromy. It's the action of a group on the fundamental group of the space	In algebraic geometry, monodromy describes how the local data of a sheaf (e.g., the stalk) changes when transported around a singularity of a variety. For a flat connection, the monodromy is given by a group representation.
Monodromy, helix E=R covering the circle B=S1 via the map p(t)=(cos(t),sin(t)). If you walk a full loop on the circle, starting at (1,0), your path in the helix lifts to one that starts at 0 and ends at 2 pi. The difference, 2 pi, is the monodromy. It's a way of counting how many times a path "spirals up" in the covering space	In homotopy theory, monodromy is the action of the fundamental group pi_1​(B) of a base space B on the fibers of a covering space p: E to B. A path in B lifts to a unique path in E, and a closed loop in B maps to a path in E that ends on a different point in the fiber.
Monodromy, roots of the polynomial x^2−2. The roots are +-2. We can visualize the Galois group as a permutation group that swaps the two roots. The monodromy is this "swapping" action as you move around a singularity. It is the action of a group that captures the symmetries of the roots	In arithmetic number theory, monodromy can be seen as the action of the absolute Galois group of a number field on the roots of a polynomial. The "monodromy group" of a polynomial with coefficients in a number field is the Galois group of its splitting field.
Grothendieck group, fundamental construction in K-theory	, consider a ring A, let F be the be the category of left A modules, the Grothendieck group of the category F is an abelian group with generators for each left A module and relations [E] = [E*] + [E**] associated with exact sequences such that 0 is to E is to E* is to E** is to 0. This group completion forming the Grothendieck group is a key part of the definition of K-theory.
Homotopy, continuous deformation	"deformation" is a continuous family of maps parameterized by a "time" interval.
Homotopy, path in function space	continuous path in the space of continuous maps
Homotopy, family of map	continuous one parameter family of maps
Homotopy, map from cylinder	map from X * I into Y, I is unit interval, map restricted to the bottom face for the first map, top face for the second map
Homotopy, equivalence relation	Equivalence relation on set of continuous maps, partitioning into homotopy classes.
Homotopy, weak isomorphism	homotopy equivalent if pair of maps composition is homotopic to identity map, weaker than homemorphism (topological isomorphism)
Homotopy, define homotopy category	homotopy classes of maps are morphisms on the homotopy category, objects are topological spaces, homotopy is equivalence relation giving which morphisms are the same
Homotopy, defining invariant of invariant functor	Homotopy define invariant functors (fundamental group and homology groups), two maps are homotopic, induces same homomorphism
Homotopy, factorisation of maps	Factor maps through special objects and properties, example factor through cylinder objects with fibrations and cofibrations
Homotopy, high dim morphisms	homotopy between two 1-morphism is 2-morphism
Homotopy, nullhomotopic	map is nullhomotopic if homotopic to constant map, defines contractible spaces
Homotopy, relative	relative homotopy keep points in a subspace fixed, defining fundamental groups where loops have fixed base points
Homotopy, simplicial maps	defined combinatorially as elementary moves on simplicies of complex, giving discrete computational model
Homotopy, equal in type theory	Path between two points in space is proof that points are equal
Homotopy, fibration category	category with weak equivalences, it is an axiom
Homotopy, infinity groupoid	points are objects, paths are 1-morphisms, homotopies are 2-morphisms, and so on
Projective module, direct summand of free module	direct sum of projective module and another module forming a free module
Projective module, lifting property	lifts surjective module homomorphism module M to module N and any homomorphism projective module P to module N using ring homomorphism from projective P to module M. Very similar to direct sum definition.
Projective module, split short exact sequence	projective if every 0 -> K -> M -> P -> 0, is split exact aka M is isomorphic to direct sum of K and P
Projective module, exactness of Hom functor	TFAE: (1) projective; (2) Hom(P, - ) is exact.
Projective module, projective resolution	Projective resolution of length 0, -> P_1 -> P_0 -> M -> 0, all P_i are projective
Projective module, dual basis	for a projective module, a dual basis exists, linear forms in Hom(P, R) for coefficients x_i in projective module P, ring R.
Projective modules, flat	All projective modules are flat modules, flat modules preserve injectivity under tensor product
Projective modules, condition via localisation at each prime ideal to get a free R_p module	TFAE: (1) for each and every prime ideal p in ring R, localised P_p is a free R_p module; (2) P is projective.
Projective module, idempotent endomorphism	TFAE: (1) P is finitely generated projective module; (2) P is the image of idempotent endomorphism of a free module. Idempotent endomorphism is map p from F to F, such that p^2 = p.
Projective module, 0 Ext group	TFAE: (1) module projective; (2) Ext^1_R(P, M). Vanishing of first Ext group means it is acyclic in some sense
Projective module, locally free sheaf	TFAE (1) finitely generated projective module over commutative ring R; (2) locally free sheaf on affine scheme Spec(R)
Projective module, vector bundles	Projective modules are to free modules (take resolutions of free modules) as vector spaces are to trivial bundles (use many trivial bundles to get vector space, no need to consider global twisting)
Projective module, flat and finitely presented	For finitely generated modules, being projective is equivalent to being flat (tensor product is exact, resolution of free modules gives flat module) and finitely presented (generators and relations)
Projective module, over local ring and locally free	A projective module over a local ring is always free.
Projective module, unimodular row	fg projective module of rank 1 is a unimodular row that can be completed to an invertible matrix.
Projective module, monoid	isomorphism classes of finitely generated modules form a commutative monoid under direct sum, construction of K-group K_0(R)
Projective module, projective cover	projective cover is minimal surjection of projective module, TFAE: (1) projective module; (2) projective cover of every homomorphic module
Projective module, faithfully flat module can generate entire module category	TFAE: (1) finitely generated projective module generating entire module category; (2) faithfully flat module
Projective module, torsion free comparison in Dedekind domains	TFAE: (1) projective over Dedekind domain; (2) torsionfree over Dedekind domain. Show that a module is direct sum of finitely generated free module and fractional ideal, in a Dedekind domain, finitely generated module is isomorphic to direct sum of free module and an ideal.
Projective module, sections of vector bundle like object	modules whose elements are "sections" of a vector bundle like object
Injective module, categorical dual to projective module	Reverse arrows in commutative diagram for projective module gives injective module diagram
Injective module, Hom-tensor adjunction	Contravariant hom functor, so becomes hom-tensor duality
Injective module, cogenerator	TFAE: (1) module C is injective cogenerator; (2) injective and for all nonzero module M, nonzero homomorphism from M to C
Injective module, Matlis theorem, local structure	Matlis theorem is for a commutative Noetherian ring, every injective module is uniquely a direct sum of indecomposable injective modules.
Injective module, injective hull of quotient	every indecomposable injective module over a commutative Noetherian ring R is isomorphic to the injective hull of a module of the form R/p for some prime ideal p of R. This establishes a powerful correspondence between indecomposable injective modules and prime ideals.
Injective module, flabby sheaf	flabby sheaf, any section over open subset can be extended as a section over the full space. Geometric parallel to homomorphism extension property of injective modules
Injective modules, divisibility has no holes	divisible module, all elements can be divided by any nonzero ring element, module has no holes that prevent division
Injective module, space of functions	space of functions with no constraint on domain extension, corresponds to sections over opens becoming sections over the whole space
Injective module, definition via corepresenting object	Q is injective object if corepresenting Hom(-, Q) maps monomorphisms to epimorphisms, formally dual for projective modules
Injective module, direct products	direct product of any family of injective modules is an injective module. The corresponding property for direct sums holds only for Noetherian rings.
Injective module, no proper essential extensions	module Q is injective if and only if it has no proper essential extensions. An essential extension of a module M is a module N containing M as a submodule, such that every nonzero submodule of N has a nonzero intersection with M.
Injective module, injective hull of any module	module M has a minimal injective module containing it, called its injective hull, denoted E(M). A module Q is injective if and only if it is its own injective hull. The injective hull is an essential extension, meaning Q is an essential submodule of E(Q).
Injective module, divisible module	integral domain R, a module Q is injective if and only if it is divisible. A module M is divisible if for every nonzero element r in R and every m in M, there exists n in M such that rn in m. For example, the rational numbers Q are an injective Z-module.
Injective module, injective resolution	0 to M to I_0 to I_1, I_i all injective modules
Injective module, splitting of short exact sequence	0 -> Q -> M -> N -> 0 is split exact, M is isomorphic to direct sum of Q and N, Q is injective module, N is projective module
Injective module, homomorphism extension	TFAE: (1) Q is injective module; (2) injective if for any submodule A of an R-module B, and any homomorphism f : A to Q, there exists an extension homomorphism g: B to Q such that g restricted to A is homomorphism f.
Swan's theorem, definition of finitely generated projective module	concrete definition of a finitely generated projective module over the ring of continuous functions as being a topological vector bundle.
Swan's theorem, ring of continuous functions	base ring for the theorem is a commutative ring C(X) of real-valued, continuous functions on a compact Hausdorff space X
Swan's theorem, topological vector bundle	topological vector bundle is a topological space E together with a continuous projection map p: E to X, such that each fiber p−1(x) has the structure of a real vector space, and the structure is locally trivial.
Swan's theorem, local triviality	"local triviality" of a vector bundle is precisely the topological analog of a finitely generated projective module being locally free, a key component of the algebraic definition.
Swan's theorem, equivalence of categories	functor F from the category of vector bundles to the category of finitely generated projective modules, and a functor G in the other direction, such that FG and GF are naturally isomorphic to the identity functors.
Swan's theorem, functorial correspondence	functor F maps a vector bundle E to the module of its continuous sections, denoted Γ(X,E). This is a module over the ring of continuous functions C(X).
Swan's theorem, module from sections	module Γ(X,E) is finitely generated and projective because the vector bundle is locally trivial. A partition of unity is used to piece together local trivializations to construct a global set of generators.
Swan's theorem, sheaf of modules	functorial correspondence can be viewed as an equivalence between the category of finitely generated projective modules and the category of locally free sheaves of finite rank.
Swan's theorems, analytic interpretation	algebraic structure of a finitely generated projective module is sufficient to capture all the topological information of a vector bundle.
Swan's theorems, generalisation of trivial bundles	Swan's theorem shows that trivial bundles correspond to free modules, and non-trivial bundles correspond to non-free projective modules. For instance, the tangent bundle of the 2-sphere is a non-trivial vector bundle, and its corresponding module is a non-free projective module.
Swan's theorems, Serre-Swan theorem	similar equivalence for smooth manifolds and the ring of smooth functions. This connects differential geometry to algebra.
Swan's theorem, perfect complex	perfect complex is a chain complex of modules that is locally quasi-isomorphic to a finite complex of free modules. It is the correct homotopical generalization of a finitely generated projective module.
Swan's theorem, higher category	stable ∞-category of vector bundles to the stable ∞-category of perfect complexes.
Swan's theorem, homotopy theory of vector bundles	vector bundles are objects that classify maps into Grassmannians. Swan's theorem can be viewed as an algebraic interpretation of the homotopy theory of these classifying spaces.
Swan's theorem, topological K-theory	starting point for topological K-theory, which is a cohomology theory built from vector bundles. The algebraic counterpart is algebraic K-theory, built from finitely generated projective modules.
Vector bundle, vector space fibres	vector bundle is a specific type of fiber bundle where the fibers are vector spaces. It consists of a total space E, a base space X, and a projection map p: E to X
Vector bundle, locally trivial, visual intuition is open subset is Cartesian producted with a copy of the R^n (example for visual imagination is R^1)	for every point x in the base space X, there is a neighborhood U and an isomorphism fibres over U to be isomorphic U × R^n, which is a local trivialization.
Vector bundle, transition functions	local trivializations on overlapping neighborhoods are related by transition functions, which are continuous maps from the overlap to the general linear group GLn​(R)
Vector bundle, continuous sections	continuous section of a vector bundle is a continuous map s: X to E such that p * s is the identity map on X. The set of all continuous sections forms a module over the ring of continuous functions on X.
Vector bundle, rank	rank of a vector bundle is the dimension n of the vector space fibers. A rank 1 bundle is a line bundle. Recall that rank is output of linear map is dimensional 1.
Vector bundle, trivial	trivial if it is globally isomorphic to a product space X × R^n. This is the simplest type of vector bundle, and its continuous sections correspond to a free module.
Vector bundle, subbundle	sub-space of a vector bundle that is itself a vector bundle. Its continuous sections form a submodule.
Vector bundle, pullback bundle	pullback of a vector bundle along a map f: Y → X is a new vector bundle over the space Y, which gives a way to "transport" the bundle's structure.
Vector bundle, Whitney sum	two vector bundles E1​ and E2​ over the same base space X is a new vector bundle E1​ ⊕ E2​ whose fibers are the direct sums of the fibers of the original bundles.
Vector bundle, classification	Vector bundles of rank n on a space X are classified by homotopy classes of maps from X to the Grassmannian manifold G_n​(R^∞).
Vector bundle, locally free sheaf	algebraic analog of a vector bundle is a locally free sheaf. A sheaf of modules is locally free if every point in the scheme has a neighborhood where the sheaf is isomorphic to a free sheaf of finite rank.
Vector bundle, Serre-Swan	compact topological space X, the category of continuous vector bundles on X is equivalent to the category of finitely generated projective modules over the ring of continuous functions C(X).
Vector bundle, projective module	Swan's theorem provides an algebraic definition of a vector bundle: it's a finitely generated projective module. This allows us to use the tools of commutative algebra to study geometric objects.
Vector bundle, flat modules	vector bundle corresponds to a finitely presented flat module. This is a weaker condition than projective, and it is the correct algebraic counterpart for schemes that are not regular.
Vector bundle, on schemes	vector bundle over a scheme is defined as a locally free sheaf of modules of constant finite rank. This directly translates the topological definition into the language of algebraic geometry.
Vector bundle, perfect complex	chain complex of modules that is locally quasi-isomorphic to a finite complex of free modules. This object captures the "homotopical" nature of vector bundles.
Vector bundle, line bundle	vector bundle of rank 1 is a line bundle. In algebraic geometry, these correspond to invertible sheaves, which are key to studying divisors and rational maps.
Vector bundle, torsor	vector bundle is a torsor under a group scheme. For a line bundle, this is an algebraic version of a principal bundle.
Vector bundle, algebraic	algebraic vector bundle on a scheme is a coherent sheaf that is locally free.
Vector bundle, Grothendieck group	set of isomorphism classes of vector bundles over a topological space X forms an abelian group called the topological K-theory group K_0​(X) under the Whitney sum operation. The algebraic counterpart is the Grothendieck group K_0​(R) of a ring, which is generated by finitely generated projective modules.
Bundle, Grothendieck fibration	Grothendieck fibration is a functor p: E → B that has a lifting property for morphisms, analogous to lifting paths in a topological space. The category E is the total category, and B is the base category.
Bundle, fiber of fibration	object B in the base category B, the fiber is the subcategory of the total category E whose objects map to B and whose morphisms map to the identity morphism of B.
Bundle, local triviality	categorical bundle is locally trivial if it can be "trivialized" by pulling back to a simpler form over a "local" part of the base category. This corresponds to the existence of cartesian sections.
Bundle, section of fibration	section of a fibration p: E → B is a functor s: B → E such that p∘s is the identity functor on B. Sections are the categorical analogs of continuous sections of a vector bundle.
Bundle, classifying space	base category of a categorical bundle can be seen as a kind of classifying space for the fibers. This generalizes the concept of a classifying space for a topological group.
Bundle, category of elements	category of elements is a category whose objects are pairs (B,X), where B is an object of B and X is an object of the category F(B). This construction provides a standard way to form a fibration.
Bundle, right fibration	functor is a right-fibration if it has a specific lifting property for all morphisms in the base category, in a "right" direction. This is a common type of categorical bundle.
Bundle, modules	module M over a ring R can be seen as a categorical bundle over the base category with a single object and one morphism, which represents the ring. The "fibers" are the elements of the module.
Bundle, sheaves	sheaf of modules on a topological space or a scheme can be interpreted as a categorical bundle over the category of open sets of the space. The fibers are the stalks of the sheaf.
Bundle, fibre functor	functor that sends a vector bundle to the module of its sections can be seen as a fiber functor that generalizes the idea of a fiber in a topological bundle.
Quasicoherent sheaf, sheaf of OX modules that is locally isomorphic to R-module	quasicoherent sheaf on a scheme X is a sheaf of OX​-modules that is locally isomorphic to the sheaf associated with an R-module. It's the correct way to transport module theory to a geometric setting.
Quasicoherent sheaf, sheaf from a module	ring R, every R-module M gives rise to a quasicoherent sheaf M on the affine scheme Spec(R).
Quasicoherent sheaf, module functor	associating a sheaf to a module, the quasicoherent sheaf M~, defines a functor from the category of R-modules to the category of quasicoherent sheaves on Spec(R). This functor is an equivalence of categories.
Quasicoherent sheaf, local isomorphism on the level of stalks	sheaf F is quasicoherent if for every point x in scheme X, there exists an affine open neighborhood U = Spec(R) of x and an R-module M such that the section on the open neighbourhood F_U is locally isomorphic to the quasicoherent sheaf M-.
Quasicoherent sheaf, global module patching modules over local rings	"global module" that is constructed by patching together modules over local rings.
Quasicoherent sheaf, compared to coherent sheaf	quasicoherent sheaf is coherent if it is locally isomorphic to a sheaf associated with a finitely presented module. Coherent sheaves are the geometric counterparts of finitely presented modules, whereas quasicoherent sheaves correspond to all modules.
Quasicoherent sheaf, pushforward of a module using structural morphism of affine scheme	quasicoherent sheaf on a scheme can be defined by the pushforward of an R-module under the structural morphism from an affine scheme to the given scheme.
Quasicoherent sheaf, visual analogy as space of functions	quasicoherent sheaf can be visualized as a "space of functions" on a scheme, where the "functions" are sections that are defined locally and glued together.
Quasicoherent sheaf, on the level of stalks	stalk: localisation of module M at prime ideal p which is a local ring; section over U is isomorphic to quasicoherent sheaf M-; stalk of quasicoherent sheaf at a prime ideal p is localisation of module M at prime ideal p, which is a local ring
Quasicoherent sheaf, homotopical derived quasicoherent sheaf	sheaf whose stalk at every point is a complex of modules that is "homotopically quasicoherent," meaning it satisfies a local property in the stable homotopy category.
Quasicoherent sheaf, derived quasicoherent sheaves that is locally quasi-isomorphic	sheaf of complexes of modules that is locally quasi-isomorphic to a complex of modules over a ring.
Quasicoherent sheaves, derived functors	forming a derived quasicoherent sheaf from a module can be seen as a derived functor of the classical functor.
Quasicoherent sheaf, stacks	quasicoherent sheaves generalizes to stacks, where a quasicoherent sheaf on a stack is a more general type of a bundle that has symmetries.
Locally free module, locally free object is analogous to product of base space and fibre, or fibration with contractible	locally free object is analogous to a space that is a product of its base space and a fiber, locally. A fibration with a contractible fiber is analogous to a locally trivial bundle.
Locally free module, classification leads to algebraic K-theory to measure farness from all modules being locally free	classification of locally free modules (vector bundles) leads to algebraic K-theory. This is an ontology where we "measure" how far a ring is from having all its locally free modules be free. The Grothendieck group K0​(R) is a way to make the set of isomorphism classes of locally free modules into a group.
Locally free modules, projective resolutions as generalisation of locally free module	in homological algebra, we use projective resolutions to "resolve" (approximate) a module with a sequence of projective (or free) modules. This is a generalization of the idea that locally free modules are "like" free modules.
Locally free modules, line bundles as locally free sheaf of rank 1	line bundle is a locally free sheaf of rank 1. Geometrically, it's a vector bundle where each fiber is a one-dimensional vector space. Think of the tangent bundle of a circle, which is a line bundle.
Locally free module, tangent sheaf as locally free sheaf	tangent sheaf of a scheme is a locally free sheaf that captures the infinitesimal behavior of the scheme. Its fibers are the tangent spaces at each point. This is a direct generalization of the tangent bundle of a manifold
Rank, group of integers Z has a rank of 1, as it can be generated by the single element 1. You can visualize this on the number line, where every point can be reached by adding or subtracting 1. The rank tells you the "dimensionality" of the group in terms of its generating elements	The rank of a group (or, more generally, an algebraic structure) is the minimum cardinality of a generating set. Visual intuition: The group of integers Z has a rank of 1, as it can be generated by the single element 1. You can visualize this on the number line, where every point can be reached by adding or subtracting 1. . The rank tells you the "dimensionality" of the group in terms of its generating elements.
Rank, a matrix that transforms a space. For example, a 3×2 matrix A transforming R2 to R3. If the rank is 2, the two column vectors are linearly independent, and their span forms a 2-dimensional plane in R3. The rank tells you the dimension of the subspace that the matrix "lands" on. A rank-1 matrix would squash the entire space onto a line	In linear algebra, the rank of a matrix is the dimension of its column space (or, equivalently, its row space). It's the maximum number of linearly independent columns.
Rank, free module Z2 over the ring Z. Its basis is {(1,0),(0,1)}, so its rank is 2. This can be visualized as the integer grid in a 2D plane. . The rank tells you the "size" of the grid	In homological algebra, the rank of a free module over a commutative ring is the size of its basis. Visual intuition: Consider the free module Z2 over the ring Z. Its basis is {(1,0),(0,1)}, so its rank is 2. This can be visualized as the integer grid in a 2D plane. . The rank tells you the "size" of the grid.
Rank, L-function and the Birch and Swinnerton-Dyer conjecture relates the rank of an elliptic curve to the order of the zero of its L-function at s=1. We can visualize the L-function as a complex function and the rank as the number of times it "touches" zero at a specific point	In arithmetic number theory, the rank of an L-function at a point is the order of the zero of the function at that point. Visual intuition: The Birch and Swinnerton-Dyer conjecture relates the rank of an elliptic curve to the order of the zero of its L-function at s=1. We can visualize the L-function as a complex function and the rank as the number of times it "touches" zero at a specific point.
Rank, sheaf of regular functions on an affine variety. The stalk at a point P is the set of all regular functions defined in a neighborhood of P. The rank of this sheaf is 1 at every point	In algebraic geometry, the rank of a sheaf is the dimension of the stalk of the sheaf at each point. Visual intuition: Consider the sheaf of regular functions on an affine variety. The stalk at a point P is the set of all regular functions defined in a neighborhood of P. The rank of this sheaf is 1 at every point.
Rank, dimension of homology example, simplicial complex, like a hollow sphere. The homology group H2​ has rank 1, corresponding to the single "hollow" region. The rank tells you the number of independent "holes" of a given dimension	In homological algebra, the rank of a chain complex is the dimension of its homology groups. Visual intuition: Consider a simplicial complex, like a hollow sphere. The homology group H2​ has rank 1, corresponding to the single "hollow" region. The rank tells you the number of independent "holes" of a given dimension.
Rank, group algebra F2​[C3​] of the cyclic group of order 3. It has a basis {e,g,g2}, so its rank is 3. This is a vector space over a finite field. The rank is the number of elements in the basis	In modular representation theory, the rank of the group algebra Fp​[G] is the dimension of the algebra as a vector space over Fp​, which is equal to the order of the group. Visual intuition: Consider the group algebra F2​[C3​] of the cyclic group of order 3. It has a basis {e,g,g2}, so its rank is 3. This is a vector space over a finite field. The rank is the number of elements in the basis.
Rank, double pendulum. It has two degrees of freedom, the angles of the two pendulums. So its rank is 2. . The rank tells you the "number of dimensions" of the system's phase space	In dynamical systems, the rank can refer to the number of independent "degrees of freedom" or "modes" of the system. Visual intuition: Consider a double pendulum. It has two degrees of freedom, the angles of the two pendulums. So its rank is 2. . The rank tells you the "number of dimensions" of the system's phase space.
Rank, elliptic curve infinite number of rational points. The rank is the number of "independent" points that can generate all other points. For example, a rank-1 curve has a single point that, through the group law, can generate an infinite number of other points	In arithmetic number theory, the rank of an elliptic curve E over Q is the rank of the group of rational points E(Q). It's the number of generators of the group modulo torsion. Visual intuition: Consider an elliptic curve with an infinite number of rational points. The rank is the number of "independent" points that can generate all other points. For example, a rank-1 curve has a single point that, through the group law, can generate an infinite number of other points.
Rank, tangent bundle of a sphere. At each point on the sphere, there's a tangent plane. The dimension of this plane is 2, so the rank of the tangent bundle is 2. The rank tells you the dimension of the "fiber" over each point	In algebraic geometry, the rank of a vector bundle is the dimension of the vector space associated with each point of the variety. Visual intuition: Consider the tangent bundle of a sphere. At each point on the sphere, there's a tangent plane. The dimension of this plane is 2, so the rank of the tangent bundle is 2. . The rank tells you the dimension of the "fiber" over each point.
Rank, for 2×2 matrices with entries in Z, M2​(Z). The rank of the projective module M2​(Z) is the dimension of the space over the field of fractions of the ring, which is 4. This corresponds to the "dimension" of the matrix algebra	in non-commutative ring theory, the rank of a finitely generated projective module P is a function that assigns a dimension to each prime ideal of the ring. Visual intuition: Consider the ring of 2×2 matrices with entries in Z, M2​(Z). The rank of the projective module M2​(Z) is the dimension of the space over the field of fractions of the ring, which is 4. This corresponds to the "dimension" of the matrix algebra.
Rank, coboundary is a function that can be written as a difference of two other functions. The rank of the coboundary tells you the number of dimensions of the "space of differences"	In dynamics, the rank of a coboundary can be the dimension of the space of functions that are coboundaries. Visual intuition: A coboundary is a function that can be written as a difference of two other functions. The rank of the coboundary tells you the number of dimensions of the "space of differences".
Rank, first homology group of a figure-eight space is Z⊕Z, which has a rank of 2. This corresponds to the two independent loops in the space. The rank is the number of loops	In homotopy theory, the rank of a homology group Hn​(X) is the rank of its free part. Visual intuition: The first homology group of a figure-eight space is Z⊕Z, which has a rank of 2. This corresponds to the two independent loops in the space. . The rank is the number of loops.
Rank, Lorenz attractor has a fractal dimension of approximately 2.06. This tells us how "space-filling" the attractor is. It's not a line (dimension 1) and not a plane (dimension 2), but something in between	In dynamical systems, the rank of a strange attractor is its fractal dimension. Visual intuition: The Lorenz attractor has a fractal dimension of approximately 2.06. This tells us how "space-filling" the attractor is. It's not a line (dimension 1) and not a plane (dimension 2), but something in between.
Automorphisms, Imagine the cyclic group Z6​ as a hexagon with vertices labeled 0,1,2,3,4,5. An automorphism is a permutation of the vertices that preserves the group operation of addition modulo 6. The identity map is a trivial automorphism. A nontrivial automorphism maps x→ − x (mod6), which corresponds to a reflection of the hexagon through a vertical axis. This reflection is a symmetry of the geometric shape that represents the group	A nontrivial automorphism of a group G is an isomorphism from G to itself that is not the identity map. It's a symmetry of the group's structure that shuffles its elements. For example, the group Z8​ of integers modulo 8 has an automorphism that maps every element to its opposite, x to −x, which is not the identity.
Automorphisms, projective line P1. Its automorphisms are given by fractional linear transformations. These are transformations of the line that are not the identity. For example, the map z↦1/z is a nontrivial automorphism. This corresponds to a geometric transformation that takes the point at infinity to zero and vice versa, and permutes other points. This is a symmetry of the projective line itself	A nontrivial automorphism of an algebraic variety X is an isomorphism from X to itself that is not the identity map. This is a geometric symmetry of the variety. The group of all automorphisms is denoted Aut(X). For example, a smooth cubic curve in the projective plane has a group of automorphisms.
Regret, suboptimality gap, comparison with best possible outcome with chosen arms	immediate definition is the expectation of the integral of the difference (suboptimality gap) between the best possible choice (argmax gives choice) and the learner's actual choice (argument).
Sublinear regret, relative standard for regret	you will always regret, so you just want the algorithm such that the average regret goes to zero.
Lai-Robbins lower bound, optimal performance constrained by information theory	the idea is to compare the suboptimal gap to the KL divergence between the probability distribution of arms. With information theory, (minimum) regret grows logarithmically with arm pulls. Therefore, one can define the limit infimum of regret at time T over log(T) must be more than the informatio ratio i.e. suboptimality gap quotiented (apply moduli space analogy here) out by KL divergence between arms
Dueling bandit regret, cases where a learner can only compare two options and pick one	define the performance measure to be the infimum of all win probabilities, then the expected dueling bandit regret can be defined as the supremum in expectation of the summation of differences related to this minimum win probability under consideration of this pair of actions.
Safe bandit regret, enforcing a penalty for violating minimum safety standards	take the per round maximum of the forgone reward and the safety violation cost. This structure ensure unsafe arms that are highly rewarding may contributed to high regret. This is also an useful heuristic to consider in real life.
Quantile regret, search space too large, find an arm whose mean reward is above a satisfactory quantile	definition is by benchmarking the expected reward of an arm whose mean reward is the (1-rho)-quantile of all mean rewards.
Pareto regret, regret should measure performance loss relative to tradeoffs	regret is first defined relative to Pareto optimal arms, Pareto regret is then defined to measure the difference between the actual performance and the performance of the optimal arm weighed by a linear combination of objectives
Regret over casual graph	analysis of regret can take place over a graph (directed acyclic, or anything with a poset structure). One define this by considering the pseudoregret. One typically defines this as a complexity measure O(d root T) where d is the number of causal features, T is the number of arm pulls.
Regret proportionality, problem difficulty arises from distinctiveness not arm count	this motivates the approximation of regrets being proportional to the root of the product between the effective dimension (dimension of the action span) and the divergence between distributions (T)
Information ratio, quantifying regret as the price per bit of information	the less information you pull, it is more likely that you will pay in regret. Therefore, one is motivated to define the information ratio as the expectation of r_t^2 (instantaneous regret at time t), note that the t^2 is a normalisation, divided by the mutual information gained at round t.
Bold format, ease of conversion	I have set up this site so that it is easy to write blog posts, focusing solely on the intuition of the math concepts I have learnt. I have set it up so that it is easy to convert it to an anki deck with my current script. I have actually ported over a lot of Anki notes over. The challenge now is how to make coherent blog posts out of these notes. This is my attempt at fitting all these in context, generating a script to fix my Anki deck.
(0,1)-category, preordered set	this is exactly a preordered set, objects are elements, morphisms exist if and only if A is less than or equal to B
(0,1)-category, poset	becomes poset if there are two morphisms A to B and B to A, then A and B are same object.
(0,1)-category, directed graph	nodes are objects, edges are morphisms, there is an identity loop on every node, and the transitive path rule for graphs serve as the composition
(0,1)-category, incident relation	incidence relation of object
(0,1)-category, subset ontology	model subset relation on a set, morphism from A to B exists if A is proper subset of B
(0,1)-category, logical implication	Objects, logical proposition, morphism from A to B means A implies B.
(0,1)-category, Boolean algebra	one can think of this as a simplifed model of Boolean algebra without complements
(0,1)-category, monoid	Monoid is a (0,1) category with single object, morphisms are elements of monoid
(0,1)-category, special functor	category with functor to the category of sets and functions, functor maps morphism to single element
(0,1)-category, terminal object	every pair of objects has a terminal object (a product), and an initial object (a coproduct)
(0,1)-category, closure properties	identity and associativity axioms satisfy closure properties of preorder relation
(0,1)-category, categorical logic	Objects: propositons, morphisms are the proofs, which there can only be one if a proposition follows from another
(0,1)-category, state machine	objects, states, morphisms means one way transition from A to B
(0,1)-category, dependency graph	objects are tasks, morphism from task A to task B means A must be done before B.
(0,1)-category, minimal structure	minimal structure that still qualifies as a category
Measure theory, linear combination of points	paradoxes arise when one defines infinite linear combination of points, therefore measure theory motivates the conditions in which this is not a problem.
Sigma ring, sets with finite measure	It has sets of finite measure.
Sigma ring, boundedness	Sigma algebra must contain entire universe, sigma-ring is bounded as it contains subsets can be built from given collections
Sigma ring, homomorphism domain	Appropriate domain for a measure to the nonnegative reals
Sigma ring, generalises Borel sets	Borel sets on real form a sigma ring, and a sigma algebra
Sigma ring, computation	Closed system of sets, with algorithms for verifying closure
Sigma ring, sigma subalgebra of power set	Sigma subalgebra of power set without requirement of containing entire set
Sigma ring, closure definition	Closed under countable union and relative complementation
Fatou's lemma, bars of histograms approximating an area under a curve. Even if some bars oscillate up and down, the “lowest horizon” formed pointwise (the lim inf) integrates to less than the lim inf of their total areas. Example	f_n(x) = χ[0,1/n](x) on [0,1]. Each integral = 1/n, but lim inf integral = 0, matching the integral of the lim inf function (0):  Integration is a map from integrals of lim infimum of f_n to the limit infimum of integrals of f_n.
Fatou's lemma, gambling outcomes Xn​ as bars. The expectation is the center of mass of these outcomes. The “eventual guaranteed payoff floor” (lim inf) always has expected value below the “eventual lim inf of averages.” Concrete example	Xn = indicator of “first n coin tosses are all heads.” Expectation = 2^{−n}, so LHS = 0, RHS = 0:
Bounded convergence theorem, bars of histograms converging pointwise to the bars of f. Because the bars never grow beyond a fixed ceiling, their shaded areas converge exactly	f_n : [0, 1] to R, with f_n(x) of norm less than equal to 1 and f_n(x) converges to f(x) pointwise, then limit as n tends to infinity of (Lebesgue integral) of f_n over 1 and 0 is integral of f from 1 to 9.
Dominated convergence theorem, f_n​ sit inside a “tent roof” given by g. Their shaded areas converge because the roof prevents runaway spikes	For f_n to f, and norm of f_n dominated by g not related to f_n in L_1 then limit of integral f_n converges to integral of f.
Dominated convergence theorem, L_1, functions wiggle but never escape a fixed “envelope.” Their areas settle onto the limit curve	DCT guarantees continuity of the integral functional on bounded sets in L1.
Irreducible representation, quick definition of abelian group	an abelian group is a group where all irreducible representations of G have degree 1. The key step for a possible proof is: define g be order of G, h is number of classes of h, (n_1, ..., n_h) be degrees of distinct irreducible representations of g, g = sum of square powers of n_i and is only equal to h (using abelian condition) if and only if all n_i are equal to 1
Cartan subgroups, Langlands functorality	representations of the general linear group corresponds to representations of Cartan subgroups.
Semisimple, exclude abelian groups	for example you do not want unipotent subgroups to be counted as a Cartan subgroup
Cofinal, Yoneda object as representative	a collection of finite groups is cofinal if all of the groups in this collection embeds into one of them. Cayley's theorem can then be stated as the collection of finite symmetric groups is cofinal. This is categorically flavored, as the cofinal object is the most free (sort of) object where forgetting parts of the cofinal object gives the relation you want. The cofinal object is an representing object.
Yoneda lemma, enabling a proof sketch for G being isomorphic to the automorphism group of forgetful functors of GSet to Set demonsrating Tannaka duality for G-sets	this is like Cayley's theorem, let C as SetG (maps from G to Set) or GSet, and we have the automorphisms (the group of invertible natural isomorphisms from F to itself, where F is the forgetful functor that sends a GSet to its underlying set) Aut(F) = Set^(SetG)(F,F) = Set^(SetG)(SetG(G, -), SetG(G, -)) = SetG(G, G) = G. Abusing notation for GSet and isomorphisms are the consequences of the Yoneda lemma's lemma.
Schur's lemma; applied on abelian groups we have G abelian, V irreducible, V = W and the nonzero linear map is a scalar multiple of an eigenvalue, therefore the result is that every subspace ofV is invariant, V is one dimensional, take homomorphism to the dual group of the multiplicative complex numbers aka the circle group aka you can use complex exponentials to represent any abelian group	Maps from V to V is G linear for every p if and only if g is in the centre of G, but the centre of G is G for an abelian group
Schur's lemma; applied on abelian groups we have G abelian, V irreducible, V = W and the nonzero linear map is a scalar multiple of an eigenvalue, therefore the result is that every subspace ofV is invariant, V is one dimensional, take homomorphism to the dual group of the multiplicative complex numbers aka the circle group aka you can use complex exponentials to represent any abelian group	Maps from V to V is G linear for every p if and only if g is in the centre of G, but the centre of G is G for an abelian group
Absolute Galois group, example of a profinite group	isomorphic to the group of profinite integers or the inverse limit of the cyclic groups of order prime.
Absolute Galois group, characterises conjugation of the reals	it is the cyclic group of two elements, one is the identity, the other is the complex conjugate.
Etale topology, gives a uniform definition of Galois groups and fundamental groups	this definition is given by Galois connections, Galois groups classifies finite field extensions, fundamental group classifies finite covering spaces, etale morphisms behaves like local homeomorphisms, define etale sheaves and etale covering spaces. The etale fundamental group is defined as the automorphism group of the fibre functor from the category of finite etale covers of X to finite sets. This definition using automorphism groups classify finite etale covers of X. If you pick X as the prime spectrum of a field, you recover the finite separable extension when you apply the definition of a finite etale cover, the etale fundamental group must therefore be the absolute Galois group. Exercise, what about X = complex algebraic varieties (hint: profinite completion of the topological fundamental group). This defines the etale fundamental group of a scheme.
Galois group of of finite field with prime power quotiented out by the same prime, cyclic groups	, this is precisely
Frobenius map, automorphism on finite fields of prime power order p^n	This is an automorphism because automorphism it sends the field to itself, since raising to the p-th power permutes all elements. Repeating the Frobenius map n-times gives identity so it is of order n. The Galois group Gal(F_p/F_p^n) is generated by the single Frobenius automorphism and can be computed as the group Z/nZ.
Frobenius map, profinite integers	If you take the case of the infinite Galois extension, this is not the integers, this is the profinite integers.
Galois correspondence, example of adjoint functors	a pair of adjoint functors between posets.
Ramification, prime ideals, imagine the prime ideals of Z as points on a number line. When we extend to a larger number field, this line is "unfolded" into a higher-dimensional space. The prime ideals in the larger field are also points, but some of them might "pile up" on top of the original prime ideal. In the case of Q(root 5)/Q, the prime (5) splits into (5) twice, which can be visualized as two points "collapsing" onto the original point. This is the geometric intuition of ramification	In algebraic number theory, ramification describes the behavior of a prime ideal p in a number field K when it is extended to a larger number field L. The ideal pO_L​ factors into a product of prime ideals in the ring of integers of L. Ramification occurs when at least one of these prime factors appears with a power greater than 1. This "bunching up" or "confluence" of prime factors is a fundamental concept. For example, in the extension Q(root 5)/Q, the prime ideal (5) of Z"ramifies" as it becomes the ideal (root 5​)^2 in the ring of integers Z[1 + root(5) / 2]
Ramification, domain P^1 as a sphere. The map z to z^2 wraps the sphere around itself twice. The points z=0 and z= infity are ramification points. This is where the wrapping "bunches up," and the pre-image of the image point is not a single point but a single point with multiplicity	For a non-constant morphism of smooth curves f: X to Y, a point p in X is a ramification point if the corresponding map on local rings is not an isomorphism. This is a geometric phenomenon where the map "folds" or "pinches" the curve at a point. The degree of ramification is measured by the ramification index, which is a key invariant. For example, the map f: P^1 to P^1 given by z to z2 is ramified at the point z = 0.
Ramification, real place is a point on a line. A complex place is a pair of points. The ramification of a real place into a complex one can be visualized as a single point on a line "splitting" into two points in a higher-dimensional space	In the theory of valuations, ramification describes the behavior of a place of a number field in an extension. A place can be a prime ideal (finite place) or an embedding into the real or complex numbers (infinite place). Ramification of a finite place means the valuation of an element changes in a non-trivial way, while for infinite places it means a real place becomes a complex one. For example, in Q(root(-1))/Q, the real place of Q is ramified because it becomes a complex place.
Ramification, Galois group as a group of symmetries of the extension. The decomposition group of a prime ideal is a subgroup that fixes the ideal. Ramification means that this subgroup is not trivial, so there are some "symmetries" that leave the ideal unchanged	In a Galois extension of number fields L/K, ramification occurs when the decomposition group of a prime ideal is not trivial. This means that there are elements in the Galois group that fix the prime ideal but not the elements in its ring. This is a subtle but deep concept that links the algebraic properties of the extension to its number-theoretic properties.
Ramification, imagine a sheet of paper. A branched cover is like folding the paper and then projecting it onto a line. The folds are the ramification locus, and the line they are projected onto is the branch locus. The map from the curve to the line is a branched cover that folds the curve at the points where the tangent is vertical	A branched cover is a surjective map of varieties with ramification. The set of ramification points is called the ramification locus, and its image is the branch locus. The map from a variety to its base is a local isomorphism everywhere except at the ramification locus. For example, the map from the curve y^2 = x(x−1)(x−2) to the affine line given by projection to the x-axis is a branched cover.
Ramification, imagine a map from a disk to a disk. A critical point is a point where the map "flattens" or "folds" the disk. The dynamics around this point are very complex and can lead to chaotic behavior	In dynamics, ramification occurs in complex dynamics when a map has critical points. A critical point is a point where the derivative of the map is zero. This is a point where the map "folds" or "pinches." For example, the map z to z^2 has a critical point at z=0.
Ramification, canonical divisor is a geometric object that is a "dual" to the tangent bundle. It is a line bundle that is related to the ramification of the map	The canonical divisor of a curve is a divisor that is related to the ramification of the curve. The degree of the canonical divisor is related to the genus of the curve and the ramification of the map.
Ramification, Hilbert symbol is a "map" that measures the ramification. It is a way of "quantifying" the ramification	The Hilbert symbol is a symbol that measures the ramification of a number field extension. The Hilbert symbol is a key tool in class field theory.
Ramification, Serre duality is a "duality" between two geometric objects. The ramification of the map is a key ingredient in this duality	The concept of ramification is used to formulate Serre duality, which is a duality theorem for coherent sheaves on a scheme. The duality is between the cohomology of a sheaf and the cohomology of its dual.
Ramification, covering space is a "bundle" of spaces. A ramified covering space is a covering space that "folds" or "pinches" at some points	A ramified covering space is a generalization of a covering space. A covering space has the property that the fibers are discrete sets. A ramified covering space has the property that the fibers can have "ramification."
Ramification, moduli space of curves is a geometric object. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms	The concept of ramification is used to study the moduli space of curves. The moduli space is a geometric object that classifies curves. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms.
Galois group, polynomial x3−2=0. The roots are primitive roots of unity.The splitting field is L = Q(cube root of 2, omega). The Galois group is Gal(L/Q) is isomorphic to S_3​, the symmetric group on 3 letters. The elements of the group permute the three roots. This can be visualized as the rotations and reflections of an equilateral triangle whose vertices are the three roots in the complex plane. The rotation by 120 degrees corresponds to the automorphism σ that sends cube root of 2 to omega cube root of 2	Galois group is the group of all automorphisms of a field extension L/K that fix the base field K. It is a finite group that encodes the symmetries of the roots of a polynomial. The fundamental theorem of Galois theory establishes a correspondence between the subgroups of the Galois group and the intermediate fields of the extension.
Galois group, covering map p	R→S1 given by p(x)=(cos(2πx),sin(2πx)). The fibers are the preimages of a point on the circle, which are the integer points on the real line: {...,−1,0,1,...}. The deck transformation group is the group of translations by integers, Z. This can be visualized as the integer lattice on the real line, with the group Z acting by shifting the entire line by an integer. The Galois group is this group of shifts:  In topology, the Galois group of a regular covering space E to B is the group of deck transformations of the covering. The fundamental group of the base space, π^1​(B), acts on the fibers, and the group of deck transformations is the group of symmetries of this action.
Galois group, elliptic curve E given by y2=x3−x. The automorphisms of this curve are the "symmetries" of its geometric shape. For example, (x,y)→(x,−y) is an automorphism. This can be visualized as the graph of the elliptic curve (in the real plane), which is a symmetric shape. The group of symmetries that preserve the origin of the curve is the Galois group	For a non-singular projective curve X over an algebraically closed field, its Galois group is a finite group of automorphisms of X. For example, the group of automorphisms of an elliptic curve is a finite group.
Galois group, number field K, the "space" Spec(K) is not a usual geometric space but a set of points (the prime ideals). A finite étale covering corresponds to a finite field extension. The Galois group is the group of symmetries of this covering. This can be visualized as a "graph" where the vertices are the prime ideals and the edges represent how they "split" or "ramify" in a field extension. The Galois group is the group of automorphisms that preserve the structure of this graph	The Galois group of a field K can be generalized as the étale fundamental group of Spec(K), denoted π1et​(Spec(K)). This is a profinite group that classifies all finite étale coverings of Spec(K).
Galois group, a field K, consider the tree of all finite extensions of K. The root is K. The branches from a field L are the extensions of L. The Galois group of the maximal abelian extension of K acts on this tree. This can be visualized as a dendrogram or a family tree, where the Galois group is a group of symmetries that rearranges the branches while preserving the relationships between the fields	A Galois group can act as a group of automorphisms of a rooted tree. The tree represents the field extensions, where each node is a field and the branches are the extensions.
Galois group, the extension Q(i)/Q with Galois group {1,σ}. The prime p=5 splits into ideals (2+i) and (2−i). The Frobenius element for (2+i) is the identity, and for (2−i) it's the identity as well (they are in the same orbit). For p=3, the prime is inert, and the Frobenius element is σ. This can be visualized as a collection of points (the prime ideals), with the Frobenius element acting as a transformation on them. The Galois group is the group of all these transformations	For an abelian extension of a number field L/K, the Galois group is the group generated by the Frobenius automorphisms. The Frobenius element at a prime p of K is the unique automorphism that acts as the p-th power map on the residue field.
Galois group, homological algebra, cohomology groups are built from complexes of modules and measure "cycles that are not boundaries." Consider the module L× and the group G. We can visualize the cohomology group H1(G,L×) as the set of "loops" in a complex of G-modules that cannot be "filled in" or "shrunk to a point." The fact that H1(G,L×) is trivial is a statement that these loops are "fillable."	In homological algebra, the Galois group G=Gal(L/K) acts on the multiplicative group of the field L×. The cohomology group H1(G,L×) measures the "failure" of Hilbert's Theorem 90, which states that any element with norm 1 is of the form σ(x)/x. This is a fundamental result in Galois cohomology.
Galois group, central simple algebra can be thought of as a non-commutative matrix ring. For example, the quaternion algebra. The Galois group is the group of symmetries of the multiplication rule of this non-commutative ring. This is a powerful tool for studying the Brauer group and the arithmetic of number fields	The Galois group of an extension L/K is the group of symmetries of a central simple algebra A over K that splits over L. The algebra A can be viewed as a twisted matrix algebra.
Galois group, spectrum of a field, Spec(K), is just a single point. But the spectrum of its separable closure, Spec(Ksep), is a highly complex topological space. The Galois group is the group of homeomorphisms of this space. This can be visualized as a group that acts on this highly structured set of "points," which are the prime ideals of the separable closure	The Galois group of a field K is the group of continuous automorphisms of the spectrum of the separable closure of K. This is a profound generalization of the classical Galois group.
Galois group, projective line is a circle. The Galois group can be viewed as the group of rotations and other symmetries of this circle. For example, the Galois group of Q(i)/Q acts on the projective line over Q(i) by sending points to their complex conjugates	The Galois group of a field extension can be realized as the group of automorphisms of the projective line P1 over the field that fixes the base field.
Galois group, a vector space over a finite field. We can change the basis of this vector space, and the matrix of a linear transformation changes accordingly. The Galois group can be visualized as a group of transformations that "twist" the scalars of the vector space. This twisting gives rise to new representations, and the Galois group is the group of these twists	In modular representation theory, the Galois group of a field extension acts on the modules over a group ring. The action of the Galois group on the coefficients can change the structure of the module, and this change is described by the Galois group.
Galois group, consider the ring of integers Z[root 2] as a lattice in R2 spanned by (1,0) and (root 2,0). The Galois group of Q(root 2)/Q is the cyclic group of order 2, with the non-trivial element σ(root 2)=- root 2. This can be visualized as a reflection across an axis that passes through the origin, which acts as a symmetry on the lattice	For an extension of number fields, the Galois group acts on the ring of integers as a group of automorphisms. This ring of integers can be viewed as a lattice in a real vector space.
Galois group, pro-finite ring is an inverse limit of finite rings. This can be visualized as a "nested series" of rings, each one fitting inside the previous one, with the Galois group acting as a symmetry group on this entire structure	The Galois group of a field extension is the group of continuous automorphisms of the valuation ring of the separable closure of the field. This valuation ring is a pro-finite ring.
Galois group, can be visualized as a nested set of boxes. The outer box is the field M, the inner box is L, and the innermost is K. The Galois group of M over K is the group of symmetries of the largest box. The normal subgroup is the group of symmetries of the box M that fixes the box L, and the quotient group is the symmetries of the box L over K	The Galois group is the group of automorphisms of a tower of fields. The structure of the group is encoded by the extensions. For example, if we have K in L in M, then Gal(M/K) has a normal subgroup Gal(M/L) with quotient Gal(L/K).
Galois group, groupoid is a category where all morphisms are isomorphisms. The Galois group can be seen as the group of automorphisms of the groupoid whose objects are the field extensions of K and whose morphisms are the K-algebra isomorphisms	The Galois group can be thought of as the automorphism group of an object in a category. For a field extension L/K, the Galois group is the automorphism group of the functor from the category of K-algebras to sets.
Galois group, a prime p in Z and the extension Q(root -19​)/Q. The prime p can split into two primes, or remain inert. This can be visualized as a graph with two "nodes" for the prime ideals above p, with the Galois group acting as the group of symmetries of this graph	The Galois group of a field extension can be the group of symmetries of a graph. For example, the graph of prime ideals lying over a given prime.
Frobenius element, consider a prime p in Z. It corresponds to a "point" on the "number line" Z. In an extension like Q(i)/Q, the prime p either splits into two points, remains one point, or ramifies. The Frobenius element can be seen as a shift operator that sends points in the fiber above p to their conjugates. Artin reciprocity is the law that says the "average shift" over all primes is a predictable global quantity that only depends on the idele class group	For an extension of a global field, the Frobenius element is a canonical generator for the decomposition group of a prime. It acts on the residue field by raising to the power of the size of the residue field. Artin reciprocity connects the global behavior of these local operators.
Isbell adjunction, visual interpretation of localisation in commutative algerbra	one can do localising via Isbell adjunction. Localisation can be seen as a restriction to the complement of subspace Y included into X such that elements of multiplicative subset S vanish when you localise at S. This looks like zooming in onto the space, but only seeing the surroundings. So you only see what is nearby in neighbourhood but not what the object is, compare this quotient where you see what is inside the thing, everything else vanish. In commutative algebra side, it means the relation is equal and made zero, in geometry it means what you see is left because that is the curve = 0. This motivates the name localisation.
Ring, two operations	a ring can viewed as a commutative group under addition, and a monoid under multiplication.
Ring, number system	the basic example of a ring is the integers. In fact, the ring is the initial object in the category of commutative rings. This means I can represent every other ring by a ring homomorphism that forgets certain properties of the ring. The prime spectrum of the ring of integers, Spec Z, is therefore the final object in the category of (affine) varieties (or for more general constructs). This means when I draw a picture of a scheme, I can forget parts of the scheme to get back Spec Z.
Ring, function space	a ring can be viewed as a set of functions from a space to a field, addition and multiplication are defined pointwise. This is the ontology required for polynomial rings. Recall that polynomials are raised to integer powers.
Ring, linear operator algebra	Consider linear operators acting on a vector space or a module. Addition is the sum of operators, multiplication is composition of operators.
Ring, closure axiom	one of the nice properties inherited from the ring of integers is the closure property. When one add, subtract, or multiply elements of the ring, then it will still be a ring element. This is the closure property of rings.
Ring, division free domain	Start with a field, remove requirement for multiplicative inverses
Ring, scalars on modules	Ring elements act as scalars on modules, generalising vector spaces
Ring, contains ideals	Rings contain ideals that capture the essence of divisibilities and factor rings or quotient rings. In fact, from the perspective of algebraic number theory, one can take integral closure to obtain unique prime factorisation of ideals.
Ring, ring of integers as infinite number lines and Gaussian integers as 2D lattice	The rings of integers of number fields are higher-dimensional generalizations, like a 2D lattice for the Gaussian integers, which still retain the essential arithmetic structure of addition and multiplication.
Ring, enabling zero divisors	Rings allow product to be zero. This leads to nonunique factorisation. This is associated with the characteristic of th ering.
Rings, integer characteristic	Number of times to add multiplicative identity to itself to get additive identity. Example in Z_2, 1 + 1 = 0.
Ring, geometric point	a ring may be designed to be a locally ringed space with nformation associated with a point in geometric space
Ring, as a group object	Group object in the monoidal category of abelian groups
Ring, endomorphism ring	a ring can be viewed as a set of endomorphisms (structure preserving maps) of an abelian group, addition is pointwise sum of maps, multiplication is their composition
Finite module, chain condition	the ascending chain condition on submodules satisified if the ring is Noetherian.
Finite module, projective object in category of modules	a projective object in the category of modules, means suitable lift exists.
Finite module, applications to rings as actions	finite modules are the multiplication table of a ring, module elements are multiplied by the ring elements
Finite module, vector space	generalisation of finite dimensional vector spaces. In general, modules are generalisations of finite dimensional vector spaces. Therefore, one can also think of representation theory as maps from groups to modules.
Finite module, homomorphic image of free module	Homomorphic image of free module of finite rank, "quotient" of free module
Finite module, spanning set	a finite module has a finite spanning set
Finitely presented module, finite descriptions	Finite generators, finite relations. Computational.
Finitely presented module, kernel of map	Kernel of map between two modules of finite rank
Finitely presented module, double finiteness	Finite generating set, and finite relations. More subtle than finitely generated.
Finitely presented, quotient	Quotient of finitely generated free module, submodule of relations is also finitely generated
Finitely presented module, vector space with relations	finitely presented module is a generalization of a finite-dimensional vector space where the "basis vectors" are subject to a finite number of linear relations (over a ring instead of a field).
Finitely presented module, projective	Over a Noetherian ring, a finitely presented module is a projective module.
Finitely presented module, flatness and projective	module is finitely presented and flat if and only if it is projective.
Finitely presented module, coherent sheaf	finitely presented module corresponds to a coherent sheaf
Finitely presented modules, coherent sheaf categories	category of finitely presented modules is equivalent to the category of coherent sheaves on a ring's spectrum
Ideal, subring with absorption	Assume two sided, coefficient r in R, a in I, ar in I, ra in I, two sided
Ideal, kernel of homomorphism	Kernel of ring homomorphism always an ideal of ring R
Ideal, element generator	Principal ideal, generated by one element, multiples of a in the ring
Ideal, equivalence class partition	ideal I in ring R define equivalence classes of cosets, forming quotient ring R/I, elements form r + I, mod out an ideal to create new a simpler ring
Ideal, lattice operations	meet is intersection of ideals, join is their sum
Ideal, primitive element in domain	Prime ideal, product of two elements in ideal, at least one of its elements must be, generalising prime number
Ideal, maximal, consider case of Z/2 versus Z/4	Maximal ideal, not properly contained in any ideal, maximal means what can be made into a unit is made into a unit or invertible, largest possible quotient rings aka fields, Z/2 is a field, everything is invertible, (2) has identified all even numbers so elements are {0,1}, Z/4 is not a field, not maximal, {0,1,2,3}, still cannot find inverses for 2b = 1 (mod 4).
Ideal, local geometry	Prime ideal, irreducible algebraic variety, this forms prime spectrum
Ideal, sheaf stalk	Ideal is stalk of sheaf of ideals on a topological space
Ideal, encoded by morphisms	implicitly defined by morphism properties, example kernels of morphisms (ring homomorphisms in category of rings) means morphisms encode ideals
Ideal, filters for ring operation	Ideals absorb under multiplication, stronger than simple additive subgroup
Ideal, radical	Radical ideal, raised to some power fall into the ideal.
Ideal, filter in order	In poset of ideal, maximal ideals are maximal elements
Ideals, representation of module	Ideal, submodule of a ring, ring as module over itself
Ideal, direct limit	Direct limit of a system of principal ideals or a colimit.
Ideal, annihilator of a module M	set of all elements of ring R that multiply with every element of module M to produce 0.
Ideal, cokernel	cokernel of inclusion map I in R is quotient ideal R/I for abelian categories
Ideal, finitely generated	finitely generated ideal, written as finite sum of principal ideals
Ideal, primary as fuzzy points	A primary ideal is a proper ideal Q such that if a product ab is in Q and a is not in Q, then some power of b is in Q. Visual Intuition: Primary ideals are like "fuzzy points" or "infinitesimal neighborhoods" around a point. The radical of a primary ideal is a prime ideal, which means it is a point with some "fuzzy" information attached to it.
Tensor product, universal bilinear map	Vector space with bilinear map, factors uniquely through it
Tensor product, free vector space modulo relations	Take free vector space V * W, mod out subspace generated by relations that enforce bilinearity, distributive law and constants
Tensor product, basis construction	set of all formal products form basis for tensor product, simple extension of basis so dimension of tensor product is simple product of dimension
Tensor product, representation of multilinear maps	space of all bilinear maps from dual to underlying field
Tensor product, functor	bifunctor from category Module to itself, take pair of spaces to tensor product, pair of linear maps to tensor product map
Tensor product, modules over commutative ring	Replace vector space with module, Cartesian product becomes tensor product
Tensor product, algebras	use (a ** b)(a' ** b') = aa' ** bb'
Tensor product, adjoint functor	left adjoint to hom functor, for hom in R as inner product form (U * V, W) = (U, (V, W))
Tensor product, product in monoidal category	associative and commutative binary operation defining products in monoidal categories
Tensor product, colimits	Tensor product of modules, colimit over diagram with bilinearity relations
Tensor product, global section space considering tangent spaces	Tensor product of tangent spaces at a point, space of tensors at that point
Tensor product, space of sections of product bundle	Tensor product of two vector bundles over manifold is new vector bundle, fibres are tensor products of the original fibres
Tensor product, operation of coherent sheaf	Tensor product of coherent sheaf is a coherent sheaf
Tensor product, combine spaces	Topological tensor product is a topological vector space that is formed from two topological vector spaces
Tensor product, commutative product in cohomology	cup product turns cohomology group into a graded ring, ring multiplication is tensor product
Tensor product, machine learning	tensor, multi dim array of number, tensor product, operation for combining these arrays
Tensor product, generalises bilinear forms	Turns bilinear forms on V cross W into linear maps on V tensor W
Tensor product, two affine lines over the complex numbers, A_C1​=Spec(C[t]) and A_C1​=Spec(C[u]). Their product is the affine plane AC2​=Spec(C[t] tensor_C ​C[u]). This tensor product is isomorphic to C[t,u]. Geometrically, this is a literal multiplication of two lines to form a plane, but the tensor product provides the algebraic machinery for it. It's how we build higher-dimensional spaces from lower-dimensional ones	The tensor product of two schemes X and Y over a base field k, denoted X ×_k ​Y, is a scheme whose ring of functions is the tensor product of the rings of functions of X and Y. Specifically, for affine schemes Spec(A) and Spec(B), their product is Spec(A tensor_k ​B). This construction allows us to "multiply" geometric objects.
Tensor product, two representations of a group G, say the cyclic group C_2​={e,a} acting on two 1-dimensional vector spaces, V1​ and V2​, over a field of characteristic 2. The action is given by matrices. The tensor product is a new representation on the space V1​⊗V2​ which is 1-dimensional. The matrix for the action of a on the tensor product is the product of the matrices for the action of a on V1​ and V2​. This is a way of "multiplying" the representations, which is a powerful way to understand the structure of the group	The tensor product of modules is a key operation in modular representation theory. For two modules M and N over a group algebra kG, their tensor product M tensor_k ​N is a new module over kG with the diagonal action g(m tensor n)=gm tensor gn. This construction allows us to build new representations from old ones, and it is a key tool for understanding the structure of representation blocks.
Tensor product, imagine two curves C1​ and C2​ that both project to the same line L. The fiber product C1 ​cross_L ​C2​ is a new curve whose points are pairs of points (p1​,p2​) from C1​ and C2​ that map to the same point on L. This is like a "pullback" of the two curves. For example, if we take two lines that intersect at the origin in the plane, their fiber product over the origin is just the origin itself. This is a very powerful way to capture how two geometric objects relate to a common base	The fiber product of two schemes X and Y over a base scheme S, denoted X cross_S ​Y, is a scheme that captures the "intersection" or "common parts" of X and Y over the base S. It is a generalization of the tensor product of rings. For affine schemes, Spec(A) and Spec(B) over Spec(C), the fiber product is Spec(A tensor_C ​B).
Tensor product, a line bundle on a manifold, which is a collection of lines attached to each point of the manifold. For example, the tangent bundle of a circle is a line bundle. The tensor product of two line bundles is a new bundle where the line at each point is the tensor product of the two lines. For example, if we take the tangent bundle of a circle and tensor it with itself, we get a new bundle. This is a way of "squaring" a line bundle	tensor product of line bundles is a key operation. For two line bundles L and M on a scheme X, their tensor product is a new line bundle L tensor {O_X} ​​M. This operation corresponds to multiplying the sections of the line bundles.
Tensor product, the character of a representation is a function on the group that tells us about the trace of the matrices. We can visualize the characters as functions on a graph of the group. The tensor product of two representations corresponds to a new character which is the product of the two original character functions. This is a way of "multiplying" the functions on the group	the character of a tensor product of representations is the product of the characters of the individual representations. The character X_{V tensor W} ​(g)= X_{V​(g)} X_{W​(g)}. This is a very powerful property that allows us to compute the character of a new representation by simply multiplying the characters of the old ones.
Tensor product, two topological spaces, say two circles. The tensor product of their chain complexes gives us the chain complex of the torus. The homology of the torus is the tensor product of the homologies of the circles. This is a way of "multiplying" the spaces in a homological sense. The tensor product of the chain complexes is a combinatorial object that tells us about the holes of the product space	The tensor product of chain complexes is a key construction in homotopy theory. It is used to compute the homology of a product of spaces. The Eilenberg-MacLane space K(A,n) has a homology group that is the tensor product of the homology of the space with a module.
Tensor product, two dynamical systems, one on a circle and one on a line. The topological entropy measures how fast the number of orbits grows. The tensor product is a new system on a cylinder. The topological entropy of the cylinder system is the sum of the entropies of the circle and the line. This is a way of "adding" the complexity of two systems	The topological entropy of a tensor product of dynamical systems is the sum of the topological entropies of the individual systems. This is a measure of the complexity of the combined system.
Tensor product, an elliptic curve over the real numbers. It can have a number of connected components. If we extend the base field to the complex numbers, the curve becomes a torus. This is a change of base. The tensor product of the scheme of the elliptic curve with the scheme of the complex numbers is the new scheme. This is a way of "multiplying" a real object with a complex one	The tensor product of schemes over different fields is a way to change the base field. For a scheme X over a field k and a field extension L/k, the new scheme is X cross_Spec(k)​ Spec(L). This is a fundamental construction for studying schemes over different fields.
Tensor product, polynomial ring in three variables. We can build a chain complex for it by taking the tensor product of three simple chain complexes, one for each variable. The resulting complex has a nice combinatorial structure. This is a way of "multiplying" the one-variable problems to get a multi-variable one	The Koszul complex is a chain complex that is a tensor product of simpler complexes. It is a fundamental tool for computing the homology of a module over a polynomial ring.
Tensor product, a collection of indecomposable modules for a group algebra. We can form a new ring where the elements are formal sums of these modules. The multiplication in this ring is the tensor product of the modules. This is a way of turning the category of modules into an algebraic object that we can study with the tools of ring theory	The Green's ring of a group algebra is a ring whose elements are the isomorphism classes of finitely generated modules. The addition is the direct sum, and the multiplication is the tensor product.
Quotient ring, form of the elements of the cosets of ideal	for the cosets of the ideal, the elements are of a form a + I
Quotient ring, definition of set via equivalence classes	set of all equivalence classes under a equivalent to b if and only if a - b is in I where I is an ideal
Quotient ring, partition of ring	Partition ring into disjoint coset, each coset has a ring structure
Quotient ring, kernel of homomorphism	a quotient ring isomorphic to the image of a ring homomorphism, where the ideal is the kernel of the homomorphism
Quotient ring, modulo ring	ring modulo an ideal denoted R / I, example Z/2Z, generalising modular arithmetic from integers to any ring
Quotient ring, homomorphic image	homomorphic image of the canonical projection map from R to R/I
Quotient ring, measure of collapse	degree which ring collapses when elements ideal are treated as zero
Quotient ring, data structure	modelled as data structure representing a ring with a zero out property for all elements in the ideal
Quotient ring, construction of field	field constructed by quotienting ring with maximal ideal
Quotient ring, collapse elements of ideals, example of ideal like a line passing through the origin, quotient ring collapses the plane along this line	"collapsing" all the elements of an ideal I in a ring R to zero. The elements of the quotient ring are the cosets of the ideal. Visual intuition: Think of a plane (the ring R). An ideal I is a line passing through the origin. The quotient ring R/I is like collapsing the plane along this line, creating a new, smaller space
Quotient ring, kernel as set of things you cannot tell apart	kernel is the set of elements that are mapped to zero. Visual intuition: The kernel is the "set of things you can't tell apart" after a transformation.
Quotient ring, quotient module is collapsing vector space onto line	vector space M. A subspace N is a line. The quotient module is like collapsing the vector space along this line.
Isotone Galois connection, adjoint functors	adjoint functors between two posets
Isotone Galois connection, order preserving maps	pair of order preserving maps between two posets
Isotone Galois connection, duality of lattices	establishes poset duality
Isotone Galois connection, special case of categorical adjunction	categories are ordered sets, so Galois connections are special case of adjunctions
Antitone Galois connections, order reversing duality	order reversing maps between two ordered sets
Antitone Galois connections, contravariant duality	contravariant adjunction, reverses direction of inequalities
Antitone Galois connection, generalises annihilators and ideals	generalises annihilators in linear algebra, and ideal in ring theory
Torsion in commutative algebra, module element annhilation	module element annhilated by nonzero element
Torsion in commutative algebra, finite order	all elements of finite order
Torsion, measure of locality	measures the extent a module is local, nonzero ring element can act as local zero
Torsion, kernel of localisation is field of fractions is torsion submodule	torsion submodule is the kernel of the natural map from a module to its localization at the zero ideal, which is the field of fractions of the ring.
Torsion, decomposition	"finite part" of a finitely generated module over a principal ideal domain (PID), as per the Fundamental Theorem of Finitely Generated Modules.
Torsion, dual of torsionfree, definition of torsionfree module	conceptual dual of a torsion-free module, where every non-zero element of the ring acts injectively
Torsion, collapsed structure	"collapsed" or "simplified" structure where elements are not unique, but are identified via a non-zero annihilator.
Torsion, homological invariant	homological invariant captured by the Tor functors, which measure the extent to which tensor products fail to be exact.
Torsion, measure of non-flatness	how far a module is from being a flat module, a module whose tensor product with other modules preserves exact sequences.
Torsion, injective from annihilated	boundary phenomenon in a module, where the behavior of its elements changes from "injective" to "annihilated."
Torsion, classification purposes via decomposition	primary tool for classifying modules over rings, particularly PIDs, by decomposing them into a free part and a torsion part
Projective module, direct summand of free module	direct sum of projective module and another module forming a free module
Projective module, lifting property	lifts surjective module homomorphism module M to module N and any homomorphism projective module P to module N using ring homomorphism from projective P to module M. Very similar to direct sum definition.
Projective module, split short exact sequence	projective if every 0 -> K -> M -> P -> 0, is split exact aka M is isomorphic to direct sum of K and P
Projective module, exactness of Hom functor	TFAE: (1) projective; (2) Hom(P, - ) is exact.
Projective module, projective resolution	Projective resolution of length 0, -> P_1 -> P_0 -> M -> 0, all P_i are projective
Projective module, dual basis	for a projective module, a dual basis exists, linear forms in Hom(P, R) for coefficients x_i in projective module P, ring R.
Projective modules, flat	All projective modules are flat modules, flat modules preserve injectivity under tensor product
Projective modules, condition via localisation at each prime ideal to get a free R_p module	TFAE: (1) for each and every prime ideal p in ring R, localised P_p is a free R_p module; (2) P is projective.
Projective module, idempotent endomorphism	TFAE: (1) P is finitely generated projective module; (2) P is the image of idempotent endomorphism of a free module. Idempotent endomorphism is map p from F to F, such that p^2 = p.
Projective module, 0 Ext group	TFAE: (1) module projective; (2) Ext^1_R(P, M). Vanishing of first Ext group means it is acyclic in some sense
Projective module, locally free sheaf	TFAE (1) finitely generated projective module over commutative ring R; (2) locally free sheaf on affine scheme Spec(R)
Projective module, vector bundles	Projective modules are to free modules (take resolutions of free modules) as vector spaces are to trivial bundles (use many trivial bundles to get vector space, no need to consider global twisting)
Projective module, flat and finitely presented	For finitely generated modules, being projective is equivalent to being flat (tensor product is exact, resolution of free modules gives flat module) and finitely presented (generators and relations)
Projective module, over local ring and locally free	A projective module over a local ring is always free.
Projective module, unimodular row	fg projective module of rank 1 is a unimodular row that can be completed to an invertible matrix.
Projective module, monoid	isomorphism classes of finitely generated modules form a commutative monoid under direct sum, construction of K-group K_0(R)
Projective module, projective cover	projective cover is minimal surjection of projective module, TFAE: (1) projective module; (2) projective cover of every homomorphic module
Projective module, faithfully flat module can generate entire module category	TFAE: (1) finitely generated projective module generating entire module category; (2) faithfully flat module
Projective module, torsion free comparison in Dedekind domains	TFAE: (1) projective over Dedekind domain; (2) torsionfree over Dedekind domain. Show that a module is direct sum of finitely generated free module and fractional ideal, in a Dedekind domain, finitely generated module is isomorphic to direct sum of free module and an ideal.
Projective module, sections of vector bundle like object	modules whose elements are "sections" of a vector bundle like object
Injective module, categorical dual to projective module	Reverse arrows in commutative diagram for projective module gives injective module diagram
Injective module, Hom-tensor adjunction	Contravariant hom functor, so becomes hom-tensor duality
Injective module, cogenerator	TFAE: (1) module C is injective cogenerator; (2) injective and for all nonzero module M, nonzero homomorphism from M to C
Injective module, Matlis theorem, local structure	Matlis theorem is for a commutative Noetherian ring, every injective module is uniquely a direct sum of indecomposable injective modules.
Injective module, injective hull of quotient	every indecomposable injective module over a commutative Noetherian ring R is isomorphic to the injective hull of a module of the form R/p for some prime ideal p of R. This establishes a powerful correspondence between indecomposable injective modules and prime ideals.
Injective module, flabby sheaf	flabby sheaf, any section over open subset can be extended as a section over the full space. Geometric parallel to homomorphism extension property of injective modules
Injective modules, divisibility has no holes	divisible module, all elements can be divided by any nonzero ring element, module has no holes that prevent division
Injective module, space of functions	space of functions with no constraint on domain extension, corresponds to sections over opens becoming sections over the whole space
Injective module, definition via corepresenting object	Q is injective object if corepresenting Hom(-, Q) maps monomorphisms to epimorphisms, formally dual for projective modules
Injective module, direct products	direct product of any family of injective modules is an injective module. The corresponding property for direct sums holds only for Noetherian rings.
Injective module, no proper essential extensions	module Q is injective if and only if it has no proper essential extensions. An essential extension of a module M is a module N containing M as a submodule, such that every nonzero submodule of N has a nonzero intersection with M.
Injective module, injective hull of any module	module M has a minimal injective module containing it, called its injective hull, denoted E(M). A module Q is injective if and only if it is its own injective hull. The injective hull is an essential extension, meaning Q is an essential submodule of E(Q).
Injective module, divisible module	integral domain R, a module Q is injective if and only if it is divisible. A module M is divisible if for every nonzero element r in R and every m in M, there exists n in M such that rn in m. For example, the rational numbers Q are an injective Z-module.
Injective module, injective resolution	0 to M to I_0 to I_1, I_i all injective modules
Injective module, splitting of short exact sequence	0 -> Q -> M -> N -> 0 is split exact, M is isomorphic to direct sum of Q and N, Q is injective module, N is projective module
Injective module, homomorphism extension	TFAE: (1) Q is injective module; (2) injective if for any submodule A of an R-module B, and any homomorphism f : A to Q, there exists an extension homomorphism g: B to Q such that g restricted to A is homomorphism f.
Flat module, preserves tensor product	Tensor product functor (- *_R M) is exact
Flat module, preserve monomorphisms	tensor product is always right exact, a module M is flat if and only if for every injective module homomorphism ϕ: A into B, the induced map ϕ ** 1_M​ : A **_R ​M to B **_R ​M is also injective. This means that tensoring with a flat module doesn't "collapse" submodules.
Flat module, condition for a flat module to not have torsion	for a module over an integral domain (product of nonzero is nonzero), flat means torsionfree
Flat module, acyclic Tor functor	TFAE: (1) flat module; (2) Tor_1^R(N, M) = 0 for all modules N.
Flat module, direct limit of free module	direct limit of finitely generated free module
Flat module, locally free	localisation every prime ideal is free module over the local ring of prime module, flatness is a local property
Flat module, example of flat module that is not a projective module	Z-module Q is flat but not projective
Flat module, faithfully flat	a module is faithfully flat if tensor product with it preserves exactness if and only if original sequence is exact
Flat module, direct sum	direct sum of an arbitrary family of modules is flat if and only if each module in the family is flat. This is a very useful closure property.
Flat module, module of scalars	flat module can be thought of as a module that "behaves like the base ring" with respect to the tensor product. It doesn't introduce any new relations or "torsion-like" behavior when tensoring.
Flat module, flat morphisms of schemes	morphism of schemes X to Y is flat at a point X if the corresponding local ring map is flat module, no deformation of fibres
Flat module, vector space analogy	over a field, every module is vector space, or every module is flat, because every short exact sequence of vector spaces split.
Flat module, local freeness	correct generalisation of locally free modules for non fg modules or non-Noetherain ring
Flat modules, compare flatness to torsion	integral domains with no torsion generalises to broader notion of flatness, torsion is about annhilators module having nonzero element m annihilated by nonzero element r is a form of torsion.
Flat modules, geometric slicing or flat morphisms as a family of schemes	flat morphism is family of schemes with nicely parametised base schemes with consistent dimension and no unexpected jumps
Flat modules, finitely presented and flat	fg module over Noetherian ring is flat if and only if it is projective
Flat modules, unimodular row	Replace projective module using relation and lifting property. Module is flat if every relation on finite set of elements of M lifts to a relation on the free module where M is a quotient.
Injective module, similar to Q	Q as Z-module is prototype example for injective module
Injective resolution, motivation for Ext functor	Every module has an injective resolution so this can be used to derive Ext functors
Ext functor, cohomology, cochain and injective resolution	Take injective resolution, take cochain complex, take cohomology of this complex, get Ext group
Injective module, enough injectives	To form Ext functors need enough injectives, need existence of monomorphism from any object to injective object
Ext functor, contravariant construction and covariant construction	Ext of dimension i over ring R for (A, B) is contravariant in A (take cohomology of cochain complex of projective resolutions of A) and covariant in B (take cohomology of cochain complex of injective resolutions of B).
Nakayama's lemma, finiteness annihilator	M be fg module over commutative ring R, I be an ideal of R, if IM = M, then there exists an element x in R such that x = 1 mod I, and xM = 0.
Nakayama's lemma, local ring version	Let R be comm. ring, m maximal ideal, (R, m) be local ring, let M be a fg R-module if M = mM, M = 0, most common form, immediate consequence of finiteness annhilator definition, pick I = m, 1 - x in m, x is unit xM = 0 implies M = 0.
Nakayama's lemma, basis version	Commutative ring R, maximal ideal m, (R, m) local ring, M a finitely generated R-module, if the images of a set of elements m_1 to m_n form a basis for the vector space M/mM over the residue field R/m, these elements generate M as an R-module.
Nakayama's lemma, minimum generators version	Min. generators of fg module over local ring (R, m) equal to dimension of vector space M/mM over residue field R/m. Quotient ring is like vector space, R/m is residue field, m maximal ideal.
Nakayama's lemma, submodule version	Let M be fg R-module, N submodule of M, I is ideal of R contained in Jacobson radical of R, if M = N + IM, then M = N.
Nakayama's lemma, local result	local result since works on maximal ideals, but can be applied to global statements. Example, homomorphism of fg modules is surjection iff induced map of localisation on every maximal ideal is surjection
Nakayama's lemma, germ of objects	local ring at point of scheme corresponds to set of neighbourhoods of that point. Nakayama's state that if fg module is trivial at infinitesimal neighbourhood of the point (stalk or filtered colimit of fg modules at that point is zero), then the module is zero in a neighbourhood
Nakayama's lemma, algebraic homotopy theory, Jacobson radical is infinitesimal neighbourhood of the closed point, consider connected components of local ring	About connected components in local ring, Jacobson radical is infinitesimal neighbourhood of the closed point, lemma says that if module is zero in the neighbourhood, must be zero globally.
Nakayama's lemma, sheaf theory	coherent sheaf of modules (finitely presented) F on a scheme X, if stalk F_x is 0 at every point in X, then F is the zero sheaf.
Nakayama's lemma, vector bundle analogy	if vector bundle is trivial when restricted to an infinitesimal neighbourhood of a point, must be trivial in a full neighbourhood
Nakayama's lemma, conditions for filtered ring	associated graded ring Noetherian, filtration is "nice"
Nakayama's lemma, derived algebraic geometry	spectrally ringed space (X, O_X), if a perfect complex of O_X modules P have zero fiber (space of sections instead of volumes) at all points of the space (infinitesimal neighbourhood), then the complex is 0
Nakayama's lemma for perfect complexes	perfect complex P over local ring (R, m) is 0 iff derived tensor product with residue field R/m is 0. Compare this to vector space M/mM over residue field R/m version.
Nakayama's lemma, fails without finitely generated	let the ring R be the integers localised at 2, the module is Q, the maximal ideal m = (2), Q as Z_(2)-module is obviously nonzero, so need finitely generation.
Filtration, of a module	sequence of submodules indexed by poset
Filtration, ordinal	filtration with ordinal numbers up to limit ordinal
Filtration, ascending submodules	sequence of submodules is increasing
Filtration, continuity	submodule is union of all previous submodules
Filtration, exhaustive	union of all submodules is entire module
Filtration, associated graded module	associated graded module is direct sum of quotients of increment modules ++ M_{a+1} / M_{a}
Filtration, Krull	Defined by M_n = m^n M, ring R with maximal ideal m
Filtration, chain condition	module satisfies ascending chain condition if every strictly ascending chain of submodules is finite
Filtration, prime ideal	construction of composition series of modules are finite filtrations
Filtration, n-primary	filtration by powers of prime ideal M_n = p^n M, similar to Krull's filtration
Filtration, Postnikov tower	spectrum can be filtered by sequence of spectra E_n, n nonnegative, fiber of map E_n -> E_{n-1} is product of Eilenberg-Maclane spectra
Filtration, spectral sequence	computation that formalises the idea of an ordinal filtration, successive approximations from simpler filtered object to true complex object
Filtrations, graded versus filtered	gradings are rigid direct sums, filtrations are more flexible inclusions
Radical, nilradical	ideal of all nilpotent elements x^n = 0 for positive integer n
Radical, Jacobson	intersection of all maximal ideals, ideal of small elements, in the sense that Nakayama's lemma
Radical, prime	lower nilradical, intersection of all prime ideals, nilradical and prime ideal are the same need to prove
Radical, ideal	radical of an ideal, set of all elements x in the ring such that x^n is in the ideal for positive integer n.
Radical, smallest	radical of an ideal, intersection of all prime ideals containing I
Radical, extremal	nilradical is smallest prime ideal of the ring
Radical, Noetherian	nilradical is nilpotent ideal in Noetherian ring
Radical, nilpotent elements	elements in radical ideals are those that are eventually zero up to some power
Radical, infinitesimal part	nilradical of ring in algebraic geometry, corresponds to non-reduced part of the affine scheme Spec(R), infinitesimal fuzziness of geometric object
Radical, Jacobson radical as local part	Jacobson radical captures the properties of the ring that are local to its maximal ideals, for example a ring is a local ring if its Jacobson radical (intersection of all maximal ideals) is its unique maximal ideal
Radical, nilradical spectrum of homotopy groups	spectrum whose homotopy groups are nilradicals of the ring's homotopy groups
Radical, nilradical of ring spectra	the nilradical can be defined as the ideal of elements x such that the multiplication map by x is a nilpotent endomorphism in the stable homotopy category. This is a higher categorical generalization of the classical definition.
Radical, Jacobson Radical in ring spectra	Jacobson radical of a commutative ring spectrum R is defined as the intersection of all maximal ideals of the homotopy ring π0​(R). This concept is more subtle and relies on the structure of the homotopy ring.
Radical, reduced	an object is reduced if its nilradical is zero. The nilradical thus serves as a powerful criterion for an object to be "sharp" or "without infinitesimal thickening."
Radical, closure of points	radical of an ideal I is the ideal of all functions that vanish on the vanishing locus of I. It gives an algebraic description of the closure of the set of points where the ideal is zero.
Radical, infinitesimals	radical in a higher setting captures the "infinitesimal" properties of objects in a way that respects their homotopical nature. It describes how things are "close to zero" in a more structured way.
Radical, nonseparatedness	Jacobson radical can be viewed as a measure of how "non-separated" the maximal ideals of a ring are. If the Jacobson radical is zero, the maximal ideals are "well-separated" in some sense since the intersection of maximal ideals is zero.
Local ring, maximal ideal	single maximal ideal
Local ring, set of non units	ring is local if and only if its set of non-units (elements that don't have a multiplicative inverse) forms an ideal. This ideal is then the unique maximal ideal.
Local ring, Jacobson	ring is local if its Jacobson radical, which is the intersection of all maximal ideals, is a maximal ideal itself.
Local ring, residue field	local ring (R,m) has a unique residue field, which is the quotient ring k=R/m.
Local ring, Nakayama's	Local rings are the rings for which Nakayama's Lemma applies in its most direct form. The lemma states that if a finitely generated module M is equal to mM, then M=0.
Local ring, direct products	ring that is a direct product of two or more non-zero rings is never a local ring. A ring is local if and only if it is not a direct product of non-trivial rings.
Local ring, localisation	ring R and a prime ideal p, the localization of R at p, denoted Rp​, is a local ring with a unique maximal ideal pRp​. This is the primary way local rings arise in practice.
Local ring, rational functions	affine variety, the local ring at a point p is the set of rational functions that are defined at that point. This ring is local, with its maximal ideal consisting of functions that are zero at p.
Local ring, Zariski topology	Zariski topology on the prime spectrum of a ring, the local ring at a point (a prime ideal) is the ring of "functions" on the "infinitesimal neighborhood" of that point.
Local ring, commutative ring spectrum	commutative ring spectrum R is a local ring spectrum if its homotopy ring p0​(R) is a local ring. This is the most direct generalization.
Local ring, localisation functor	process of localizing a ring at a prime ideal has a direct analogue in spectral algebraic geometry: the localization functor on a category of modules over a ring spectrum.
Local ring, infinitesimal	algebraic model for an infinitesimal neighborhood of a point on a scheme. It discards global information to focus on what happens in a tiny region.
Local ring, antithesis of global	antithesis of a ring that is a direct product. It's "connected" in a strong algebraic sense, as it has no non-trivial idempotents besides 0 and 1.
Minimal prime ideal, zero dimensional local ring	prime ideal p is a minimal prime if and only if the localization Rp is a zero-dimensional local ring. This means its unique maximal ideal is also its nilradical.
Minimal prime ideal, irreducible components	minimal primes of a ring correspond to the irreducible components of its spectrum Spec(R). Each minimal prime is the generic point of an irreducible component.
Minimal prime ideal, no other prime ideal	no other prime ideal q such that q is in p
Minimal prime ideal, associated prime	minimal prime ideal of a Noetherian ring is an associated prime of the zero ideal. An associated prime of a module M is a prime ideal p that is the annihilator of some element in M.
Minimal prime, radical of zero ideal	nilradical of a ring is the intersection of all its minimal prime ideals (lol need not be minimal). This is a fundamental result that links the nilradical to the geometric structure of the ring.
Minimal prime, Noetherian	Noetherian ring, there are only a finite number of minimal prime ideals. This is a crucial finiteness property that simplifies many arguments.
Minimal prime over an ideal I, ideal theoretic	ideal I, a minimal prime over I is a prime ideal p containing I such that there are no other prime ideals between I and p. The minimal primes of the ring are just the minimal primes over the zero ideal.
Minimal prime, chain of primes	prime ideal is a minimal prime if and only if any chain of prime ideals contained in it must terminate at the prime itself.
Minimal prime, nilpotent elements	minimal primes are precisely the prime ideals that contain the nilradical. Since the nilradical is the set of all nilpotent elements, minimal primes are those that capture the most fundamental "non-reduced" parts of the ring.
Minimal primes, intersections	minimal prime cannot be written as the intersection of two strictly larger ideals.
Minimal prime, generic point	minimal prime is the generic point of an irreducible component. This means that a property that is true on a dense open subset of the component is also true at the minimal prime.
Polynomial ring, formal expressions	polynomial ring in one variable x over a ring R, denoted R[x], is the set of all expressions of the form a_n x^n to a_0.
Polynomial ring, universal property	ring that freely adjoints an element to the ring, for any R-algebra A and any element a in A, there is a unique R-algebra hom from R[x] to A that maps x to a
Polynomial ring, monoid algebra	monoid algebra of the monoid (N0​,+) over the ring R. This generalizes to multiple variables and other monoids.
Polynomial ring, free commutative algebra	polynomial ring in n variables, R[x1​,…,xn​], is the free commutative R-algebra on n generators.
Polynomial, functions	polynomial can be viewed as a function from R to R, but in general, this is a distinct concept. For infinite fields, the two are isomorphic.
Polynomial ring, Hilberts basis theorem	R is a Noetherian ring, then R[x] is also Noetherian. This is the Hilbert Basis Theorem.
Polynomial ring, Gauss's lemma	R is a UFD, then R[x] is also a UFD. This is Gauss's Lemma for polynomial rings.
Polynomial rings, affine n-space	prime spectrum of the polynomial ring k[x1​,…,xn​] over an algebraically closed field k is the affine n-space, A_k^n​. The polynomial ring is the ring of regular functions on this space.
Polynomial ring, symmetric algebra	M free module with basis, Sym_R(M) is poly ring R of basis
Polynomial rings, homological resolution	construct free resolutions of modules
Polynomial ring, exterior algebra	anticommutative analogue of symmetric algebra, generalises noncommutative poly rings with de Rham cohomology
Polynomial ring, stable homotopy theory	polynomial ring spectrum is a commutative ring spectrum that is "freely generated." It's an object in a higher category that generalizes the concept of a polynomial ring.
Polynomial ring, affine schemes	polynomial rings is the foundation for defining affine schemes in algebraic geometry. An affine scheme is defined by a ring, and the polynomial ring defines affine space.
Polynomial ring, projective space	geometric object that extends affine space by adding a "hyperplane at infinity."
Polynomial ring, function ring of schemes	for any affine scheme X, the ring of regular functions on X is a quotient of a polynomial ring. This establishes the fundamental correspondence between geometry and commutative algebra.
Polynomial ring, formal power series ring	completion of the polynomial ring, consisting of infinite sums. It is used in local algebra and formal geometry.
Polynomial ring, algebraic closure	construction of the algebraic closure of a field. For any field k, every polynomial in k[x] has a root in the algebraic closure of k. An algebraically closed field is equal to its algebraic closure.
Nilpotent, zero power element	nilpotent element x in a ring is an element such that some positive integer power of it is zero, i.e., x^n = 0 for some n in positive integers
Nilpotent, kernel of reduction map, reduced ring has nilradical as kernel	nilradical is the kernel of the map from a ring R to its reduced ring R_red​ = R/nilrad(R)​. The reduced ring has no nonzero nilpotents because all parts in the nilradical are identified and vanished
Nilpotent, algebraic variety analogy	nilpotent element is an algebraic manifestation of a geometric object having "fat points" or "multiple components" at a single location. The algebraic variety defined by a polynomial equation might have a non-reduced structure at certain points due to nilpotents.
Nilpotent, vanishing to high order	nilpotent element can be seen as a function that vanishes to a high enough order at every point of the spectrum. For example, in the ring k[x]/(x^2), the element x is a non-zero nilpotent, and it corresponds to a function on a single point that vanishes to order 2.
Nilpotent, morphism	derived algebraic geometry, a nilpotent morphism is a morphism of ring spectra that is, in some sense, "infinitesimal."
Nilpotent, in spectrum	nilpotent element in a commutative ring spectrum R is an element x in derived ring p(R) such that the multiplication map x: R to R is a nilpotent map in the stable homotopy category.
Module, vector space where you cannot scale down scalars	a grid of points, like a vector space. A module is a more flexible grid where the "scalars" (the ring elements) may not have multiplicative inverses, so you can't always "divide" or scale down.
Module, direct sum as stacking of two grids	direct sum of two modules is a new module whose elements are pairs of elements from the original modules. Imagine two grids. The direct sum is a new, larger grid that's a "stacking" of the two original grids.
Module, free module as perfect regular grid	free module is a module that has a basis, just like a vector space. Every element can be uniquely written as a linear combination of basis elements. Visual Intuition: A free module is a "perfectly regular" grid. Every point in the grid can be reached by a unique combination of "steps" along the basis vectors.
Module, finitely generated grid	finitely generated if it can be generated by a finite number of elements. Visual Intuition: A finitely generated module is like a grid that can be "drawn" with a finite number of lines, as opposed to a potentially infinite number of lines.
Module, projective module as one that sits nicely in a perfectly regular grid	projective module is like a "subset" of a perfectly regular grid that is itself a module. It's not a perfectly regular grid itself, but it sits nicely inside one. A projective module is a direct summand of a free module.
Module, injective module as a module with no holes	module with "no holes." Any map to the module from a submodule can be extended to a map from the whole module.
Module, chain complex of modules and intuition with maps that go from one grid to a next	the homology of this chain complexes measures its "holes." Chain complex is a sequence of grids, with "maps" that go from one grid to the next. The homology is a measure of the "failed" maps.
Module, sheaf of modules	gluing together local modules. Imagine a collection of grids, one for each open set, that are consistently glued together.
Module, quasicoherent sheaf as global modules that look like simple local modules when you zoom in	a quasicoherent sheaf is a sheaf of modules that is locally isomorphic to a module. It's the geometric equivalent of an abstract module. "global module" that looks like a simple, local module when you "zoom in."
Quasicoherent sheaf, sheaf of OX modules that is locally isomorphic to R-module	quasicoherent sheaf on a scheme X is a sheaf of OX​-modules that is locally isomorphic to the sheaf associated with an R-module. It's the correct way to transport module theory to a geometric setting.
Quasicoherent sheaf, sheaf from a module	ring R, every R-module M gives rise to a quasicoherent sheaf M on the affine scheme Spec(R).
Quasicoherent sheaf, module functor	associating a sheaf to a module, the quasicoherent sheaf M~, defines a functor from the category of R-modules to the category of quasicoherent sheaves on Spec(R). This functor is an equivalence of categories.
Quasicoherent sheaf, local isomorphism on the level of stalks	sheaf F is quasicoherent if for every point x in scheme X, there exists an affine open neighborhood U = Spec(R) of x and an R-module M such that the section on the open neighbourhood F_U is locally isomorphic to the quasicoherent sheaf M-.
Quasicoherent sheaf, global module patching modules over local rings	"global module" that is constructed by patching together modules over local rings.
Quasicoherent sheaf, compared to coherent sheaf	quasicoherent sheaf is coherent if it is locally isomorphic to a sheaf associated with a finitely presented module. Coherent sheaves are the geometric counterparts of finitely presented modules, whereas quasicoherent sheaves correspond to all modules.
Quasicoherent sheaf, pushforward of a module using structural morphism of affine scheme	quasicoherent sheaf on a scheme can be defined by the pushforward of an R-module under the structural morphism from an affine scheme to the given scheme.
Quasicoherent sheaf, visual analogy as space of functions	quasicoherent sheaf can be visualized as a "space of functions" on a scheme, where the "functions" are sections that are defined locally and glued together.
Quasicoherent sheaf, on the level of stalks	stalk: localisation of module M at prime ideal p which is a local ring; section over U is isomorphic to quasicoherent sheaf M-; stalk of quasicoherent sheaf at a prime ideal p is localisation of module M at prime ideal p, which is a local ring
Quasicoherent sheaf, homotopical derived quasicoherent sheaf	sheaf whose stalk at every point is a complex of modules that is "homotopically quasicoherent," meaning it satisfies a local property in the stable homotopy category.
Quasicoherent sheaf, derived quasicoherent sheaves that is locally quasi-isomorphic	sheaf of complexes of modules that is locally quasi-isomorphic to a complex of modules over a ring.
Quasicoherent sheaves, derived functors	forming a derived quasicoherent sheaf from a module can be seen as a derived functor of the classical functor.
Quasicoherent sheaf, stacks	quasicoherent sheaves generalizes to stacks, where a quasicoherent sheaf on a stack is a more general type of a bundle that has symmetries.
Locally free module, locally free object is analogous to product of base space and fibre, or fibration with contractible	locally free object is analogous to a space that is a product of its base space and a fiber, locally. A fibration with a contractible fiber is analogous to a locally trivial bundle.
Locally free module, classification leads to algebraic K-theory to measure farness from all modules being locally free	classification of locally free modules (vector bundles) leads to algebraic K-theory. This is an ontology where we "measure" how far a ring is from having all its locally free modules be free. The Grothendieck group K0​(R) is a way to make the set of isomorphism classes of locally free modules into a group.
Locally free modules, projective resolutions as generalisation of locally free module	in homological algebra, we use projective resolutions to "resolve" (approximate) a module with a sequence of projective (or free) modules. This is a generalization of the idea that locally free modules are "like" free modules.
Locally free modules, line bundles as locally free sheaf of rank 1	line bundle is a locally free sheaf of rank 1. Geometrically, it's a vector bundle where each fiber is a one-dimensional vector space. Think of the tangent bundle of a circle, which is a line bundle.
Locally free module, tangent sheaf as locally free sheaf	tangent sheaf of a scheme is a locally free sheaf that captures the infinitesimal behavior of the scheme. Its fibers are the tangent spaces at each point. This is a direct generalization of the tangent bundle of a manifold
Associated prime, module R/(xy) as with irreducible axes as the irreducible primes	associated prime of a module M over a commutative ring R is a prime ideal p that is the annihilator of some element x in M, Consider the ring of polynomials R=k[x,y] and the module M = R/(xy). The prime ideals corresponding to the x-axis and y-axis are (x) and (y). The associated primes are (x) and (y) because they annihilate the elements y and x respectively in the quotient ring. This can be visualized as the set of irreducible components of the variety defined by the annihilator of the module, which in this case are the x and y axes.
Associated prime, embedded prime, x-axs as embedded prime subset of ideals, but origin is embedded in x-axis case of polynomial ring k[x,y], and module k[x,y]/(x^2, xy)	An embedded prime is an associated prime that is contained in another associated prime. Consider the ring k[x,y] and the module k[x,y]/(x^2,xy). The associated primes are (x) and (x,y). Here, (x) is an embedded prime because it is a subset of (x,y). Geometrically, the ideal (x,y) corresponds to the origin, which is embedded in the line defined by the ideal (x).
Associated primes, on a sheaf are associated primes of a stalk since these are algebraic, corresponds to irreducible components on the support of the sheaf	The associated primes of a sheaf on a scheme are the associated primes of the stalks of the sheaf at its points. The associated primes of a sheaf correspond to the irreducible components of the support of the sheaf. The support is the set of points where the sheaf is non-zero. For example, a sheaf of functions that is non-zero only on the x-axis has (x) as an associated prime.
Associated points, singular points or subvariety on the support of the sheaf, example for k[x,y]/(x^2, xy) on affine plane, associated points are origin and entire x-axis	An associated point is a point in the support of a sheaf that corresponds to an associated prime. An associated point is a "singular point" or "subvariety" of the support of a sheaf. For the sheaf k[x,y]/(x2,xy) on the affine plane, the associated points are the origin and the entire x-axis. The origin is "embedded" in the x-axis.
Associated primes, support of Ext functors, Ext functors measure obstruction of homomorphism	The associated primes can be used to compute the support of the Ext functors. The Ext functors measure the "obstructions" to a homomorphism. The associated primes tell you where these obstructions live, geometrically.
Associated primes, ideals that give the rank of the module, associated primes are locations where the module behaviour changes	rank of a module is the dimension of the free module it looks like locally. The associated primes are the ideals that give the rank of the module. The associated primes of a module are the "points" where the dimension of the module changes. For a module over a polynomial ring, the associated primes can be thought of as the locations where the module's behavior changes, such as where it has a singularity.
Ramification, prime ideals, imagine the prime ideals of Z as points on a number line. When we extend to a larger number field, this line is "unfolded" into a higher-dimensional space. The prime ideals in the larger field are also points, but some of them might "pile up" on top of the original prime ideal. In the case of Q(root 5)/Q, the prime (5) splits into (5) twice, which can be visualized as two points "collapsing" onto the original point. This is the geometric intuition of ramification	In algebraic number theory, ramification describes the behavior of a prime ideal p in a number field K when it is extended to a larger number field L. The ideal pO_L​ factors into a product of prime ideals in the ring of integers of L. Ramification occurs when at least one of these prime factors appears with a power greater than 1. This "bunching up" or "confluence" of prime factors is a fundamental concept. For example, in the extension Q(root 5)/Q, the prime ideal (5) of Z"ramifies" as it becomes the ideal (root 5​)^2 in the ring of integers Z[1 + root(5) / 2]
Ramification, domain P^1 as a sphere. The map z to z^2 wraps the sphere around itself twice. The points z=0 and z= infity are ramification points. This is where the wrapping "bunches up," and the pre-image of the image point is not a single point but a single point with multiplicity	For a non-constant morphism of smooth curves f: X to Y, a point p in X is a ramification point if the corresponding map on local rings is not an isomorphism. This is a geometric phenomenon where the map "folds" or "pinches" the curve at a point. The degree of ramification is measured by the ramification index, which is a key invariant. For example, the map f: P^1 to P^1 given by z to z2 is ramified at the point z = 0.
Ramification, real place is a point on a line. A complex place is a pair of points. The ramification of a real place into a complex one can be visualized as a single point on a line "splitting" into two points in a higher-dimensional space	In the theory of valuations, ramification describes the behavior of a place of a number field in an extension. A place can be a prime ideal (finite place) or an embedding into the real or complex numbers (infinite place). Ramification of a finite place means the valuation of an element changes in a non-trivial way, while for infinite places it means a real place becomes a complex one. For example, in Q(root(-1))/Q, the real place of Q is ramified because it becomes a complex place.
Ramification, Galois group as a group of symmetries of the extension. The decomposition group of a prime ideal is a subgroup that fixes the ideal. Ramification means that this subgroup is not trivial, so there are some "symmetries" that leave the ideal unchanged	In a Galois extension of number fields L/K, ramification occurs when the decomposition group of a prime ideal is not trivial. This means that there are elements in the Galois group that fix the prime ideal but not the elements in its ring. This is a subtle but deep concept that links the algebraic properties of the extension to its number-theoretic properties.
Ramification, imagine a sheet of paper. A branched cover is like folding the paper and then projecting it onto a line. The folds are the ramification locus, and the line they are projected onto is the branch locus. The map from the curve to the line is a branched cover that folds the curve at the points where the tangent is vertical	A branched cover is a surjective map of varieties with ramification. The set of ramification points is called the ramification locus, and its image is the branch locus. The map from a variety to its base is a local isomorphism everywhere except at the ramification locus. For example, the map from the curve y^2 = x(x−1)(x−2) to the affine line given by projection to the x-axis is a branched cover.
Ramification, imagine a map from a disk to a disk. A critical point is a point where the map "flattens" or "folds" the disk. The dynamics around this point are very complex and can lead to chaotic behavior	In dynamics, ramification occurs in complex dynamics when a map has critical points. A critical point is a point where the derivative of the map is zero. This is a point where the map "folds" or "pinches." For example, the map z to z^2 has a critical point at z=0.
Ramification, canonical divisor is a geometric object that is a "dual" to the tangent bundle. It is a line bundle that is related to the ramification of the map	The canonical divisor of a curve is a divisor that is related to the ramification of the curve. The degree of the canonical divisor is related to the genus of the curve and the ramification of the map.
Ramification, Hilbert symbol is a "map" that measures the ramification. It is a way of "quantifying" the ramification	The Hilbert symbol is a symbol that measures the ramification of a number field extension. The Hilbert symbol is a key tool in class field theory.
Ramification, Serre duality is a "duality" between two geometric objects. The ramification of the map is a key ingredient in this duality	The concept of ramification is used to formulate Serre duality, which is a duality theorem for coherent sheaves on a scheme. The duality is between the cohomology of a sheaf and the cohomology of its dual.
Ramification, covering space is a "bundle" of spaces. A ramified covering space is a covering space that "folds" or "pinches" at some points	A ramified covering space is a generalization of a covering space. A covering space has the property that the fibers are discrete sets. A ramified covering space has the property that the fibers can have "ramification."
Ramification, moduli space of curves is a geometric object. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms	The concept of ramification is used to study the moduli space of curves. The moduli space is a geometric object that classifies curves. The ramification of a family of curves is a phenomenon that occurs when the fibers of the family have "non-trivial" automorphisms.
Automorphisms, the number field Q(root 2) as a 2D plane with rational coordinates. The points are of the form (a,b) representing a+b root(2)​. The nontrivial automorphism is a reflection of this plane across the a-axis. It maps every point to its reflection while preserving all algebraic operations	A nontrivial automorphism of a number field K is a field isomorphism from K to itself that is not the identity. These are also known as Galois automorphisms. For example, the number field Q(root(2)) has an automorphism that maps a+ b root(2)​ to a− b root(2).
Automorphisms, affine line as a line. An automorphism is a transformation of this line that preserves its algebraic structure. A nontrivial automorphism is a shift or a scaling of the line, like the map x↦x+1 or x↦2x	A nontrivial automorphism of a scheme X is a scheme isomorphism from X to itself that is not the identity. These are more general than automorphisms of varieties. For example, the affine line A_k^1​ has automorphisms of the form x to ax+b, entry fields in k.
Automorphisms, groupoid as a collection of objects with arrows between them. The automorphisms are loops from an object to itself. A nontrivial automorphism is a loop that is not just the identity	A nontrivial automorphism of an object in a groupoid is an isomorphism from the object to itself that is not the identity. The groupoid is a category where all morphisms are isomorphisms.
Automorphisms, fundamental group of a space, like a torus, is a group of loops. A nontrivial automorphism of this group is a transformation that shuffles the loops in a way that is not just conjugation	A nontrivial automorphism of the fundamental group of a space is an automorphism of the group that is not inner.
Automorphisms, a family of elliptic curves. Some of the curves have extra automorphisms, like a curve with complex multiplication. This corresponds to a fiber with a larger automorphism group	The study of nontrivial automorphisms of fibers in a family of varieties is a key topic in algebraic geometry. The group of automorphisms can change from fiber to fiber.
Automorphisms, module is a geometric object. Its automorphisms are symmetries of this object. The study of these automorphisms helps us understand the structure of the module	The study of nontrivial automorphisms of objects in a category is a key topic in homological algebra. For example, the study of automorphisms of a module is a key topic.
Quasicoherent sheaf, imagine the ring Z as a single point, Spec(Z). A Z-module is a group. A quasicoherent sheaf on Spec(Z) is just a group. A more complex example is the ring of polynomials C[x]. A module over this ring is a vector space with a linear operator. A quasicoherent sheaf over Spec(C[x]) is a family of vector spaces parameterized by the affine line, together with a linear operator that varies smoothly	A quasicoherent sheaf is the geometric analogue of a module in commutative algebra. Just as a module over a ring R is a "linear" object, a quasicoherent sheaf is a "linear" object over a scheme. It is the natural setting for studying modules from a geometric perspective.
Gorenstein ring, a Gorenstein ring is like a geometric space that is "homologically symmetric." Imagine a regular local ring, which is geometrically a smooth point. A Gorenstein ring is a generalization of this. It's a point that might have a singularity, but the singularity has a "homological symmetry." For example, the ring k[x,y]/(x^2,y^2) has a singularity at the origin, but it is Gorenstein. Its homological structure is symmetric, and it has a "mirror" image in its injective dimension	A Gorenstein ring is a commutative Noetherian local ring (R,m) that has finite injective dimension as a module over itself. This is a crucial property that makes these rings "well-behaved" from a homological perspective. For example, a regular local ring is always Gorenstein.
Gorenstein ring, is a geometric object that is "homologically symmetric." A smooth variety is a Gorenstein scheme, which can be visualized as a surface with no singularities. A Gorenstein scheme can have singularities, but they are "well-behaved." For example, a variety with a single isolated singularity can be Gorenstein. The canonical sheaf is a line bundle, which is a very simple and well-behaved object	A Noetherian scheme X is Gorenstein if it is Cohen-Macaulay and its canonical sheaf is an invertible sheaf. A Gorenstein scheme is a geometric object with a well-behaved canonical sheaf. For example, a smooth variety is Gorenstein.
Gorenstein ring, a group algebra as a geometric object. A Gorenstein group algebra is a symmetric object. The left and right injective dimensions are finite. This is a very strong property that is a generalization of the commutative case	A group algebra kG is Gorenstein if it has finite injective dimension as a module over itself. This is a key property that is used to study the modular representations of a group. A Gorenstein group algebra is a "symmetric" object.
Gorenstein ring, Ext groups measure the "extensions" of modules. A Gorenstein ring has symmetric Ext groups. This is a very strong property that makes the ring easy to work with	A commutative Noetherian local ring (R,m) is Gorenstein if the Ext groups of the residue field k with itself are symmetric.
Cohen-Macaulay ring, geometric space that has a "well-behaved" dimension. Imagine a smooth variety, which is always Cohen-Macaulay. The dimension of a smooth variety is the number of independent parameters needed to describe a point on it. The depth is the length of a maximal regular sequence, which can be thought of as the number of "cuts" you can make without hitting a singularity. A Cohen-Macaulay ring is a ring where these two numbers are the same. A nonsingular variety is a great example	A Cohen-Macaulay ring is a commutative Noetherian local ring (R,m) such that its depth is equal to its dimension. The depth of a ring is the length of a maximal regular sequence in the maximal ideal. This is a crucial property that makes these rings "well-behaved" from a geometric and homological perspective. For example, a regular local ring is always Cohen-Macaulay.
Cohen-Macaulay, scheme is a geometric object that is "well-behaved." It is a generalization of a smooth variety. A variety with a single isolated singularity can be Cohen-Macaulay, but a variety with a "cone-like" singularity, like the cusp y^2 = x^3, is not. The Cohen-Macaulay property ensures that the singularities are "not too bad."	A Noetherian scheme X is Cohen-Macaulay if its local rings are all Cohen-Macaulay. A Cohen-Macaulay scheme is a geometric object with a "well-behaved" dimension. For example, a smooth variety is Cohen-Macaulay.
Valuations, imagine the rational numbers Q as a line. The usual absolute value measures the distance from zero. A p-adic valuation measures a different kind of "distance" from zero, where numbers divisible by higher powers of p are "closer" to zero.This creates a "tree-like" structure on the rational numbers. For instance, in the 5-adic valuation, the numbers 1,2,3,4 are all at "distance" 1 from 0. The number 5 is at "distance" 1/5, and the number 25 is at "distance" 1/25	A valuation on a field K is a function that assigns a real number to each element of the field, satisfying certain properties that generalize the notion of absolute value. A non-archimedean valuation is one for which the triangle inequality is replaced by a stronger condition, norm(x+y) ≤max(norm(x), norm(y(). This is a powerful tool for studying the arithmetic properties of a field. For example, the p-adic valuation on the field of rational numbers Q assigns to each non-zero rational number x a value that depends on the highest power of the prime p that divides x.
Valuation, valuation ring is like a "local neighborhood" around a point on a curve. For a valuation on the field of rational functions on a curve, the valuation ring is the ring of functions that are regular at a point. This is a very powerful geometric intuition that connects algebraic objects to geometric ones	A valuation on a field K is a function v: K to G union {point at infinity}, where G is an ordered abelian group, satisfying v(xy) = v(x) + v(y) and v(x+y) more than min(v(x),v(y)). The ring of a valuation is the set of all elements with non-negative valuation. For example, the p-adic valuation on Q has the ring of p-adic integers Z(p)​.
Valuation, number field is a geometric object. The places are the "points" of the number field. A valuation is a way of "measuring" a number in a way that is compatible with the "geometry" of the number field	A place of a number field is an equivalence class of valuations. The finite places correspond to the prime ideals of the ring of integers, and the infinite places correspond to the embeddings into the real or complex numbers. A valuation gives us a way to "measure" a number in a way that is compatible with the number field.
Valuation, variety is a geometric object. A valuation is a way of "zooming in" on a point on the variety. The valuation ring is the ring of all functions that are "well-behaved" at that point	A valuation on a field K is a function that gives rise to a valuation ring. The valuation rings on a field of rational functions on a variety correspond to the points on the variety. This is a very powerful tool for studying the geometry of a variety. For example, a valuation on the field of rational functions on the affine line A1 corresponds to a point on the line.
Valuation, module over a group algebra is a geometric object. A valuation is a way of "measuring" the "size" of this object	In modular representation theory, a valuation is a function that gives us a way to "measure" the "size" of a module. For a module over a group algebra, a valuation is a function that is related to the prime ideals of the group algebra.
Valuation, a divisor is a geometric object. A valuation is a way of "measuring" the "multiplicity" of this object	A divisor on a variety is a formal sum of prime divisors. A valuation is a function that gives us a way to "measure" the "multiplicity" of a divisor. This is a key concept in the theory of divisors.
Valuation, imagine a polynomial as a curve. Hensel's Lemma says that if the curve has a "root" in a small "neighborhood," then it has a "root" in a "bigger neighborhood."	Hensel's Lemma is a key result in number theory that gives a criterion for the existence of roots of a polynomial in a complete field with respect to a non-archimedean valuation. This is a powerful tool for solving equations.
Valuation, "measuring" the "size" of an ideal. This is a key concept in the theory of ideals. Krull's Theorem states that every proper ideal in a commutative ring is contained in a maximal ideal. This is a key result in commutative algebra. A valuation is a way of "measuring" the "size" of an ideal	
Splitting lemma, projection map from R3 onto the xy-plane. The kernel of this map is the z-axis, and the image is the xy-plane. The Rank-Nullity Theorem says that the dimension of the starting space (3) is the sum of the dimension of the kernel (1) and the dimension of the image (2). This can be visualized as a 3D space that is a direct sum of a line and a plane	In linear algebra, the Splitting Lemma is a formalization of the Rank-Nullity Theorem. For a linear map T: V to W, the short exact sequence is 0 to ker(T) to V to Im(T) to 0. The theorem states that dim(V)=dim(ker(T))+dim(Im(T)). Since any short exact sequence of vector spaces splits, this is always true. Consider example of projection map from R3 onto the xy-plane. The kernel of this map is the z-axis, and the image is the xy-plane. The Rank-Nullity Theorem says that the dimension of the starting space (3) is the sum of the dimension of the kernel (1) and the dimension of the image (2). This can be visualized as a 3D space that is a direct sum of a line and a plane.
Splitting lemma, dihedral group D3​, the group of symmetries of an equilateral triangle. There is a short exact sequence 1 to C3​to D3​ to C2​ to 1, where C3​ is the group of rotations and C2​ is the group of reflections. The sequence splits, but D3​ is not the direct product C3​ × C2​. Instead, it's a semidirect product. The reflection "twists" the rotations, preventing a simple direct sum structure	For non-abelian groups, the Splitting Lemma isn't quite the same. If a short exact sequence of groups 1 to A to B to C to 1 is right split, then B is a semidirect product of A and C. It is only a direct product if the splitting map is trivial.
Splitting lemma, trivial line bundle on a circle, which is a cylinder. We can "split" the tangent bundle of the cylinder into a vertical tangent line bundle and a horizontal tangent line bundle. The total tangent bundle is the direct sum of these two, which corresponds to the splitting of the exact sequence	The splitting of a short exact sequence of vector bundles on a variety corresponds to the direct sum decomposition of the bundles. A sequence 0 to E′ to E to E′′ to 0 splits if and only if E is isomorphic to direct sum of E′ and E′′.
Splitting lemma, group Z ++ Z/2​. The torsion subgroup is Z/2​. The free part is Z. The splitting is the decomposition of the group into a number line and a two-point group. This shows how the group is built from these two pieces	For a finitely generated abelian group A, the sequence 0→A_tor​→A→A/A_tor​→0 splits, where A_tor​ is the torsion subgroup. This means A can be decomposed into its torsion part and a free part.
Splitting lemma, the Wedderburn-Artin theorem says that a "nice" non-commutative ring can be broken down into a simple, geometric structure of matrices. The Splitting Lemma is the underlying tool that allows this decomposition	The Wedderburn-Artin theorem states that a semisimple ring is a direct product of matrix rings over division rings. This theorem is a consequence of the fact that every module over a semisimple ring is a direct sum of simple modules, which is a result of the Splitting Lemma. Visual intuition: The Wedderburn-Artin theorem says that a "nice" non-commutative ring can be broken down into a simple, geometric structure of matrices. The Splitting Lemma is the underlying tool that allows this decomposition.
Splitting lemma, ring of integers as a lattice of points. The class group measures "holes" in this lattice. The splitting lemma says that the lattice has no "holes" if and only if a certain sequence splits	The class group of a number field is a measure of the failure of unique factorization. A certain short exact sequence involving the class group splits if and only if the ring of integers is a principal ideal domain. Visual intuition: Imagine the ring of integers as a lattice of points. The class group measures "holes" in this lattice. The splitting lemma says that the lattice has no "holes" if and only if a certain sequence splits.
Splitting lemma, the composition series is like a way of building up a complex object from simple blocks. The Splitting Lemma is a condition that allows this process to be reversible, allowing a complex object to be decomposed into simpler ones	The Jordan-Hölder theorem states that a composition series of a module is unique up to isomorphism and permutation. While not a direct application of the Splitting Lemma, it is a consequence of related ideas. A module is a finite direct sum of simple modules if and only if it has a composition series whose simple subquotients are those simple modules.
Completion, construction of the real numbers R from the rational numbers Q. Imagine the rational numbers as discrete points on a line with many "holes." The completion process fills in these holes with the irrational numbers, such as root(2) or π. This creates a continuous, unbroken line. The completed space, R, is "complete" because every sequence that "should" converge does converge to a point within the space	In analysis, a completion is the process of constructing a complete metric space from an incomplete one by adding all the limits of its Cauchy sequences.
Completion, ring R with an ideal I as a space. The quotients R/I, R/I^2, R/I^3,… represent a sequence of increasingly "finer" approximations of the ring, where we are progressively ignoring less and less information about the ideal. The inverse limit is the "final product" that incorporates all this information. For example, the ring of integers Z completed with respect to the ideal (p) for a prime p gives the p-adic integers Zp​, which contain infinite "series" of powers of p. The elements of Zp​ are "infinite strings" of numbers in Z/p^n Z that are compatible with each other	In commutative algebra, the I-adic completion of a commutative ring R with respect to a proper ideal I is defined as the inverse limit of the quotient rings invlim​ ​R/I^n. This construction gives R a topology where the powers of I form a basis of open neighborhoods around 0.
Completion, algebraic variety, the Zariski topology is very "coarse." Points are "isolated" and neighborhoods are very large. By completing the local ring at a point, we are essentially "zooming in" to such an extreme degree that we can see the "infinitesimal" structure around it. This process gives a much richer topology (the m-adic topology) that's closer to what we'd expect from a manifold. For example, completing the ring of polynomials C[x] at the ideal (x) gives the ring of formal power series C[[x]]. This allows us to think of functions near x=0 using infinite series	In algebraic geometry, completion of the local ring of a scheme at a point allows us to study the "infinitesimal" or "formal" neighborhood of that point. For a point x on a scheme X with local ring O_{X,x}​, the completion is the ring O_{X,x}​, which is the inverse limit of the quotients of the maximal ideal.
Completion, circle S1 has a fundamental group Z. The profinite completion of Z is Z = invlim​_n ​Z/nZ. The profinite completion of the circle is a space with a fundamental group that is "filled in" with all the "finite pieces" of the integers	In homotopy theory, the profinite completion of a space X is a space X^ whose fundamental group and higher homotopy groups are the profinite completions of the original groups. It's constructed as an inverse limit of spaces with finite covers.
Completion, module as a vector space over a ring. The completion is like taking a sequence of projections onto smaller and smaller subspaces and then "piecing" them back together. This process allows us to study a complex module by analyzing a series of simpler, finite-dimensional quotients, and the completion itself is the ultimate "assembly."	In homological algebra, the completion of a module M over a ring R with an ideal I is defined as the inverse limit lim​ ​M/I^n M. This process allows us to study the local properties of a module in the I-adic topology.
Completion, group ring F_p​[G] is the "space" of all representations. The completion at a Sylow p-subgroup is like "zooming in" on a specific point of this space. This allows us to study the representations of the whole group by studying the representations of a simpler subgroup, which can be visualized as a "local" analysis of a global object	In modular representation theory, the completion of a group ring F_p​[G] at the ideal generated by a Sylow p-subgroup is a powerful tool. It allows for a transfer of knowledge between the group algebra and its local properties.
Completion, rational function on the complex plane can behave erratically at infinity. By compactifying the complex plane into a sphere by adding a "point at infinity," we can study the behavior of the map at that point. This makes the map a continuous function from the sphere to itself. The completion provides a "holistic" view of the dynamics	In dynamics, the completion of a rational map f(x) in C(x) is the process of extending the map to the Riemann sphere P^1(C). The completion adds a point at infinity, which allows for a more complete study of the map's dynamics.
Completion, scheme as a geometric space. A closed subscheme is a "subspace." The formal completion is a space that is "sewn" onto the original scheme along the subscheme. It allows us to study the geometry of the original space in a very small neighborhood of the subscheme	In algebraic geometry, the formal completion of a scheme X along a closed subscheme Y is a new scheme that "lives" in the infinitesimal neighborhood of Y.
Completion, an algebra with a filtration is a set of "approximations." The completion is the "limit" of these approximations, which is a new algebra that is "finished" in a sense. This allows for a more robust study of the original algebra	In non-commutative ring theory, the completion of an algebra with a filtration is a process that creates a new algebra that is complete with respect to the filtration.
Completion, a number field is a "global" object. The completion at a prime ideal is like "zooming in" on that prime ideal to study its properties. This is analogous to studying a manifold by looking at its tangent spaces	In arithmetic number theory, the completion of a number field K at a prime ideal p is a local field. This process allows us to study the number-theoretic properties of K "locally."
Completion, division ring is a set of "numbers" with division. The completion is a process of adding "missing numbers" to make the set complete. This is analogous to constructing the real numbers from the rationals	in non-commutative ring theory, the completion of a division ring with a valuation is a new division ring that is complete with respect to the valuation.
Completion, Dedekind domain is a "global" object. The completion at a prime ideal is like "zooming in" on that prime ideal to study its properties. This is analogous to studying a manifold by looking at its tangent spaces	In arithmetic number theory, the completion of a Dedekind domain at a prime ideal is a discrete valuation ring, which is a key tool in studying the local properties of the domain.
Locally free module, vector bundle over the space	"space" is the spectrum of the ring, Spec(R), and the module M corresponds to the collection of "fibers" (vector spaces) over each point of the space. A module is locally free if the fibers over points in a neighborhood all have the same dimension, and the bundle is trivial (like a product) over that neighborhood.
Locally free, deformation of a free module	a free module as a perfectly straight, rigid structure. A locally free module is like a deformed or twisted version of this structure that, when you zoom in, still looks straight. The Möbius strip is a classic example of a line bundle that is locally trivial (looks like a line locally) but not globally trivial.
Module, projective subspace that can be projected back	projective module is like a subspace that can be "projected back" onto the larger space without losing information, for example, a plane in R3. Projective modules are always locally free.
Dedekind domain, unique factorization of ideals	Need not be a unique factorization domain on elements, but it does have unique factorization of ideals.
Dedekind domain, visual intuition of an ring of regular functions on an algebraic curve on a smooth affine variety	Imagine a smooth curve with no sharp corners or self intersections, this corresponds to a Dedekind domain on the ring of regular functions on a smooth affine varieties. The “prime ideals” correspond to points on the curve with unique factorization in these points.
Dedekind domain, visual intuition for the standard definition of Noetherian, integrally closed, of dimension 1 using the ring of regular functions as your guide	A ring of regular functions on a smooth affine variety with no self intersections. Noetherian means every ascending chain of ideals terminates, think visually of a finite inclusion of ideals, integrally closed means there are no holes where no element from the field of fractions can be an algebraic integer or a root of a monic polynomial as a hole, dimension one means lines, points are the only one dimensional subobjects.
Dedekind domain, visual comparison with (higher dimensional) Krull domain both with some factorisation due to prime ideals	Prime ideals of height 1 are what matters for factorisation of prime ideals, these corresponds to lines whose . So a Krull domain is a higher dimensional analogue, with the same factorization property as Dedekind domain.
Dedekind domain, ideal class group to distinguish between Dedekind domains and unique factorization domains	Ideal class group measures the twisting in the Dedekind domain (factorization on ideals) that prevents it from being a unique factorization domain (factorisation of elements), a trivial ideal class group means the structure is flat
Dedekind domain, defined with homological projective resolution of dimension 1 and is an integral domain, visual intuition	Recall the visual intuition for an integral domain is that it has no “holes” that are formed out by elements in the field of fractions to serve as algebraic integers in the roots of polynomials. A projective resolution of dimension 1 is very simple? It only has a set of generators as a free module (with a basis) and a set of relations as a free module as well (with a basis)
Dedekind domains, ideal visually viewed as lattices	Ideals in a Dedekind domain can be viewed as lattices in a vector space.
Cogenerator, visual intuition for non-zero elements as a detector (right M-module) using sensory input (ring homomorphism from M to Q)	A cogenerator is a detector for nonzero element from a nonzero module using a ring homomorphism (as a sensory input). Let Q be a right R-module (detector) that for a nonzero module M and a nonzero element m in module M, there is always a ring homomorphism (sensory input) f from M to Q such that f(m) is nonzero in module Q. We can say Q is a cogenerator.
Cogenerators, faithful functor and distinguishing detector analogy and using Hom to turn other modules into sensory input	Let Q be a right R-module, we can turn it into maps by applying Hom functors into Q, Hom(-, Q) (sensory input) this takes a set of maps of right R-modules (category) to a set of maps of abelian groups (category) that is able to distinguish if two maps are different (detecting faithfulness)
Partition of unity, sphere S2 and an open cover consisting of two open hemispheres. We can construct a partition of unity with two functions, ρ1​ and ρ2​. Function ρ1​ is 1 on a smaller open set in the northern hemisphere and smoothly drops to 0 at the equator. Function ρ2​ is 1 on a smaller open set in the southern hemisphere and smoothly drops to 0 at the equator. The sum ρ1​+ ρ2​ is always 1 on the equator	A partition of unity on a manifold M is a family of smooth functions {ρi​} such that the sum of all functions is identically 1 (∑i​ρi​=1) and the support of each function is contained within a given open cover. It’s a tool for smoothly piecing together local information to get global information. Visual Intuition: Consider a sphere S2 and an open cover consisting of two open hemispheres. We can construct a partition of unity with two functions, ρ1​ and ρ2​. Function ρ1​ is 1 on a smaller open set in the northern hemisphere and smoothly drops to 0 at the equator. Function ρ2​ is 1 on a smaller open set in the southern hemisphere and smoothly drops to 0 at the equator. The sum ρ1​+ ρ2​ is always 1 on the equator. . This lets us smoothly glue a local function on the northern hemisphere and a local function on the southern hemisphere to create a global function on the sphere.
Partition of unity, sheaf can be thought of as a collection of local data (e.g., functions, sections) on a space. A partition of unity allows us to build a complex of sheaves that "resolves" the sheaf, meaning it captures its structure	In homological algebra, a partition of unity for a sheaf F on a space X is a way to construct an acyclic resolution. An acyclic resolution is a complex of sheaves whose higher cohomology groups are zero. Visual Intuition: A sheaf can be thought of as a collection of local data (e.g., functions, sections) on a space. A partition of unity allows us to build a complex of sheaves that "resolves" the sheaf, meaning it captures its structure. For instance, on a manifold, we can construct a fine resolution of the sheaf of smooth functions. This fine resolution is acyclic because we can "smoothly" glue local sections using the partition of unity, preventing the formation of "holes" in the complex.
Partition of unity, group algebra Fp​[G] of a finite group G over a field Fp​. We can find orthogonal idempotents that act as a "partition of unity." These idempotents decompose the group algebra into a direct sum of indecomposable modules	In modular representation theory, a partition of unity can be seen as a set of orthogonal idempotents that sum to the identity in a group algebra. These idempotents decompose the group algebra into a direct sum of modules. Visual Intuition: Consider the group algebra Fp​[G] of a finite group G over a field Fp​. We can find orthogonal idempotents that act as a "partition of unity." These idempotents decompose the group algebra into a direct sum of indecomposable modules. Geometrically, this is like breaking down a complicated object into its fundamental, non-decomposable building blocks.
Partition of unity, ring Z6​, orthogonal idempotents e1​=3 and e2​=4 (since 3^2 = 9 ≡ 3 mod 6 and 4^2=16 ≡ 4 mod 6, and 3⋅4 = 12 ≡ 0 mod 6). Their sum is 3+4=7 ≡ 1 mod 6. The ring Z6​ is the direct product of Z2​ and Z3​. This is a "partition" of the ring into two "independent" components	In commutative algebra, a partition of unity is a set of orthogonal idempotents {e1​,…,en​} in a ring R such that ei​ej​=0for i not equal to j and sum of e_i​=1. These idempotents decompose the ring as a direct product of subrings. Consider ring Z6​, orthogonal idempotents e1​=3 and e2​=4 (since 3^2 = 9 ≡ 3 mod 6 and 4^2=16 ≡ 4 mod 6, and 3⋅4 = 12 ≡ 0 mod 6). Their sum is 3+4=7 ≡ 1 mod 6. The ring Z6​ is the direct product of Z2​ and Z3​. This is a "partition" of the ring into two "independent" components.
Partition of unity, coprime decomposition to the Chinese Remainder Theorem states that Zmn​ is isomorphic to Zm​×Zn​ when m and n are coprime. This is a decomposition of the ring into two "independent" parts	In arithmetic number theory, a partition of unity can be seen as a decomposition of the ring of integers Z into a direct product of rings Zp​, using the Chinese Remainder Theorem. Visual Intuition: Consider the ring Z. The Chinese Remainder Theorem states that Zmn​ is isomorphic Zm​×Zn​ when m and n are coprime. This is a decomposition of the ring into two "independent" parts. This is a number-theoretic analog of a "partition of unity" in the sense that we are "decomposing" the ring into a direct product of its constituent "factors."
Family of schemes, parametric (base scheme) dependence in algebraic geometry, results are encoded in fibres pulled back to original scheme	idea is simple, you want a morphism of schemes to a base scheme S to vary over, the base scheme is the parameter to vary, so you want to pull back (get the argument that gets the result), so for each point in the base scheme (parameters), one considers the fibres X_s = X * Spec(k(s)) capturing the member of the family parameterised by s. Additional properties, especially flatness, properness or smoothness ensures good geometric properties captured by the fibre.
Artinian k-algebra, suitable test objects since every descending chain of ideals stabilises	commutative k-algebra A of finite length as a module over itself, satisfying the descending chain condition on ideals. It has the unique maximal ideal such that the quotient of the maximal ideal with the algebra is isomorphic the residue field. Any small thickening of the field factors through these algebras, so these are designaed as the test objects.
Flat deformation, conditions to avoid base change and geometric data jumps, nice local conditions (Artinian k-algebra), nice global glueing (schemes), preserving tensor (fibre) products	start with the nice local properties you want, in this case it is an Artinian k-algebra (descending chain condition), with residue field k. You are working over schemes. Then a flat deformation of a scheme over a local Artinian k-algebra A with residue field K is a flat morphism pi from X to Spec A together with an isomorphism where the fibre product of X *_{Spec A} Spec(k) is isomorphic to X. The sheaf of rings OX is a flat OSpec(A)-module, ensuring that Hilbert polynomials, cohomological invariants, fibre dimensions behaviour continuously
Kahler differentials, linearising functions as tangent data of a scheme, module since you want vector space on these linearising functions, universal property since you want the univerasl derivation as chain rule	linearising is the only way we do algebra well, this motivates Kahler differentials. The idea starts from a chain rule d(ab) = a db + b (da) as the universal property you want to define, this is the universal derivation. We define a module of Kahler differentials for a k-algebra A such that for any A-module M, every k-linear derivation factors uniquely through the universal derivation.
Dual numbers, easiest example of nilpotent (classic example is y = x^2) thickenings for deformation calculations	the dual numbers over a field is k(eps)/(eps^2) where eps is nonzero and eps^2 = 0, they form a local Artinian k-algebra with residue field k. A morphism Spec(k(eps)/(eps^2)) to k encodes infintesimal tangent vectors at point X (hint: you pullback to get the encoding)
Tangent sheaf, derivations of structural sheaf encoding infinitesimal vector fields, Kahler differentials	the idea is you want to consider derivations of the structural sheaf, start with the (sheaf of) Kahler differentials Omega^1 X over field k, the the tangent sheaf is the homomorphisms over the sheaf of rings Hom_{OX}(Omega^1 X/k, OX). This way, sections of the tangent sheaf over an open U are the k-linear derivations.
Deformation, define tangent space and obstructions keeping niceness of flat deformations, niceness means you want a functor with derived functors as invariants	since this is a functor, you want to think about the categories of interest: the infinitesimal deformation functor Def_X is a functor that assigns each local Artinian k-algebra with residue field K the set of isomorphism classes of flat deformations of X over Spec(A). The tangent space of the first Ext^1(T_X, O_X) where T_X is the tangent sheaf of X, O_X is the NOT the sheaf of Artinian k-algebras of X, it is more general, just a sheaf of rings. We will visit the idea that the Artinian k-algebras are test objects in this space.
Cotangent complex, encodes homologically all the infinitesimal deformations, taking Kahler differentials as a base, derived categories are nicer to work with than cohomology	homological algebra is typically considered on the first dimensional example to generated higher dimension examples like the obstruction space. Define for a morphism of schemes f from scheme X to base scheme S, the cotangent complex is an object in the derived category on the sheaf of rings D(O_X) such that the cohomology captures this pattern: the zeroth cohomology H^0 of the cotangent complex is the Kahler differential, the first cohomology H^1 encode obstructions, Ext^i of the cotangent complex with its sheaf of rings compute the tangent and obstruction spaces where i = 0 is infintesimal automorphisms, i = 1 is tangent space, i = 2 is obstruction space.
Obstruction space, characterised by lifting	we saw how obstruction space can be naturally defined in terms of the derived Ext functors of the cotangent complex, its use in practice is the following: consider a small extension of Artinian k-algebras 0 to I to A' to A to 0, elements of the tensor product of Ob_X * I in the residue field k detects whether it can be lifted to A'.
Static analyses of programs, Rice's theorem	idea is you want to statically analyse whether a program will execute without errors, define semantic property about program's behaviour example given is halting problems unlike syntactic property, generalises halting problem, cannot check any given program is correct. Corollary (in engineering): reduce complexity of machines from Turing completeness or design programs that make it statically correct or be like me, do not program if you do not need to.
Kleene's recursion theorem, proving Rice's theorem in ZFC	uses contradiction, assume nontrivial extension computable set of natural numbers P, so there is natural number a in P and natural number b not in P. Define a function Q by Q_e(x) = phi_b(x) where e is in P, and Q_e(x) = phi_a(x) where e is not in P. Subscript differs based on membership in P. By Kleene's recurison theorem phi_e is definable isomorphic (in the Roger's fixed point theorem sense) Q_e or this function is a Roger's fixed point function since we assumed this is a nontrivial extension computable set of natural numbers, this contradicts extensionality since phi_a = phi_b = phi_e since e in P and e not in P.
Roger's fixed point theorem, explains intuition in Rice's theorem, and the halting problem	since we can have a Roger's fixed point theorem, we can't have a program that changes the extensional behaviour of all programs i.e. there is a program unaffected by the change, therefore there is a program that is unaffected by checking the termination on given natural number, a program that is unaffected by checking for equivalence of programs. So on and so forth, this is the intuitive reason why Rice's theorem works, it all stems from the nonexistence of a program that determines the extensional behaviour of all programs OR you can always design a program that is invariant by the extension program.
Roger's fixed point theorem, extensions of programs	if F is a total computable function, it has a fixed point such that phi_e is isomorphic to phi_F(e), where phi is an admissible numbering of the partial recursive function, phi_e is this function corresponding to index e, F is (I made this up) definably isomorphic to G as partial function on the naturals if F(n) and G(n) are both defined and equal, otherwise they are both undefined. This guarantees the existence of a program that is not altered by any transformation from programming instructions. Given any effective procedure to transform programs, there is always a program that, when modified by the procedure, does exactly what it did before. Or, corollary, there is no program that changes the extensional behaviour of all programs. Space of Turing complete programs is too big, so there alawys is a Roger's fixed point.
Number theory, unique factorization of polynomials	one can transplant ideas gleaned from the study of number theory into the study of polynomials (although these are not really distinct). Product formulas, classification using cyclic groups, and other fairly similar intuitions can be similarly transplanted into polynomials. The Stone-Weierstrass theorem with certain extra thinking about how to make the polynomial smooth or continuous enough gives a nice correspondence between polynomials and functions, with the right weakening of this correspondence applying to generalized functions. This is why I find number theory motivating for me, an engineer by training.
Finite field extension, correct generalization of prime factorization	one cares about how to generalize the integers having a unique prime factorization, let K be a finite field extension of the rationals, then let O_K denote the ring of algebraic integers in K, the ideals in O_K factor uniquely into prime ideals as a lemma.
Ideals, Yoneda embedding for posets	Dedekind constructed the reals from the rationals, one embeds the rationals in its power set by defining the representative set (known as a Dedekind cut) using the least upper bound of the rationals as the Yoneda embedding on the poset of the rationals. This is an order preserving injection, you can work with these sets instead of the original rational numbers. The similar idea is to consider ideal sets where you have powers of rationals bounded by an integer, then embed the divisibility relation. For example, define the analogous Dedekind cut S_x by elements a in the integers adjoined the square root of negative 5 such that x divides a. Now take the kernel under homomorphisms from this field extension into an integral domain. One obtains ideals this way. See Qiaochu Yuan's blog post on primes and ideals.
Irreducible element, fix Euclid's algorithm	see example of the integers adjoined root(-5), the Euclid's algorithm fails, these are the elements that cannot be factored further. But the right notion of primarily is the one where prime p divides ab means a prime p divides a or prime p divides b, this is the right notion of primality (in fact Euclid's lemma becomes a definition here) because it allows us to cancel factors in two different prime factorization of an integer. Note that this is strangely category theoretical or algebraic flavored.
Euclid's algorithm, proof that the integers Z are a principal ideal domain	here is a proof sketch, the key step aq + r = b, but the remainder r must be zero since sums of ideals are in ideals. Consider I as ideal of Z, if I is zero ideal then this is principal. Suppose, without loss of generality, I as a nonzero ideal, let l be smallest positive element in I, it exists by the by well ordering of integers, (l) = I, (l) is in I, since for product integer lr in I, the remainder r is an integer, let b in the ideal I, use Euclid's algorithm, therefore so b = aq + r, so the remainder must be zero, b = aq, so the ideal (a) generates I for any ideal in the ring of integers Z. Surprisingly, this means that zero remainder gives equivalence of linear combinations and products to give principal ideals. One must consider the ideas used in the proof that the product of principal ideals is an ideal to reconcile this fact.
Greatest common divisor, preserve information on scalars as a meet	consider gcd(ab, ac) = a gcd(b, c) holds because we are taking the greatest of something. Change the notation, a(b ^ c) = (ab) ^ (ac), multiplication by integer a can be thought of as a functor on the poset, this is Yoneda flavoured, f_a(x) = ax, this is a monotone map because x | y implies ax | ay, we have f_a(b ^ c) = f_a(b) ^ f_a(c) or that multiplication by a preserves meets. Left adjoints on posets preserve joins (colimits), right adjoints on posets preserves meets (limits), so multiplication by a is a right adjoint functor. The left adjoint to multiplication by a, f_a, is simply division by gcd(a,y), or g_a(y) = y / gcd(a,y), this forms a Galois connection. Similarly, intersections (meets) preserving scalar multiplication is another example (scalar multiplication is right adjoint over poset of ideals). The opposite property corresponds to left adjoints like the extension of scalars or localisation.
Integral equation, motivating problem in PDEs	we do not understand integral equations, therefore we can try to use functional analysis and distribution theory to answer questions about this.
Functional analysis, extension of spectral theory to PDEs	spectral theory and duality are two key areas of study to consider for PDEs. Spectral theory is basically about eigenfunctions and expansions, takes 60 years to extend to PDEs. Spectral theory matured wit an understanding of linear duality (or the uncertainty principle).
Schwartz space, definition of objects that capture automorphisms	one big idea to capture simple objects in mathematics is to capture objects that are invariant under automorphisms of important operations. For example, Schwartz spaces are based on automorphisms of the Fourier transforms, algebraic stacks are objects that capture automorphisms of moduli spaces for classification purposes. The capturing of automorphisms lend themselves to simplicity, since they retain the same properties under automorphic actions.
Sobolev parameters, Imagine a 1D function u(x) on the interval [0,1]. Its L2 norm, ||u||L2​, measures its overall "size" or area under the curve (squared). The W1,2 norm, ||u||_W1,2​ = sqrt (iunit ntegral of u(x)^2 + unit integral of u'(x)^2) measures its "size" and its "slope" or "wiggliness." Consider the function u(x) = sin(2πx). It has a moderate L2 norm. The function v(x) = sin(20πx) has the same L2 norm, but is much "wiggier," so its derivative is larger, and hence its W1,2 norm is much larger. The parameter k determines how many derivatives you are including in the "wigginess" measure. The parameter p determines the type of averaging. For p=2, we have the Hilbert space Hk=Wk,2, which is particularly important	The norm is defined by the sum of functions on a domain with integral of the |D^a u(x)| p dx 1/p, so k is for the maximum partial derivative, p is the exponent of the norm root, Roughly speaking, if a function has amplitude A, is supported on a set of volume 𝑉, and has frequency N, then the W^k,p norm is going to be about A N^k V^(1/p).
Sobolev norm, consider the Laplace operator del on a bounded domain. The domain of del as an unbounded operator on L2 is not L2 itself but a dense subspace of L2. The Sobolev space H2 is the most natural domain for the Laplacian. An eigenfunction of the Laplacian, u(x), satisfies del u = eu. The Sobolev norm ||u||_H2​ is proportional to the eigenvalue, e. For example, for a vibrating drumhead, the fundamental mode of vibration (the eigenfunction with the smallest eigenvalue) is smooth and has a small H2 norm. Higher-frequency modes, which have more "wiggles" and oscillations, have larger eigenvalues and therefore larger H2 norms. The Sobolev norm precisely quantifies this relationship between "wigginess" and eigenvalue	In the Spectral Theory of Operators, the Hilbert space H^k(omega) (where p=2) is the natural domain for studying differential operators, such as the Laplacian. The Sobolev norm provides a way to define the domain of an operator and to analyze its spectral properties. The operator's action is bounded from a Sobolev space to a simpler space.
Sobolev norm, fractal, like the Sierpinski gasket. It is a set with a non-integer dimension and has no traditional derivatives. However, we can define a notion of a "weak gradient" and a measure on it. The Sobolev norm on the Sierpinski gasket would measure the "energy" of a function on the gasket. A function that is "smooth" or "well-behaved" on the gasket would have a small Sobolev norm, while a function that is "bumpy" or "singular" would have a large Sobolev norm. The Sobolev norm is a way of extending calculus to these non-classical geometric objects	In Measure Theory, Sobolev spaces can be defined on metric measure spaces, not just on Euclidean space. This extends the concept of "differentiability" to more general settings, such as fractals or graphs. The Sobolev norm is then defined using a suitable notion of a weak gradient and an underlying measure.
Sobolev norm, Imagine a stock price over time, represented as a random path. The L2 norm measures the overall deviation from a mean value. The Sobolev norm of order k=1 (recall that k is the max order of the partial derivative), however, measures the "jerkiness" of the path. The path of a random walk is very "jerky" and has an infinite Sobolev norm because its derivative is infinite at every point. The Sobolev norm provides a way to quantify this roughness	In Probability Theory, Sobolev norms are used to study the regularity of paths of stochastic processes. For example, the paths of a Wiener process (Brownian motion) are almost surely continuous but nowhere differentiable. While the classical derivative doesn't exist, a notion of a Sobolev space can be defined, and the Sobolev norm can be used to analyze the "roughness" of the paths.
Sobolev norm, The Dirac delta function, δ(x), is a highly singular distribution that is zero everywhere except at x=0, where it is "infinite." Its derivative is also a distribution. We can't talk about its classical differentiability, but we can talk about its Sobolev norm. The Sobolev norm of the delta function is infinite because it represents an infinite "concentration" of a singularity at a single point. In contrast, a smooth Gaussian function has a finite Sobolev norm because it is a "spread out" singularity. The Sobolev norm provides a way to quantify the degree of singularity of a distribution	In Distribution Theory, the Sobolev space W^(k,p) can be defined as the set of distributions whose derivatives (in the sense of distributions) are functions in Lp. The Sobolev norm is then defined on these distributions. This allows us to talk about the "smoothness" of objects that are not functions, like the Dirac delta function.
Sobolev norm, a function that is smooth everywhere except for a sharp crease along a line. The Sobolev wave front set would be a "line" in the cotangent bundle that "points" in the direction of the crease. The Sobolev norm of the function would be infinite, but the wave front set would tell us precisely where the singularity is and what "type" it is. A different type of singularity, like a single point, would have a different wave front set. The Sobolev norm is the "metric" we use to identify these singularities	In Microlocal Analysis, the Sobolev norm is a fundamental tool for defining the Sobolev wave front set, which describes the "singularities" of a function in both position and frequency. The wave front set of a distribution u is a subset of the cotangent bundle T∗R^n, which describes the points and directions where u is not smooth.
Sobolev norm, imagine the surface of a sphere. We can define Sobolev spaces of functions on the sphere. The Sobolev norm of a function on the sphere would measure its "smoothness" or "wrinkliness." A function that is constant on the sphere has a small Sobolev norm. A function that has many "peaks" and "valleys," like the surface of a golf ball, would have a large Sobolev norm. The Sobolev norm provides a way to quantify the geometric complexity of a function on a curved surface	In Global Analysis, Sobolev spaces are defined on manifolds, not just on Euclidean space. This allows us to study the regularity of functions and sections of vector bundles on curved spaces, which is crucial for the study of geometry and general relativity. The Sobolev norm is defined using local charts and partitions of unity.
Sobolev norm, thin vibrating membrane with a concentrated force acting at a single point. The displacement of the membrane, u(x,y), would not be a classical solution to the wave equation because its derivative would be infinite at the point of the force. However, it would be a weak solution in a Sobolev space. The Sobolev norm measures the "energy" of the membrane's displacement, which includes the energy of the "infinite derivative" at the point of force. This allows us to find a "generalized" solution that accurately describes the physical system	In the study of Partial Differential Equations (PDEs), Sobolev spaces provide the natural setting for defining and studying weak solutions. A weak solution to a PDE is a function in a Sobolev space that satisfies the PDE in a generalized sense, often by integration by parts.
Sobolev norm, a problem where we want to find a function that minimizes an "energy" functional. We can start with a sequence of functions whose energy is getting closer and closer to the minimum value. Since the Sobolev space is complete, we are guaranteed that this sequence converges to a function that is also in the space and is a minimizer. The Sobolev norm provides the "ruler" we use to measure the distance between functions, and its completeness ensures that there are no "holes" in the space	In Nonlinear Functional Analysis, the Sobolev space W^{k,p} is a complete normed vector space (a Banach space), which is crucial for proving the existence of solutions to nonlinear problems. The direct method of the calculus of variations relies on the fact that a minimizing sequence has a convergent subsequence, and this requires the space to be complete.
Sobolev norm, imagine a blob of ink diffusing in a glass of water. The concentration of the ink is described by the heat equation. The initial concentration can be very "spiky" or non-smooth, but over time, it will become very smooth as it diffuses. The Sobolev norm of the concentration function will decrease over time, reflecting this smoothing process. The Sobolev norm is a "smoothness metric" that decreases as the system evolves	In Semigroup Theory, Sobolev spaces are used to study the well-posedness and regularity of solutions to evolution equations, such as the heat equation. The solution to the heat equation can be described by a semigroup of operators, and the Sobolev norm provides a way to measure the "smoothing effect" of the semigroup.
Sobolev norm, consider the group of rotations in 3D, SO(3), acting on a function on the sphere. The smooth functions on the sphere are the "smooth vectors" in this representation. The Sobolev norm on the sphere measures the "smoothness" of these functions. The action of the Lie algebra (the angular momentum operators) on these functions can be described by their derivatives, which are well-defined on the Sobolev space	In Representational Theoretic Harmonic Analysis, Sobolev norms are used to define spaces of "smooth vectors" in representations of Lie groups. Smooth vectors are crucial for the study of the action of the Lie algebra on the representation space. The Sobolev norm provides a way to quantify this smoothness.
Sobolev norm, imagine a function that is "smooth" in one direction but "rough" in another. The standard Sobolev norm cannot distinguish between these two directions. However, the Hörmander spaces, with their additional parameters, can. For example, a function that is smooth along the x-axis but rough along the y-axis would have a small Sobolev norm in the x-direction but a large one in the y-direction. These parameters allow us to "zoom in" on the smoothness in different directions	In Microlocal Analysis, more general Sobolev spaces, called "Hörmander spaces," are used to study the regularity of solutions to a wider range of PDEs. These spaces are defined using additional parameters a and r, which allow for a more precise analysis of the smoothness of a function.
Sobolev norm, uncertainty principle, Sobolev norms are trying to measure a combination of three aspects of a function	height (amplitude), width (measure of the support), and frequency (inverse wavelength). Roughly speaking, if a function has amplitude 𝐴, is supported on a set of volume 𝑉, and has frequency 𝑁, then the 𝑊^{𝑘,𝑝} norm is going to be about 𝐴𝑁^{𝑘}𝑉^{1/𝑝}. The uncertainty principle tells us that if a function has frequency 𝑁, then it must be spread out on at least a ball of radius comparable to the wavelength 1/𝑁, and so its support must have measure at least 1/𝑁^𝑑 or so: 𝑉 more than or equal to 1/𝑁^𝑑:  This relation already encodes most of the content of the Sobolev embedding theorem, except for endpoints. It is also consistent with dimensional analysis, of course, which is another way to derive the conditions of the embedding theorem.
Sobolev space, one can classify the integrability and regularity of a function space norm by testing that norm against a bump function of amplitude 𝐴 on a ball of volume 𝑉, modulated by a frequency of magnitude 𝑁. Typically the norm will be of the form 𝐴𝑁𝑘𝑉1/𝑝 for some exponents 𝑝, 𝑘 (at least in the high frequency regime 𝑉≳1/𝑁^𝑑). One can then plot these exponents 1/𝑝, 𝑘 on a two-dimensional diagram as mentioned by Jitse to get a crude "map" of various function spaces (e.g. Sobolev, Besov, Triebel-Lizorkin, Hardy, Lipschitz, Holder, Lebesgue, BMO, Morrey, ...) The relationship 𝑉 ≳ 1/𝑁^𝑑 lets one trade in regularity for integrability (with an exchange rate determined by the ambient dimension - integrability becomes more expensive in high dimensions), but not vice versa	Classification
Sobolev space, For an operator like the Laplacian, its domain is not the set of all functions, but a subspace where the operator is "well-behaved." The Sobolev space is precisely this subspace. The eigenfunctions of the Laplacian (e.g., sine waves on an interval) are in a Sobolev space. The space is a "safe ground" where the operator can act without causing a function to blow up	Sobolev spaces are the domains of unbounded operators, like the Laplacian.
Sobolev space, function in a Sobolev space has a "measure-like" derivative. For a function with a jump, its classical derivative is infinite.Its weak derivative is a Dirac delta measure, which is not a function. But in a Sobolev space, the weak derivative is a function, not a measure. The space is a subset of the functions whose "measure-like" derivative is nice enough to be a function	A function in a Sobolev space has a distributional derivative that is a function in an L^p space.
Sobolev space, In stochastic analysis, we deal with random functions, like a random walk. The Malliavin derivative, a form of weak derivative, is used to study the properties of these random functions. Sobolev spaces are the spaces where these derivatives live. This provides a rigorous way to define and study "smoothness" for random functions	Sobolev spaces are used in the analysis of stochastic processes, especially in Malliavin calculus.
Sobolev space, distribution is a generalized function. A Sobolev space is the set of all distributions whose weak derivatives are also functions. This gives us a hierarchy of spaces, from the space of all distributions to the space of smooth functions, with Sobolev spaces in between	Sobolev spaces are the spaces of distributions that are functions.
Sobolev space, regularity of a function can be measured by its Sobolev norm. A higher Sobolev norm means a smoother function. Microlocal analysis studies the "local smoothness" of a function at different points and in different directions. Sobolev spaces provide a way to quantify this smoothness and understand how it changes	Sobolev spaces are a natural setting for studying the regularity of solutions to PDEs.
Sobolev space, Sobolev norm of a function is related to the decay of its Fourier transform. A function is in a Sobolev space W^{k,p} if its Fourier transform decays fast enough. This is a way of seeing that a smooth function in the time domain corresponds to a rapidly decaying function in the frequency domain	Sobolev spaces are related to the decay of the Fourier transform.
Sobolev space, Banach space is a complete normed vector space. The Sobolev space is a Banach space, which means that any Cauchy sequence of functions in the space converges to a function that is also in the space. This makes it a "good" space to do analysis, as it doesn't have "holes" in it	Sobolev spaces are a primary example of a Banach space.
Sobolev space, optimal control, you are trying to find a control function that minimizes a cost functional. The control function and the state of the system are often in a Sobolev space. This provides a way to ensure that the control function is "well-behaved" and the system's state is "smooth enough."	Sobolev spaces are the natural setting for optimal control problems.
Sobolev embedding, W(1,1) p = 1, k = 1 is in L^\infty(R), first derivative, so the norm is the actual value, therefore this is the fundamental theorem of calculus	Fundamental theorem of calculus
Sobolev embedding, W(d,1) p = 1, k = d is in L^\infty(R^d), d-th derivative, p = 1 so the norm is the actual value, therefore this is the iterated fundamental theorem of calculus + Fubini	Therefore this is the iterated fundamental theorem of calculus + Fubini.
Sobolev embedding, W(0, p) (R^d), k is the 0th derivative, so not derivative, this gives L^p(R^d), this is trivial	Trivial case
Regularity in Sobolev norms,  of functions, like a landscape with hills and valleys. The Lp norm measures the "flatness" or overall size of the function; for example, a function with a small L2 norm is generally "low" or close to zero. The Sobolev norm, however, also accounts for the "smoothness" or "steepness" of the landscape. A function with a high Sobolev norm is not only "large" but also has "steep" slopes (large derivatives) up to a certain order. The Sobolev embedding theorems are like a rule that says if your landscape is "smooth enough" and "steep enough" in a certain way, then it must also have a specific property, like being "bounded" or continuous, which is a stronger property. For example, the Sobolev embedding theorem W1,2(R) into L^\infty(R) for 1D functions says that if a function and its derivative have finite L2 norms, then the function must be bounded. This is visualized as a function with finite "energy" (from the L2 norm of the derivative) being constrained from "blowing up" to infinity	Regularity in the context of Sobolev embedding and norms refers to the property of a function having a certain number of weak derivatives that are also in a given Lp space. The Sobolev norm ||f||_Wk,p(Ω)​ quantifies this regularity by combining the Lp norm of the function itself with the Lp norms of its weak derivatives up to order k. Sobolev embedding theorems establish conditions under which a function with high regularity (i.e., a high Sobolev norm) can be guaranteed to have better properties, such as being continuous or belonging to a different Lq space, providing a link between differentiability and continuity.
Regularity, random walk on a graph. The walk's path is a sequence of points. If the walk is a simple one, it just jumps from one point to another, and its path is "jagged" and discontinuous. A more "regular" process, like a Brownian motion, can be thought of as a continuous random path. While it's continuous, it's also highly "wrinkled" and "fractal," with infinite wiggles at any point. This corresponds to its non-differentiability. The regularity of this path (i.e., its continuity) is a guaranteed property of the process, even though its "smoothness" in the classical sense is low. The norm here might be related to the maximum displacement or the variation of the path over time, which quantifies its "size" or "jaggedness" in a probabilistic sense. For example, the quadratic variation of a Brownian motion is deterministic (t), which tells us something about the process's overall regularity, even though the sample paths are not smooth	In probability theory, especially for stochastic processes, regularity can be understood as the smoothness of sample paths. A stochastic process is a collection of random variables indexed by time. The regularity of the process refers to the properties of its realizations, or sample paths, as functions of time. For example, a Brownian motion has continuous but nowhere-differentiable sample paths, while other processes might have smoother paths.
Regularity, imagine the graph of a function as a surface, and a PDE as a set of physical constraints on that surface. For example, the Laplace equation Δu=0 says that the surface has no local maxima or minima and that it is "harmonic" or "smooth." A weak solution to the Laplace equation might be a surface that's "close" to being smooth but could have sharp corners or edges.  Elliptic regularity theory for the Laplace equation states that if a function satisfies the equation in a weak sense and has a certain level of smoothness, then it must be infinitely differentiable. This is like a principle that says the physical law of a "harmonic surface" is so strong that it forces any function that satisfies it to be perfectly smooth. The Sobolev embedding theorem here is a tool that helps to translate the "weak smoothness" from the equation into "strong smoothness" of the solution	In the context of partial differential equations (PDEs), regularity refers to the smoothness of a solution. A solution to a PDE is a function that satisfies the equation. The regularity of this solution is measured by how many continuous derivatives it has. A weak solution might only be in a Sobolev space and not have classical derivatives, but a regularity theory for a PDE provides conditions under which a weak solution is also a classical (smooth) solution. This is a crucial concept, as it allows us to prove that solutions we find in a weak sense are actually "well-behaved" enough to be physically meaningful.
Regularity, Laplacian operator Δ on a domain Ω. The eigenfunctions of the Laplacian, un​, satisfying −Δun​=λn​un​, are often sine and cosine functions or Bessel functions, which are very smooth. The regularity of these eigenfunctions is a natural property. The spectral theorem states that any function in the domain can be decomposed into a sum of these eigenfunctions. For example, a "rough" or "jagged" function on a disk can be represented as a weighted sum of smooth Bessel functions. The Sobolev norm measures how many of these smooth eigenfunctions are needed to approximate the function. A function with high regularity (high Sobolev norm) is a sum of only a few smooth eigenfunctions, while a low-regularity function requires a sum of many high-frequency eigenfunctions (which correspond to higher eigenvalues) to approximate it	In the spectral theory of operators, regularity can be viewed as the smoothness of functions in the domain of an operator. An operator A:D(A)→H maps elements from a domain D(A) to a Hilbert space H. The regularity of the functions in the domain is related to the operator itself. For example, a differential operator like dxd​ acts on functions, and its domain is often a Sobolev space, where functions have a certain degree of regularity. The spectral theorem for a self-adjoint operator, for instance, decomposes the Hilbert space into a sum of eigenspaces, with each eigenvector having a certain regularity.
Regularity, Consider a nonlinear map F	X→Y between Banach spaces. We can visualize this as a "stretching and bending" of the space X. The Fréchet derivative at a point is a linear approximation of this map, like a tangent plane to the curved surface. If this linear approximation is non-degenerate (i.e., an invertible map), then the nonlinear map locally behaves like a linear map. The regularity of the map, such as its continuous differentiability, ensures that this local linear approximation exists and varies smoothly from point to point. Sobolev embedding theorems are used here to show that a solution to a nonlinear PDE, which is a fixed point of some nonlinear operator, has a certain regularity. For example, if we have a nonlinear equation that we know has a weak solution, we might use a Sobolev embedding to show that the solution is continuous, which then allows us to apply more powerful tools from calculus:  In nonlinear functional analysis, regularity is concerned with the smoothness of solutions to nonlinear equations or the properties of nonlinear operators. A key concept is the inverse function theorem for Banach spaces, which states that if a nonlinear operator is "well-behaved" (i.e., its Fréchet derivative is a bounded linear isomorphism), then it has a local inverse, and the inverse is also smooth. Regularity is thus a property that allows us to transfer smoothness from one space to another.
Regularity, a distribution can be visualized as a "linear machine" that takes a smooth function and outputs a number. A regular distribution is a machine that does this by simply integrating the smooth function against a "nice" function. For example, the Dirac delta distribution, δ, is an irregular distribution. It doesn't correspond to any function, but it acts on a test function by just picking out its value at zero	⟨δ,ϕ⟩=ϕ(0). Sobolev embedding theorems say that if a distribution and its weak derivatives are "close enough" to be regular functions in a certain sense (i.e., they are in an Lp space), then the distribution itself must also be a regular function with better properties, like being continuous. This is a powerful result that provides a bridge between the abstract world of distributions and the concrete world of classical functions:  In distribution theory, a regularity can be interpreted as the property of a distribution being a function. A distributionis a generalized function that acts on test functions (infinitely smooth functions with compact support). A distribution is said to be regular if it can be represented by a locally integrable function. The Sobolev spaces are spaces of distributions that have "weak derivatives" that are also distributions.
Regularity, process of heat diffusion on a metal rod. The temperature distribution at time t is the result of a semigroup acting on the initial temperature profile. Even if the initial temperature profile is "jagged" (e.g., a discontinuous function), the heat equation is so "smoothing" that the temperature profile becomes infinitely differentiable for any time t>0. This is the regularizing effect of the semigroup. The Sobolev norm here can measure the smoothness of the temperature profile at any given time. The regularity theory for the heat equation says that even if the initial state u_0​ is only in L^2, the solution u(t) will be in C\infty for any t>0. The Sobolev embedding theorem is the tool that tells us that once the solution is in a high-enough Sobolev space (which it is for any t>0), it must be continuous and even infinitely differentiable	Semigroup theory studies families of operators that describe the evolution of a system over time. A regularity propertyof a semigroup, {T(t)}_t nonnegativity​, refers to the smoothness of the solution u(t)=T(t) u_0​ as a function of time, for an initial condition u_0​. A key concept is the analytic semigroup, where the solution not only is continuous in time but also can be extended to an analytic function in a sector of the complex plane. This implies that the solution is infinitely differentiable with respect to time for t>0.
Regularity, very jagged function. We can "smooth it out" by taking a weighted average of its values in a small neighborhood. This is exactly what convolution with a mollifier does. The resulting function is smooth, even though the original one wasn't. The Sobolev norm measures how "close" a function is to a smooth function. A function in a high Sobolev space is "close" to a smooth function, and the Sobolev embedding theorem says that this "closeness" implies a better property, like continuity. For example, a function in W1,2 can be approximated by a sequence of smooth functions, and the embedding theorem tells us that the limit of this sequence must be a continuous function	Regularity can be seen as the result of a smoothing process. For example, convolution with a smooth function (like a Gaussian kernel) can turn a "rough" function into a "smooth" one. The mollifier is a family of smooth functions with compact support that can be used to approximate any function in an L^p space with a sequence of smooth functions. The regularity of the function is then the property that it can be approximated by smooth functions in some sense.
Brauer group, twisted field	Twisting of multiplication that prevents an algebra from being a matrix ring over 1
Brauer group, equivalence class	The Brauer group is a set of equivalence classes of central simple algebras. The ontology is not about individual algebras, but about their collective properties, specifically their similarity to a matrix algebra.
Brauer group, operation is tensor product	Addition is tensor product of algebras, elements are Morita equivalence classes of simple algebras over K. Classify division algebras over a field, and build them with tensor products.
Brauer group, divsion algebra group	Group of division algebras up to matrix equivalence
Brauer group, cohomology group	H^2(G, F^x) for Galois group X, field under multiplication F
Brauer group, matrices	Brauer group classifies algebras that become matrix algebra after field extensions
Brauer group, number theory	Classify algebra over number fields by looking at completions
Brauer group, Azumaya algebras	set of all possible ways to define a sheaf of Azumaya algebras on an algebraic variety, or the isomorphism classes of Azumaya algebras under Morita equivalence
Brauer group, dimension	Classifies algebras based on dimension over the field
Brauer group, meaning of central simple	simple means no non-trivial two sided ideals, central means center is base field
Brauer group, splitting field	splitting field is field extension that turns central simple algebra into matrix algebras
Brauer group, obstruction to commutativity	measures obstruction to commutative rings. An element is in the trivial class if and only if its corresponding algebra is a matrix ring over the base field, a commutative object.
Brauer group, cohomological Galois extensions	encodes Galois extension information using cocycle conditions
Brauer group, group of 2-cocycles	H^2(G, F^x) means group of 2 cocycles of Galois group of separable closure
Artin reciprocity, Consider the extension Q(i)/Q with Galois group Gal(Q(i)/Q) isomorphic to C^2​={1,σ}, where σ is complex conjugation. The prime ideals in Z[i] are defined by their norms. Primes p in Z that are congruent to 1(mod4) split, like 5=(2+i)(2−i). The Artin map sends the ideal (2+i) to the identity element. Primes congruent to 3(mod4) remain inert, like 3. The Artin map sends the ideal (3) to the non-trivial element σ. This can be visualized on a "number lattice" in the complex plane,where the primes are points. The Artin map acts like a filter, sending some points (the split primes) to "do nothing" (identity) and others (the inert primes) to "flip" the lattice (complex conjugation)	The Artin map is a homomorphism from the group of fractional ideals of a number field K to the Galois group of an abelian extension L/K. It's a central object in class field theory that connects the arithmetic of K (ideals) with the Galois theory of L. It sends a prime ideal p to its corresponding Frobenius element in the Galois group.
Artin reciprocity, consider an algebraic curve defined over Fq​. The geometric points of this curve can be thought of as a graph, where the edges connect points that are conjugates under the Frobenius map. The étale fundamental group, π1et​(X), can be imagined as the group of all loops on this graph, allowing for "jumping" between fields. The Frobenius automorphism acts on this graph, moving points around. Artin reciprocity says that the action of the Frobenius element on these loops is the same as the action of the Galois group of the function field	In algebraic geometry, for a smooth, connected, and proper curve X over a finite field Fq​, the geometric Frobenius automorphism acts on the geometric points of X. The Artin reciprocity law is a statement about how the action of this Frobenius element on the étale fundamental group of X relates to the action of the Galois group of the function field of Xon the field of functions.
Artin reciprocity, think of the circle S1. Its universal cover is the real line R. The group of deck transformations is Z, which is the fundamental group of S^1. Now, consider the "arithmetic circle" Spec(Z). It has a single "point at infinity" and a point for each prime number. The maximal abelian extension of Q is the cyclotomic field Q(μ∞​), whose Galois group is Gal(Q(μ∞​)/Q)≅Z× or the ring of integers under multipication. This group is the "fundamental group" of this arithmetic space, and the extension is the "universal abelian covering." Artin reciprocity says that the action of this Galois group corresponds to the geometry of this space	Artin reciprocity can be seen as an arithmetic analogue of the geometric theory of covering spaces. In topology, for a manifold M, the fundamental group π1​(M) classifies all covering spaces of M. For an abelian covering, the Galois group of the covering space is isomorphic to the fundamental group mod its commutator subgroup. Artin reciprocity provides an arithmetic analogue where the Galois group of an abelian extension of a number field K is the "fundamental group"of some geometric object associated to K, specifically the "space of primes" or Spec(O_K​).
Artin reciprocity, A central simple algebra can be thought of as a generalized matrix algebra. The Brauer group is a collection of these algebras, where multiplication is tensor product. The elements of the Brauer group are "twists" of matrix algebras. Artin reciprocity provides a complete picture of how these "twists" behave over a number field. It tells us that an element of the global Brauer group is uniquely determined by its local components, which are in the Brauer groups of the local fields. This is like having a set of locally-defined blueprints for a structure that perfectly fit together to form a unique global structure	Brauer group of a field K, Br(K), is a group of equivalence classes of central simple algebras over K. The Brauer group of a number field is a cornerstone of class field theory. Artin reciprocity gives a powerful description of this group, providing an exact sequence that relates it to the local Brauer groups.
Artin induction theorem, character table of a group G. The characters of G are vectors in a vector space. Artin's induction theorem says that the "building blocks" for all these character vectors are the vectors from the cyclic subgroups. Artin reciprocity is a parallel statement for field theory	the "building blocks" for all abelian extensions are the cyclic extensions. This can be visualized as a tree of field extensions, where the root is the base field, and the branches are extensions. The reciprocity law tells us how to build the entire tree just from knowing the simplest, cyclic branches:  Artin's induction theorem in representation theory states that any rational-valued character of a finite group G can be written as a rational linear combination of characters induced from cyclic subgroups. Artin reciprocity can be seen as a generalization of this theorem from characters to field extensions. It shows that the structure of an abelian extension is controlled by the structure of its cyclic sub-extensions.
Artin reciprocity, think of the "space" Spec(K) as having a group of "loops" on it, which is the fundamental group. Unlike in topology, these loops are built from prime ideals. Artin reciprocity says that if you take all these loops and "unwind" them into their abelian part (i.e., you forget the order in which you trace the loops), the resulting abelian group is exactly the Galois group of the maximal abelian extension	Anabelian geometry is the study of schemes and their fundamental groups, with the goal of reconstructing the scheme from its fundamental group. In this context, the Artin reciprocity law for a field K is the statement that the Galois group of its maximal abelian extension is the abelianization of its profinite fundamental group, π1pro​(Spec(K)).
Artin reciprocity, set of all prime ideals of a number field as a set of points, like a discrete number line. The ideal class group is the group that "shifts" these points, for instance, by multiplication with non-principal ideals. The Artin map is a rule for translating this "shifting" action into an action on a finite set of points (the elements of the Galois group)	In class field theory, the ideal class group of a number field K acts as the group of covering transformations for the "arithmetic covering" of K's spectrum by its Hilbert class field. Artin reciprocity says this group is isomorphic to the Galois group of the Hilbert class field, thereby providing a concrete realization of the abstract Galois group.
Laziness in Haskell, weak head normal form	the data structure is fully determined upon evaluation. Placeholders allow for nonstrict evaluations, with as little evaluation done as necesssary. This is very similar to what tinygrad has done. Therefore, one can define and initialise infinite data structures in Haskell.
Krull dimension, supremum of length of chains of prime ideals, in schemes with local ring	Krull dimension of a ring is the supremum of the lengths of all chains of prime ideals. For a scheme, its dimension is the Krull dimension of its local rings.
Dimension, dimension of a scheme	dimension of a scheme is the supremum of the dimensions of all its local rings.
Codimension, difference in dimension or smallness of subvarieties	codimension of a subvariety in an algebraic variety is the difference between their dimensions. It's an important measure of how "small" a subvariety is.
Dimension, chain of primes and chain of prime ideals	dimension of a scheme is defined by a chain of prime ideals. A chain of prime ideals is a sequence of prime ideals p_0 in p_1 in... p_m
Dimension, Krull's principal ideal theorem for Noetherian ring and the height of a prime ideal	for a Noetherian ring, the height of a prime ideal is at most the number of generators of an ideal contained in it. Codimension is geometric, corresponds to the algebraic concept the height of a prime ideal.
Dimension, visual intuition	Krull dimension corresponds to the intuitive geometric dimension of an algebraic variety. A variety of dimension 1 is a curve, a variety of dimension 2 is a surface, and so on.
Dimension, local ring and m-primary ideal	dimension of a local ring is the minimum number of elements that can generate a m-primary ideal.
Dimension, homological dimension of a module	homological dimension of a module is the length of its minimal free resolution. This provides a way to measure the complexity of a module.
Dimension, global dimension of projective dimensions of all modules	global dimension of a ring is the supremum of the projective dimensions of all modules over that ring. Rings with finite global dimension are often well-behaved.
Dimension, cohomological dimension of a scheme	cohomological dimension of a scheme is a measure of its size based on the vanishing of certain cohomology groups. It is related to the topological dimension.
Dimension, comparison with rank	Dimension means actual number of dimensions, rank means effective number of dimensions (number of linearly independent columns or rows)
Codimension, height of prime ideal	algebraic counterpart of codimension is the height of a prime ideal. For a ring R and a prime ideal p, the height of p, denoted ht(p), is the length of the longest chain of prime ideals contained in p.
Codimension, visual intuition	geometric intuition of "how many equations you need to define a subvariety." For example, a point in a 2D plane has codimension 2, which is defined by two equations (x=0,y=0).
Codimension, subscheme	closed subscheme Y of a scheme X, the codimension is the minimum of the heights of the prime ideals in the local rings of X that contain the ideal defining Y.
Codimension, pure codimension of subscheme	subscheme is of pure codimension if all its irreducible components have the same codimension.
Codimension, hypersurface	subscheme defined by a single non-zero function is a hypersurface, and it typically has codimension 1.
Codimension, size of a subspace	A higher codimension means a "smaller" subspace relative to the larger space.
Codimension, motivation to define complete intersection of a subvariety	subvariety is a complete intersection if its codimension is equal to the number of equations needed to define it.
Codimension, core concept in intersection theory	core concept in intersection theory, which studies how subvarieties intersect. For example, in a smooth variety, the intersection of two subvarieties of codimensions c1​ and c2​ is expected to have codimension c1 ​+ c2​.
Codimension, derived subscheme	derived algebraic geometry, the concept of a subscheme is generalized to a derived subscheme, and its codimension is a measure of the "size" of the subscheme in a homotopical sense.
Codimension, derived prime ideal	height of a derived prime ideal in a commutative ring spectrum is a measure of its derived codimension.
Codimension, etale codimension	étale codimension of a subscheme is the dimension of the subscheme within the étale topology, which is a finer topology than the Zariski topology.
Codimension, spectral codimension	spectral codimension of a subobject in a spectral category is a measure of its "size" in a homotopical sense.
Codimension, locus of section, codimension of the vanishing locus of section of vector bundle, and Euler classes	codimension of the vanishing locus of a section of a vector bundle is a key invariant in algebraic geometry, which is computed using the Euler class.
Codimension, of a singular locus of a scheme and behaviour of singularities	codimension of a singular locus of a scheme is a measure of how "badly behaved" the singularities are. A singularity of codimension 1 is a relatively mild singularity.
Bezout's theorem, motivates spaces in combinatorics	curves d and e of degree d and e in complex projective plane CP^2 intersects at exactly d * e points. The correct definition of intersection and the proper setting in complex projective space of exactly needed for combinatorics since in projective space, any two lines intersect.
Bipartite graph, motivates Mantell's theorem	for N vertex graph, maximum number of edges without forming triangles is n^2/4. The bipartite graph is the extreme example of this.
Finite dimensional vector spaces, norm construction is induced by the topology	we show that every vector space has a norm. Every vector space has a finite linear combination of basis vectors (even if it has infinite dimensions, this uses some weird completion magic). Take the maximum of the coefficients amongst finitely many basis vectors, this defines one possible norm that is induced by the topology, particularly by the dimension of the vector space. Infinite dimensional TOPOLOGICAL vector spaces do not have a norm that induces the topology.
Rank, group of integers Z has a rank of 1, as it can be generated by the single element 1. You can visualize this on the number line, where every point can be reached by adding or subtracting 1. The rank tells you the "dimensionality" of the group in terms of its generating elements	The rank of a group (or, more generally, an algebraic structure) is the minimum cardinality of a generating set. Visual intuition: The group of integers Z has a rank of 1, as it can be generated by the single element 1. You can visualize this on the number line, where every point can be reached by adding or subtracting 1. . The rank tells you the "dimensionality" of the group in terms of its generating elements.
Rank, a matrix that transforms a space. For example, a 3×2 matrix A transforming R2 to R3. If the rank is 2, the two column vectors are linearly independent, and their span forms a 2-dimensional plane in R3. The rank tells you the dimension of the subspace that the matrix "lands" on. A rank-1 matrix would squash the entire space onto a line	In linear algebra, the rank of a matrix is the dimension of its column space (or, equivalently, its row space). It's the maximum number of linearly independent columns.
Rank, free module Z2 over the ring Z. Its basis is {(1,0),(0,1)}, so its rank is 2. This can be visualized as the integer grid in a 2D plane. . The rank tells you the "size" of the grid	In homological algebra, the rank of a free module over a commutative ring is the size of its basis. Visual intuition: Consider the free module Z2 over the ring Z. Its basis is {(1,0),(0,1)}, so its rank is 2. This can be visualized as the integer grid in a 2D plane. . The rank tells you the "size" of the grid.
Rank, L-function and the Birch and Swinnerton-Dyer conjecture relates the rank of an elliptic curve to the order of the zero of its L-function at s=1. We can visualize the L-function as a complex function and the rank as the number of times it "touches" zero at a specific point	In arithmetic number theory, the rank of an L-function at a point is the order of the zero of the function at that point. Visual intuition: The Birch and Swinnerton-Dyer conjecture relates the rank of an elliptic curve to the order of the zero of its L-function at s=1. We can visualize the L-function as a complex function and the rank as the number of times it "touches" zero at a specific point.
Rank, sheaf of regular functions on an affine variety. The stalk at a point P is the set of all regular functions defined in a neighborhood of P. The rank of this sheaf is 1 at every point	In algebraic geometry, the rank of a sheaf is the dimension of the stalk of the sheaf at each point. Visual intuition: Consider the sheaf of regular functions on an affine variety. The stalk at a point P is the set of all regular functions defined in a neighborhood of P. The rank of this sheaf is 1 at every point.
Rank, dimension of homology example, simplicial complex, like a hollow sphere. The homology group H2​ has rank 1, corresponding to the single "hollow" region. The rank tells you the number of independent "holes" of a given dimension	In homological algebra, the rank of a chain complex is the dimension of its homology groups. Visual intuition: Consider a simplicial complex, like a hollow sphere. The homology group H2​ has rank 1, corresponding to the single "hollow" region. The rank tells you the number of independent "holes" of a given dimension.
Rank, group algebra F2​[C3​] of the cyclic group of order 3. It has a basis {e,g,g2}, so its rank is 3. This is a vector space over a finite field. The rank is the number of elements in the basis	In modular representation theory, the rank of the group algebra Fp​[G] is the dimension of the algebra as a vector space over Fp​, which is equal to the order of the group. Visual intuition: Consider the group algebra F2​[C3​] of the cyclic group of order 3. It has a basis {e,g,g2}, so its rank is 3. This is a vector space over a finite field. The rank is the number of elements in the basis.
Rank, double pendulum. It has two degrees of freedom, the angles of the two pendulums. So its rank is 2. . The rank tells you the "number of dimensions" of the system's phase space	In dynamical systems, the rank can refer to the number of independent "degrees of freedom" or "modes" of the system. Visual intuition: Consider a double pendulum. It has two degrees of freedom, the angles of the two pendulums. So its rank is 2. . The rank tells you the "number of dimensions" of the system's phase space.
Rank, elliptic curve infinite number of rational points. The rank is the number of "independent" points that can generate all other points. For example, a rank-1 curve has a single point that, through the group law, can generate an infinite number of other points	In arithmetic number theory, the rank of an elliptic curve E over Q is the rank of the group of rational points E(Q). It's the number of generators of the group modulo torsion. Visual intuition: Consider an elliptic curve with an infinite number of rational points. The rank is the number of "independent" points that can generate all other points. For example, a rank-1 curve has a single point that, through the group law, can generate an infinite number of other points.
Rank, tangent bundle of a sphere. At each point on the sphere, there's a tangent plane. The dimension of this plane is 2, so the rank of the tangent bundle is 2. The rank tells you the dimension of the "fiber" over each point	In algebraic geometry, the rank of a vector bundle is the dimension of the vector space associated with each point of the variety. Visual intuition: Consider the tangent bundle of a sphere. At each point on the sphere, there's a tangent plane. The dimension of this plane is 2, so the rank of the tangent bundle is 2. . The rank tells you the dimension of the "fiber" over each point.
Rank, for 2×2 matrices with entries in Z, M2​(Z). The rank of the projective module M2​(Z) is the dimension of the space over the field of fractions of the ring, which is 4. This corresponds to the "dimension" of the matrix algebra	in non-commutative ring theory, the rank of a finitely generated projective module P is a function that assigns a dimension to each prime ideal of the ring. Visual intuition: Consider the ring of 2×2 matrices with entries in Z, M2​(Z). The rank of the projective module M2​(Z) is the dimension of the space over the field of fractions of the ring, which is 4. This corresponds to the "dimension" of the matrix algebra.
Rank, coboundary is a function that can be written as a difference of two other functions. The rank of the coboundary tells you the number of dimensions of the "space of differences"	In dynamics, the rank of a coboundary can be the dimension of the space of functions that are coboundaries. Visual intuition: A coboundary is a function that can be written as a difference of two other functions. The rank of the coboundary tells you the number of dimensions of the "space of differences".
Rank, first homology group of a figure-eight space is Z⊕Z, which has a rank of 2. This corresponds to the two independent loops in the space. The rank is the number of loops	In homotopy theory, the rank of a homology group Hn​(X) is the rank of its free part. Visual intuition: The first homology group of a figure-eight space is Z⊕Z, which has a rank of 2. This corresponds to the two independent loops in the space. . The rank is the number of loops.
Rank, Lorenz attractor has a fractal dimension of approximately 2.06. This tells us how "space-filling" the attractor is. It's not a line (dimension 1) and not a plane (dimension 2), but something in between	In dynamical systems, the rank of a strange attractor is its fractal dimension. Visual intuition: The Lorenz attractor has a fractal dimension of approximately 2.06. This tells us how "space-filling" the attractor is. It's not a line (dimension 1) and not a plane (dimension 2), but something in between.
Trace, linear transformation in 2D space. The trace is the sum of the eigenvalues, which represent the scaling factors of the principal axes of the transformation. For a shear transformation on a square, the trace is 2, indicating that the transformation preserves area and directionality on average, even as it distorts the shape	The trace of a square matrix A, denoted tr(A), is the sum of the elements on the main diagonal. It is equal to the sum of the eigenvalues of the matrix, counting multiplicities.
Trace, the characters of a group representation as a "fingerprint" of the representation. The trace of p(g) is the sum of the eigenvalues of the matrix representing the action of g on the vector space V. For the representation of the cyclic group C^3​ acting on C^2 by rotation, the character for a rotation by 120∘ is exp(i2π/3)+exp(i4π/3)=−1, which is the sum of the complex eigenvalues. This single value tells us a lot about the rotation's effect	For a finite group G and a field F, the trace of a representation p:G to GL(V) is the function g↦tr(p(g)). This function is the character of the representation.
Trace, chain complex as a sequence of vector spaces connected by linear maps. The trace of a chain map represents a "net flow" or a "weighted count" of fixed points. The Lefschetz trace formula is a concrete example. For a map f on a finite complex, its Lefschetz number L(f) is this alternating sum of traces. If the map has isolated fixed points, this number counts them, each with a sign determined by the local behavior of the map. For a rotation of a torus, the trace of the induced map on homology is non-zero only if the rotation has a fixed point	In the context of complexes of modules, the trace of a chain map f: C to C can be defined as the alternating sum of traces on each component, tr(f)= sum of (−1)^i tr(f_i​).
Trace, trace of a matrix over a non-commutative ring is not well-defined as a single element, its image in the abelianized ring R_{ab}​ is. Think of the commutators [R,R] as representing the "non-commutative noise" in the ring. The trace map filters out this noise, leaving a well-defined value that captures the sum of the diagonal elements, modulo the non-commutativity. The image of the trace in R_{ab}​ is an invariant, much like the trace of a matrix over a field	For a non-commutative ring R, the trace map tr : M_n(R) to R/[R,R] sends a matrix A to the class of  sum A_{ii}​ in the abelianization of R, denoted R_{ab}​. Here, [R,R] is the additive subgroup generated by commutators ab−ba.
Trace, a section of a vector bundle over a 2-sphere. The trace of a section of the endomorphism bundle, for example, of a vector field, is a scalar field on the sphere. The integral of this trace, weighted by a volume form, is related to the number of zeroes of the vector field. This is the Poincaré-Hopf Theorem at work. The trace operator captures the local behavior of the vector field, and integrating it "counts" the singularities	In the context of vector bundles over a manifold M, the trace of an endomorphism of a vector bundle can be seen as a section of the endomorphism bundle. The determinant of the trace is a key ingredient in the definition of the Euler characteristic of the bundle.
Trace, a field extension, for example, Q(root 2)/Q, as a 2-dimensional vector space over Q. Multiplication by an element, say a+b root 2, is a linear transformation. Its eigenvalues are the conjugates a±b root 2, The trace is the sum of these conjugates, (a+b root(2))+(a−b root (2)) = 2a. This trace map "projects" the field extension back down to the base field, capturing an average or a sum of the conjugates	For a field extension L/K, the trace map tr_{L/K} ​: L to K is a K-linear map. For an element a in L, the trace of a is the sum of the eigenvalues of the K-linear transformation on L given by multiplication by a.
Trace, the flow of a system of differential equations. The Jacobian matrix at a fixed point describes the local linearization of the flow. The eigenvalues of this matrix determine whether nearby trajectories are attracted to or repelled from the fixed point. The trace, being the sum of these eigenvalues, gives a quick indicator of the overall behavior. If the trace is negative, the system tends to contract volume locally. If it is positive, it expands. For a 2D system, if the trace is negative and the determinant is positive, the fixed point is stable. This relates the trace to the overall "attraction" or "repulsion" of the system	In the study of dynamical systems, the trace of the Jacobian matrix at a fixed point determines the local stability of the system.
Operator, linear transformation in R2 represented by a matrix. The matrix rotates, stretches, or shears a vector to a new location. An operator is a similar rule, but for functions. For example, the operator that takes a function and squares it is a nonlinear operator	An operator is a mapping between vector spaces.
Operator, subgradient operator maps a point on a convex function to a set of subgradients. For a convex function that is not everywhere differentiable, like f(x)= |x|, the subgradient at x=0 is the entire interval [−1,1]. The operator is the rule that maps x=0 to this set. The proximal map is an operator that projects a point onto a convex set	An operator can represent a proximal map or a subgradient operator.
Operators, eigenvalues of a matrix reveal its fundamental properties (e.g., whether it rotates or stretches), the spectrum of an operator reveals its underlying structure. The eigenfunctions of the Laplacian on a drumhead reveal its fundamental modes of vibration. An operator is the physical object (the drumhead) and its spectrum is the set of all its possible vibrations	"An operator is a machine whose internal workings are revealed by its spectrum."
Operator, conditional expectation operator takes a random variable and projects it onto a subspace of random variables that are measurable with respect to a sub-sigma-algebra. Imagine a random variable on a plane and a line on that plane. The operator takes the random variable and projects its distribution onto the line	An operator can represent the conditional expectation.
Operator, derivative operator D is an operator that takes a function and gives its derivative. When acting on a distribution, it gives another distribution. For example, the derivative of the Heaviside step function is the Dirac delta function. The operator is a rule that transforms one generalized function into another	An operator is a continuous linear map from a space of test functions to a space of distributions, or vice versa.
Operator, curved space, like a sphere, the concept of a derivative is generalized. The Laplacian operator on a sphere takes a function on the sphere and gives another function. The operator is the rule for "differentiation" on a curved space	An operator is a differential operator on a manifold, like the Laplacian on a sphere.
Operator, stochastic process like a random walk, the generator is an operator that describes the "infinitesimal" change in the process. For a simple random walk, the generator is the discrete Laplacian. It's the "engine" that produces the random motion	An operator is the generator of a stochastic process.
Operator, representation of a group is a way of "realizing" the group's abstract elements as operators on a vector space. For example, the group of rotations in 3D can be represented by operators (matrices) that act on vectors in R3. The operator is the "physical manifestation" of an abstract group element	An operator is a representation of a group.
Homotopy, equivalent under parameterization	ontology in Homotopy Type Theory, the idea is the homotopy of a path and inverses covers areas and therefore is not exactly the identity, therefore one can invent homotopy to consider the entire area of paths and a path that covers no areas is equivalent, therefore this motivates homotopy as a higher dimensional operation.
Homotopy, filling space for paths between paths	consider family of paths with same end point then there are areas , so one can invent homotopy as a filling space of k+1 dimensions for k dimensional paths, inventing the notion of a k-morphism.
Homotopy, continuous deformation	"deformation" is a continuous family of maps parameterized by a "time" interval.
Homotopy, path in function space	continuous path in the space of continuous maps
Homotopy, family of map	continuous one parameter family of maps
Homotopy, map from cylinder	map from X * I into Y, I is unit interval, map restricted to the bottom face for the first map, top face for the second map
Homotopy, equivalence relation	Equivalence relation on set of continuous maps, partitioning into homotopy classes.
Homotopy, weak isomorphism	homotopy equivalent if pair of maps composition is homotopic to identity map, weaker than homemorphism (topological isomorphism)
Homotopy, define homotopy category	homotopy classes of maps are morphisms on the homotopy category, objects are topological spaces, homotopy is equivalence relation giving which morphisms are the same
Homotopy, defining invariant of invariant functor	Homotopy define invariant functors (fundamental group and homology groups), two maps are homotopic, induces same homomorphism
Homotopy, factorisation of maps	Factor maps through special objects and properties, example factor through cylinder objects with fibrations and cofibrations
Homotopy, high dim morphisms	homotopy between two 1-morphism is 2-morphism
Homotopy, nullhomotopic	map is nullhomotopic if homotopic to constant map, defines contractible spaces
Homotopy, relative	relative homotopy keep points in a subspace fixed, defining fundamental groups where loops have fixed base points
Homotopy, simplicial maps	defined combinatorially as elementary moves on simplicies of complex, giving discrete computational model
Homotopy, equal in type theory	Path between two points in space is proof that points are equal
Homotopy, fibration category	category with weak equivalences, it is an axiom
Homotopy, infinity groupoid	points are objects, paths are 1-morphisms, homotopies are 2-morphisms, and so on
Homotopy type theory, proof system using homotopy	define a point to be a (-2)-groupoid or a proposition, then consider symmetries of true statements, so types as points become infinitely groupoids considering from points to paths and so on.
Covering space, example with spiral staircase on to a circle	covering space of a topological space X is a space X~ with a continuous map p: X~ to X such that for every point x∈X, there is an open neighborhood U of x for which the preimage p−1(U) is a disjoint union of open sets in X, each of which is mapped homeomorphically onto U by p. Imagine a circle. A possible covering space is a "spiral staircase" that projects onto the circle. Each step of the staircase is a disjoint copy of a small arc of the circle. The projection map takes each point on the staircase to the corresponding point on the circle, wrapping around infinitely many times.
Covering space, real line as universal cover onto a circle with group Z that unwraps to real line	universal cover of a space X is a simply connected covering space, which "unwraps" all loops in X. For the circle, the universal cover is the real line. A path on the real line that starts at 0 and goes to 2π projects to a loop around the circle. The real line provides a way to "lift" any loop in the circle to a non-looping path.
Covering space, deck transformations as integer translations on spiral covering space of the real line	deck transformations are a group of homeomorphisms of a covering space X* that preserve the projection map p : X* to X is called the group of deck transformations. For the real line covering the circle, the deck transformations are the integer translations x to x + n for n in Z. These transformations move you from one "sheet" of the cover to another while still projecting to the same point on the circle.
Covering spaces, etale cover as a locally projection resemblence from y^2 = x to the line is an etale cover with two sheets, point on line is two points on hyperbola, looks like projection of two lines onto one	étale cover is a finite flat morphism of schemes that is unramified. It's a generalization of a covering space from topology to algebraic geometry. Imagine a complex algebraic curve with an étale cover. The cover is a new curve that projects onto the old one, locally looking like a product. For instance, the map from the hyperbola y2=x to the line is an étale cover (with two sheets). At a point on the line, there are two points on the hyperbola, which locally resembles a projection of two lines onto one.
Covering spaces, Galois cover with deck cover of the complex line by the hyperbola y^2 = x^2−1. The deck transformations are the reflections (x,y) to (x,−y)	étale cover whose deck transformation group acts transitively on the fibers. This group is called the Galois group of the cover. Imagine a cover of the complex line by the hyperbola y^2 = x^2−1. The deck transformations are the reflections (x,y) to (x,−y). This group acts transitively on the fibers (the two points above each point on the line), which are the algebraic counterpart to the deck transformations of a topological cover.
Covering, of categories like directed graph, local isomorphisms respect the direction of the morphisms	covering of a category is a functor that, for each object, maps the morphisms in the covering category to the morphisms in the base category in a well-behaved way. Imagine a category as a directed graph. A cover is a new graph that projects onto the old one, such that the maps from a new vertex to any other vertex are locally isomorphic to the maps from the old vertex. This is a way to "unfold" the graph.
Covering space, torus of 2D plane, dynamical systems of a torus is unwrapped to straight line on the plane	dynamical systems, a map f: X → X is a covering map if it's a local homeomorphism. The inverse map is not necessarily a single function. Imagine a torus (a doughnut shape). A dynamical system on the torus can be studied by lifting it to its universal cover, which is the 2D plane. The dynamics on the torus (a point moving around) is "unwrapped" to a straight line on the plane. The covering map provides a way to simplify the dynamics by working in a simpler space.
Covering space, induced covers from pullbacks of cover of codomain space X to domain space Y	concept of a covering can be induced by a map to another space. Visual Intuition: If we have a covering of a space X and a map from a space Y to X, we can "pull back" the cover to get a cover of Y. This is like taking a projection onto a screen, and then projecting the screen onto a new screen, which induces a new cover.
Covering space, classified by the fundamental group of the space, symmetries and subgroups of the fundamental group serve as the possible covers of the space	set of all covers of a space is classified by the fundamental group. The fundamental group acts as a "master list" for all possible covers of a space. Every possible cover corresponds to a subgroup of the fundamental group.
Sheaf, stick notes intuition	surface with sticky notes. A sheaf is a collection of "pieces of information" on each note. The sheaf conditions ensure that if you have a collection of pieces of information that "match up" on the overlapping parts of the notes, you can always glue them together to get a single, coherent piece of information on the whole surface.
Stalk, visual intuition of microscope	a powerful microscope. You're looking at a single point, and the stalk is the "data" that the sheaf assigns to that point, ignoring all the global information. It's the "infinitesimal" information.
Sheaf, locally free intuition with a surface and patches	Think of a surface. A locally free sheaf is like a vector bundle over that surface. For each little patch on the surface, the information on the sheaf is just a copy of a vector space.
Homology, measure of holes	measures the "holes" in a topological space.
Cocycle, cocycle condition measures circulation around a face	cocycle is a cochain whose differential is zero. The differential of a 1-cochain is a 2-cochain that, roughly, measures the circulation around the boundary of a face. The cocycle condition means there is no circulation.
Cocycle, visual intuition as set of arrows on the edges of a surface	Imagine a 1-cochain as a set of arrows on the edges of a surface, each with a numerical value. The differential of this cochain measures the "flow" around the boundary of each face. If the sum of the flows on the boundary of every face is zero, it's a cocycle.
Coboundary, cochain that is the differential of a previous cochain	cochain that is the differential of a previous cochain. The differential of a 0-cochain assigns a value to each vertex. The differential of this is a 1-cochain that measures the difference in values on the two endpoints of an edge.
Coboundary, visual intuition as assignment of heights along a surface by taking differences of heights	1-coboundary is an assignment of values to edges that comes from taking differences of values at the vertices. Imagine a height function on a surface; the 1-coboundary is the set of changes in height along the edges.
Cohomology, sheaf cohomology as obstructions on space attached to open sets	space with "data" attached to each open set (a sheaf). Sheaf cohomology measures the "obstructions" to consistently gluing together local pieces of data to form a global object.
Cohomology, singular cohomology for singular chains or continuous maps from standard simplices into the space	type of cohomology for topological spaces, defined using singular chains (continuous maps from standard simplices into the space). It is a fundamental invariant of a topological space.
Cohomology, de Rham as holes of the manifold	smooth manifold, de Rham cohomology is the cohomology of the complex of differential forms. It measures the "holes" in the manifold using calculus.
Cohomology, visual intuition in terms of vector fields closed 1-form with no curl, exact 1-form as gradient	closed 1-form is a vector field whose curl is zero. It's like a fluid flow that has no local vortices. An exact 1-form is the gradient of a function. de Rham cohomology tells you when a "no-vortex" flow is not the gradient of any height function
Cohomology, Betti numbers over real numbers as holes	dimension of the n-th cohomology group over the real numbers is the n-th Betti number, which is a measure of the number of n-dimensional holes in a space.
Spectral sequence, sequence of page	page is bigraded modules, sequence of bigraded modules
Spectral sequence, differentials	differential dr​: E_r^{p,q}​→E_r^{p+r, q−r+1}​ such that dr​ * dr​ = 0. This differential gives the page a chain complex structure.
Spectral sequence, homology of pages	next page, E_{r+1}​, is the homology of the previous page with respect to the differential dr​. This is the core mechanism of a spectral sequence.
Spectral sequence, convergence	converges to a graded object, which is typically the homology of a given complex. This means that for a fixed total degree n = p+q, the terms E_r^{p,q}​ eventually become stable for large r.
Spectral sequence, filtration	filtration of a chain complex C∙​. A filtration is a sequence of subcomplexes into F_p ​C_* ​into F_{p+1} ​C_* ​into ... The terms of the first page of the spectral sequence are related to the homology of the successive quotients of this filtration.
Spectral sequence, associated graded object	spectral sequence computes the homology of the filtered complex by first computing the homology of its associated graded object, Gr(C)= ++_p​ F_p ​C /F_{p+1} ​C. The first page, E_1​, is often the homology of this graded object. ++ is direct sum in this case.
Spectral sequence, edge homomorphisms	"edges" of the spectral sequence, where p = 0 or q = 0, are often simple and provide a way to relate the spectral sequence to the homology of the original complex.
Spectral sequence, first quadrant spectral sequence	first quadrant spectral sequence if its non-zero terms are only in the first quadrant of the bigraded plane, i.e., p ≥ 0,q ≥ 0.
Spectral sequence, exact couple	system of two objects and three maps that form a diamond-shaped commutative diagram.
Spectral sequence, homology of derived functors	computing the homology of derived functors. For example, the Grothendieck spectral sequence relates the derived functors of a composition of two functors to the derived functors of each individual one.
Spectral sequence, Hochschild-Serre Spectral Sequence	This spectral sequence relates the group cohomology of a group G to the group cohomology of a normal subgroup N and the quotient group G/N. It's a key tool in group cohomology and number theory.
Spectral sequence, homotopy theory	spectral sequence that computes the homotopy groups of a space by filtering its universal covering space. The Serre spectral sequence is a prime example, relating the homology of a fiber bundle to the homology of its base and fiber.
Spectral sequence, fibration	deeply connected to a fibration in topology. It allows us to compute the homology of the total space from the homology of the base space and the fiber.
Spectral sequence, Adams	omputes the stable homotopy groups of a spectrum using the Ext groups of its mod p cohomology.
Spectral sequence, Leray	sheaf cohomology computes the sheaf cohomology of a space by using the cohomology of a cover of the space and the cohomology of the intersections of the cover.
Cofibration, imagine a hollow sphere A=S2 and a solid ball X=D3. The inclusion map i	S2 to D3 is a cofibration. If we have a map from the ball to another space, and we start to deform the sphere (the boundary of the ball), we can always deform the whole ball in a consistent way. The boundary is "stuck" to the ball in a way that allows us to push any deformation from the boundary into the interior. This is the dual concept to a fibration, which allows us to "lift" homotopies from a base space: A cofibration is a continuous map i: Ato X between topological spaces that satisfies the homotopy extension property. This means that for any space Y, any map f: X to Y, and any homotopy H:A cross I to Y of the restricted map f∣A​, there exists a homotopy lift H~:X cross I to Y that extends H. In other words, any homotopy defined on the subspace A can be "extended" to a homotopy on the entire space X.
Cofibration, a space A and two maps, f	A to B and g: A to C. The pushout of this diagram is a space P that "glues" B and C together along the image of A. If the map A to B is a cofibration, the pushout is well-behaved. For example, if we glue two disks together along a circle, the resulting space is a sphere. The inclusion of the circle into the disk is a cofibration, and this property ensures that the gluing is well-behaved:  The homotopy extension property can be formulated in terms of a pushout square. A cofibration is a map A to X such that a specific pushout square is a pullback square.
Cofibration, the inclusion of the origin in the affine plane. This is a closed immersion. The map from Spec(k[x,y]/(x,y)) to Spec(k[x,y]) is a closed immersion. This is a geometric "cofibration," where a smaller space is "stuck" inside a larger one in a very rigid way. The embedding is a cofibration because any map from the origin to a scheme can be extended to the entire plane	A closed immersion of schemes f:X→Y is a morphism that is a homeomorphism onto its image, and the induced map on sheaves of rings is a surjective map. A closed immersion is a "cofibration" in the geometric sense, as it embeds one scheme as a closed subscheme of another.
Cofibration, a free module F and a submodule N. The inclusion of N into F is a cofibration. A free module is a "cofibrant" object, and this is a key property in homological algebra. It means that the module can be "built" from a free module	In the category of modules over a non-commutative ring, a cofibration is a module homomorphism that is an injective map with a projective cokernel. This is a "dual" concept to a fibration, which is a surjective map with an injective kernel.
Cofibration, consider field F_p​ as a single point. The field F_{p^n}​ is a larger field with more points. The inclusion map is a cofibration. This is a way of "embedding" a smaller algebraic object into a larger one. This is a fundamental construction in arithmetic geometry	In the context of number theory, a cofibration can be seen through the lens of a Frobenius map. The inclusion of a finite field into a larger finite field can be seen as a cofibration.
Cofibration, the group algebra F_p ​_Cp​. The simple module F_p​ is not projective. However, we can find a projective module P and a map from P to F_p​. The kernel of this map is a submodule. The inclusion of the kernel into the projective module is a "cofibration." This is a way of "building" a simple module from a projective one	In the category of modules over a group algebra, a cofibration is a module homomorphism that is an injective map with a projective cokernel. This is a key property for understanding the structure of modules and their relationships.
Cofibration, building a 2-sphere by starting with a point, attaching two lines (a "figure eight"), and then attaching a disk. At each step, the inclusion of the subcomplex is a cofibration. This is a way of "building" a complex space from simpler pieces in a well-behaved way. The cofibration property guarantees that the attachment is "non-trivial."	A CW complex is a space built up by attaching cells of increasing dimension. The inclusion of a subcomplex into a CW complex is a cofibration. This is a powerful property that makes CW complexes well-behaved in homotopy theory.
Cofibration, formal scheme is a "germ" of a scheme along a closed subscheme. The inclusion of the formal scheme of the origin in the formal scheme of the affine line is a cofibration. This is a way of "embedding" a local object into a larger one	A closed immersion of formal schemes is a cofibration in the category of formal schemes. This is a way of embedding a formal scheme as a closed subscheme of another.
Cofibration, a ring of integers Z is a principal ideal domain, so every ideal is free, and thus projective. The inclusion of an ideal, say 2Z, into Z is a cofibration. This is a way of "embedding" a module into a larger one in a well-behaved way	A ring R is left hereditary if every left ideal is a projective module. This means that every inclusion of a left ideal into the ring is a cofibration. This is a very strong property that is a key to understanding the homological properties of the ring.
Cofibration, inclusion of a compact manifold into a larger one is a proper morphism. For example, the inclusion of a sphere into R3 is a proper morphism. This is a way of "embedding" a compact object into a larger one	A proper morphism of schemes is a morphism that is separated, of finite type, and universally closed. A proper morphism is a "cofibration" in a strong sense. It is a map that is a closed embedding.
Cofibration, the ring of integers Z. The inclusion of Z into the ring of rational numbers Q is a cofibration. This is a way of "embedding" a ring into a field	The inclusion of a ring into its localization at a prime ideal is a cofibration in a sense. The localization process is a way of "embedding" a ring into a larger one.
Characteristic, field of rational numbers Q. The characteristic is 0, since no matter how many times you add 1 to itself, you never get 0	This can be visualized on a number line that extends infinitely in both directions. There is no finite number of steps that brings you back to the origin, which is a manifestation of characteristic 0.
Characteristic, representation is related to the trace of the matrices in the representation. For example, for the cyclic group of order 3, C3​, a representation over C sends the generator g to the matrix (0 1​; -1 −1​). The trace of the characteristic is the sum of the eigenvalues. These eigenvalues give us information about the "behavior" of the representation	In modular representation theory, the characteristic is an algebraic invariant of a representation of a group G over a field of characteristic p. It's a map from the group algebra to the field that captures the properties of the representation.
Characteristic, Euler characteristic of a polyhedron is calculated as V−E+F, where V is the number of vertices, E is the number of edges, and F is the number of faces. For a tetrahedron, V=4, E=6, and F=4, so the Euler characteristic is 4−6+4=2. For a cube, V=8, E=12, and F=6, so the Euler characteristic is 8−12+6=2. Both can be continuously deformed into a sphere, which also has a characteristic of 2. The characteristic is a measure of the "holes" in the object	In homotopy theory, the characteristic is a topological invariant, often called the Euler characteristic or Euler number. It's a number that describes the "shape" of a topological space. Visual Intuition: The Euler characteristic of a polyhedron is calculated as V−E+F, where V is the number of vertices, E is the number of edges, and F is the number of faces. For a tetrahedron, V=4, E=6, and F=4, so the Euler characteristic is 4−6+4=2. For a cube, V=8, E=12, and F=6, so the Euler characteristic is 8−12+6=2. Both can be continuously deformed into a sphere, which also has a characteristic of 2. The characteristic is a measure of the "holes" in the object.
Characteristic, short exact sequence of vector spaces 0 to A to B to C to 0. This can be viewed as a chain complex with three non-zero modules. The Euler characteristic is dim(A)−dim(B)+dim(C)=0. This is a statement of the "conservation of dimension" in the complex	In homological algebra, the Euler characteristic of a chain complex C∙​ is the alternating sum of the ranks of its modules, sum over i of ​(−1)^i rank(C_i​). It is related to the homology groups of the complex. Visual Intuition: Consider a short exact sequence of vector spaces 0 to A to B to C to 0. This can be viewed as a chain complex with three non-zero modules. The Euler characteristic is dim(A)−dim(B)+dim(C)=0. This is a statement of the "conservation of dimension" in the complex.
Stacks, a 2D representation of the cyclic group C4​ (rotations of a square). The group acts on the plane by rotating it. A nontrivial automorphism is a transformation of the plane (like a scaling or a shear) that commutes with the rotations. This means if you first rotate the plane and then apply the transformation, it is the same as applying the transformation and then rotating	A nontrivial automorphism of a representation of a group is an invertible linear map that commutes with the action of the group. These are symmetries of the representation itself. By Schur's Lemma, if a representation is simple, its endomorphism ring is a division algebra, and its automorphisms are the invertible elements of this algebra.
Stacks, sphere S2 has a vast group of automorphisms, given by rotations, reflections, and other more complex homeomorphisms. The rotation of the sphere about a fixed axis is a nontrivial automorphism. It is a symmetry of the sphere as a topological space	A nontrivial automorphism of a topological space X is a homeomorphism from X to itself that is not the identity. This is a topological symmetry of the space. The group of all such automorphisms is denoted Aut(X).
Chain maps, simplicial map f	K to L from a tetrahedron K to a square L. The map f takes the vertices of K to the vertices of L and induces maps on the edges and faces. This simplicial map induces a chain map on the chain complexes of K and L:  Simplicial map f: K to L from a tetrahedron K to a square L. The map f takes the vertices of K to the vertices of L and induces maps on the edges and faces. This simplicial map induces a chain map on the chain complexes of K and L. The chain map is essentially a geometric map that preserves the "combinatorial structure" of the objects, and the commutativity of the diagram reflects this preservation.
Chain maps, maps on singular chains, example of chain maps takes every singular simplex (a continuous map from a standard simplex into X) to a point, which is a degenerate singular simplex in Y	A continuous map f: X to Y between two topological spaces induces a chain map f∗​: S(X)  to S(Y) between their singular chain complexes. This chain map is constructed by applying f to the singular simplices in X. Imagine a continuous map that deforms a sphere X into a point Y. This map takes every singular simplex (a continuous map from a standard simplex into X) to a point, which is a degenerate singular simplex in Y. The chain map is the "point-wise" action of the continuous map on all the "triangulations" of the spaces, preserving their topological properties like "connectedness" or "holes."
Chain maps, group cohomology and bar complexes	in group cohomology, a chain map is a map between the homogeneous bar complexes of two groups (or of a group and its subgroup). The bar complex is a specific type of free resolution. Visual intuition: The bar complex of a group can be thought of as a structured way to "disassemble" the group into its fundamental pieces. A map between groups induces a chain map that "disassembles" the group homomorphism into a sequence of compatible maps on these pieces.
Chain maps, relative chain map in relative homology on these complexes is a map that respects this "modding out" process. It's a map that "ignores" the interior of the subspaces and focuses on the relationship between the boundaries	In relative homology, a chain map is a map between the relative chain complexes of two pairs of spaces (X,A) and (Y,B), where A and B are subspaces of X and Y respectively. Visual intuition: A relative chain complex is a way to study the homology of a space by "modding out" a subspace. A chain map on these complexes is a map that respects this "modding out" process. It's a map that "ignores" the interior of the subspaces and focuses on the relationship between the boundaries.
Injective, subring embedding of matrices visual intuition	An injective ring homomorphism is a way to embed one ring as a subring of another without any loss of information. Imagine a ring of 2×2 matrices. An injective map could embed this ring into a ring of 3×3 matrices by adding a row and a column of zeros and a single one at the bottom right.
Injective, representations, visual example of cyclic group of order two acting on a line to be perfectly embedded into a plane	An injective representation of a group G is an injective module over the group algebra kG. An injective representation is a space of symmetries that can perfectly contain any smaller space of symmetries without restriction. For example, if we have a group C2​ (the cyclic group of order 2) acting on a line, an injective representation is a larger space (like the plane) where this action can be perfectly embedded.
Injective, actions on a sphere with no redundancy, definition of injective actions	A group action on a space is injective if different group elements act differently on the space. The group's action is perfectly faithful. Each group element corresponds to a unique transformation, and there's no redundancy. For example, the action of the group of rotations on the sphere is injective.
Projective resolution, periodic projective resolution multiplication by 1 that approximates Z from the left	projective resolution of a module M is an exact sequence of projective modules P2 to P1 to M to - from the left that "approximates" M from the left. Consider Z_2 acting on module Z by multiplication by 1, trivial representation has periodic projective resolution Z[Z_2] to Z[Z_2] to Z to 0 where Z[Z_2] is a group ring.
Injective resolution, approximates module M from the right, example approximate to embed it into larger modules from Z to Q to Q/Z	injective resolution of the Z-module Z is 0 to Z to Q to Q/Z to 0, where Q is the rational numbers and Q/Z are the rationals mod 1. The module Q is injective and divisible, capable of "absorbing" any homomorphism from a submodule of another module. Q/Z is also injective. This resolution visualizes how Z can be embedded into a sequence of larger, "nicer" modules that capture its structure without losing information.
Resolution, minimal resolution is free resolution of minimal rank using example of poly ring k[x,y] / (x^2, xy, y^2)	In the ring k[x,y]/(x2,xy,y2), a minimal resolution of the module k is given by from k[x,y]^3 to k[x,y]^2 to k[x,y] to k to 0. The minimal resolution is the most compact and efficient "architectural blueprint" for a module, using the fewest possible free modules to describe its structure.
Resolution, by means of simplicies onto a circle	topological space of a circle can be resolved by a sequence of simplicial complexes, where the first is a single loop, the next is a 2-simplex with an edge glued to it, and so on. This provides a way to approximate a curved complex surface with flat triangles, making it easier to compute its properties.
Classifying space, topological monoid of n by n matrices by Grassmannian	monoid of n×n matrices, the classifying space is the Grassmannian manifold of n-planes in an infinite-dimensional space. The geometric properties of the Grassmannian are a reflection of the algebraic properties of the matrix monoid.
Classifying space, cohomology group H^2(X, G) classifying principal G-bundles, or gerbes	cohomology group H2(X,G) can be used to classify principal G-bundles, which are also known as gerbes. A gerbe is a "twisted" object. The classifying stack of a group G is a geometric object that captures all the possible "twists" for G-bundles, which is a geometric manifestation of the second cohomology group.
Paradox of ungrounded confidence, flexibility due to arrogance	Confidence that come from certain events, such as ... winning a competition can one day collapse, ... but the ungrounded confidence that I can do anything is good for having flexibility. It implies that groundless confidence, which does not depend on logic can help moving forward and change your existing goals when faced with difficulties or unfamiliar situations.
Overrated willpower, tunnel vision failure mode	I  found his remarks on doing anything at all costs being a failure mode that leads to very bad tunnel vision to be very interesting. This includes understanding something at all costs being a bad failure mode. He found that motivation and willpower are vastly overrated and made you a smaller version of yourself, and that is a dangerous failure mode to operate in.
Overrated willpower, not understanding and natural curiosity for understanding	This also seems to mirror Scholze's remarks on doing what is best for your and for your circumstances, and being honest with yourself. This is similar to Dustin Clausen's refusal to write things up and doing exercises, when understanding or even not understanding is what keeps me going.
Overrated willpower, working with your situation	(1) do what is works for you; (2) motivation and willpower shrinks your ambition; (3) humility in confident honest arrogance; (4) be confident and motivated in not understanding, seek understanding when it works for you.
Working with your brain, Serge Lang's notebooks	another thing I noticed is the popularity of Serge Lang's math books. Lang's algebra had me fairly convinced that the is writing for himself, and somehow this became rather useful for mathematicians as well: </i>
Rubber ducking, companionship increases stamina	this term I first came across from Daniel Litt, basically, being able to have someone (or in this case if it is an AI, something) to talk to can increase your stamina when you are facing hardship. This is not a difficult notion to extend from having imaginary friends because you are lonely.
Plancherel's theorem, the space of square-integrable functions L2(R) as a Hilbert space. The Fourier transform acts as a rotation or a rigid transformation within this space. Just as a physical rotation preserves the length of a vector, the Fourier transform preserves the "length" or norm of a function. For a function like the Gaussian f(x)=exp(−x2/2), its Fourier transform is also a Gaussian, f^​(ξ)=\root(2π​)exp(−ξ^2/2). The Plancherel theorem says that the integral of |f(x)|^2 over the real line is equal to the integral of |f^​(ξ)|2 over the real line. The shapes of the functions change, but their "total energy" remains the same	The Plancherel theorem, in the context of harmonic analysis on a locally compact abelian group G, states that the Fourier transform is a unitary operator from L2(G) to L2(G^), where G^ is the dual group of continuous characters. This means the Fourier transform preserves the L2-norm.
Plancherel's theorem, a "signal" in the time domain, represented by a function f(t) in L2(R). Its energy is given by the integral of |f(t)|^2 over support being the real line dt. The Plancherel theorem says that this total energy is exactly the same as the total energy of the signal in the frequency domain, given by |f(omega)|^2 over support being the real line domega. For a simple square pulse function, its Fourier transform is a sinc function. The total area under the squared magnitude of the pulse is equal to the total area under the squared magnitude of the sinc function	
Plancherel's identity, operator P = −i d/dx​ acts on functions. Its eigenfunctions are exp(iξx) with eigenvalues ξ. These are not in L2, but the Plancherel theorem shows that the Fourier transform decomposes any L^2 function into a continuous "sum" of these eigenfunctions. The Plancherel identity norm of f in frequency square is equal to norm of f in dual space sqquared is an expression of this diagonalization, where the norm on the original space is a sum of norms of components (like an inner product), and the norm on the transformed space is the integral of the squared magnitudes of the eigenvalues, which are the components of the diagonalized operator	In the context of the spectral theory of the differential operator P=−i d/dx​, which has a continuous spectrum, the Plancherel theorem provides the spectral decomposition of this operator. It says that the unitary map (the Fourier transform) diagonalizes P, transforming it into a multiplication operator by the dual variable f on L^2(R).
Plancherel's theorem, a particle state can be described by its position wave function ψ(x), where wave function^2 is the probability density of finding the particle at position x. The total probability is 1, so integral of wave function suqared is 1=1. The Plancherel theorem ensures that the corresponding momentum wave function ϕ(p), which is the Fourier transform of ψ(x), also has a total probability of 1. It's a statement that the "total probability" of the particle being somewhere is invariant whether we measure it in position space or momentum space	In quantum mechanics, the Plancherel theorem states that the position (time) space wave function ψ(x) and the momentum (frequency) space wave function ϕ(p) contain the same information and are related by the Fourier transform, which is a unitary transformation. The probability of finding a particle in a certain position range is conserved under this transformation to the probability of finding it in a certain momentum range.
Plancherel's theorem, blob of heat on an infinite metal plate. The heat distribution u(x,t) at any time t is a function in L2(Rn). The Plancherel theorem guarantees that the total "heat energy," represented by the norm u(*, t)||^2​, can be computed equivalently by integrating the squared magnitude of its Fourier transform, ||u^(⋅,t)||^2​. This is fundamental to showing that the L2 norm of the solution decays over time, as the heat diffuses. The total energy in the system is decreasing, which is easier to see in the frequency domain	In the context of solving PDEs like the heat equation ut​=Δu, the Plancherel theorem is crucial for using Fourier analysis. It guarantees that the Fourier transform is a tool that preserves the "energy" or L2 norm of the solution as we move from the spatial domain to the frequency domain. This allows us to prove stability and existence results for solutions.
Plancherel's theorem, PDF f_X ​(x) tells us how the probability of an outcome is distributed. The Plancherel theorem relates this to the "spread" of the characteristic function ϕX​(t) in the frequency domain. For a normal distribution, both the PDF and characteristic function are Gaussians. The theorem says the total squared area of the PDF is proportional to the total squared area of the characteristic function. This is a powerful identity that relates the "concentration" of a distribution in the space of outcomes to its "concentration" in the frequency domain	In probability, the Plancherel theorem is a version of Parseval's theorem for continuous random variables. It relates the expected value of a function of a random variable to the expected value of its Fourier transform. For a continuous random variable X with probability density function (PDF) f_X​(x), the characteristic function is ϕ_f​(t)=E[exp[ifX]]. The Plancherel theorem sttates the integral of the norm of the characteristic function ^2 / 2pi over frequency is the integral of f_X(x)^2 dx over outcomes.
Plancherel's theorem, analysis uses the Fourier transform to study a function's "behavior" at a point and in a direction (the "microlocal" viewpoint). The Plancherel theorem is the guarantee that this transform is well-behaved and preserves energy. For example, consider a function that is localized to a small region. Its Fourier transform will be broad. The Plancherel theorem guarantees that the total "area" under the squared magnitude of the function is the same as the total "area" under the squared magnitude of its transform. The energy is conserved, it's just spread out	In microlocal analysis, which studies functions and distributions locally in both position and momentum space, the Plancherel theorem serves as the foundational pillar for the theory. It's the statement that the Fourier transform is a unitary map, which is crucial for defining and analyzing pseudodifferential operators, which are built upon Fourier analysis.
Plancherel's theorem, he real line R with Lebesgue measure, which assigns a "size" to sets based on their length. The Plancherel theorem says that the Fourier transform maps this measure space to another measure space (the dual space R with Lebesgue measure), such that the total "volume" or "size" of any square-integrable function is conserved. The total volume of a "blob" of probability on the real line is the same as the total volume of its transformed "blob" in the frequency domain. The measures are normalized so this holds	From the perspective of measure theory, the Plancherel theorem can be stated as a relationship between Lebesgue measure on a locally compact abelian group G and Haar measure on its dual group G^. It asserts that the Fourier transform is an isometry between the Hilbert spaces L2(G,μG​) and L2(G^,μG^​), where μG​ and μG^​ are appropriately normalized Haar measures.
Plancherel's theorem, Hilbert space, the inner product is a way to measure the "angle" and "length" of vectors. The Plancherel theorem says the Fourier transform is a "rigid motion" of the entire function space. It doesn't stretch or compress functions; it just changes their representation. For two functions f and g, the Plancherel theorem says their "overlap" (inner product) is the same as the "overlap" of their Fourier transforms	Plancherel's theorem is a statement about the properties of the Fourier transform as a linear operator. It asserts that the Fourier transform F:L2(R^n)→L2(R^n) is a unitary operator, which means it's an isomorphism that preserves the inner product. That is, inner product of fg in L^2 is the same as inner produt of duals f^ g^ in L^2 for all f and g in L^2(R^n)
Plancherel's theorem, function u0​ and let a semigroup act on it, such as heat diffusion. The Plancherel theorem allows us to transform the complex operation of diffusion into a simple multiplication by an exponential decay factor in the frequency domain. The total energy of the heat blob, ||u(t)||_norm2​, can be calculated by integrating the squared magnitude of its Fourier transform, which we know decays exponentially. The Plancherel theorem is the bridge that allows us to view the decay of total energy in the spatial domain as a simple decay in the frequency domain	Plancherel's theorem is crucial for the spectral decomposition of semigroups of operators. For example, in the context of the heat equation, the solution operator T(t) u)0​=exp(tΔ)u_0​ forms a contraction semigroup. Plancherel's theorem allows us to analyze this semigroup in the frequency domain, where it becomes a simple multiplication operator, exp(−t∣ξ∣^2), which makes the analysis of its behavior much simpler.
Plancherel's theorem, a compact manifold like a sphere. The eigenfunctions of the Laplace-Beltrami operator are the spherical harmonics. The Plancherel theorem for this case states that any function on the sphere can be decomposed into a sum of these spherical harmonics, and the total "energy" of the function is the sum of the energies of its harmonic components. This is a discrete version of the Plancherel theorem, where the "frequency space" is the discrete set of eigenvalues of the Laplacian	In global analysis, Plancherel's theorem is a foundational tool for analyzing functions on manifolds. It is generalized to the study of the spectrum of differential operators on Riemannian manifolds, such as the Laplace-Beltrami operator. It's a statement about the spectral decomposition of these operators, which is a key part of the theory.
Plancherel's theorem, a convex set K. The Fourier transform of its indicator function is related to the support function of the set. The Plancherel theorem says that the integral of the squared magnitude of the indicator function, which is the volume of the set, is related to the integral of the squared magnitude of its Fourier transform. This provides a link between the geometry of the set in the spatial domain and the "shape" of its Fourier transform in the frequency domain	The Plancherel theorem, via the Brunn-Minkowski inequality, can be seen as a statement about the relationship between the volume of a convex body and the volume of its polar body. While not a direct application, the Plancherel theorem relates the size of a function to the size of its Fourier transform, and there are analogous results in convex geometry.
Vector bundle, vector space fibres	a vector bundle is a specific type of fiber bundle where the fibres are vector spaces (my intuition for bundles are similar to that of basis, for vectors you glue [take colimits] vectors together, for topological spaces you glue open neighbourhoods, for schemes you glue local rings [literally look like rings for me], for infinity categories or stacky stuff you glue group(oids)). It consists of a total space E, a base space X, and a projection map p: E to X
Vector bundle, locally trivial, visual intuition is open subset is Cartesian producted with a copy of the R^n (example for visual imagination is R^1)	for every point x in the base space X, there is a neighborhood U and an isomorphism fibres over U to be isomorphic the cartesian product of U and R^n, which is a local trivialization.
Vector bundle, transition functions	local trivializations on overlapping neighborhoods are related by transition functions, which are continuous maps from the overlap to the general linear group GLn(R)
Vector bundle, continuous sections	continuous section of a vector bundle is a continuous map s: X to E such that p * s is the identity map on X. The set of all continuous sections forms a module over the ring of continuous functions on X.
Vector bundle, rank	rank of a vector bundle is the dimension n of the vector space fibers. A rank 1 bundle is a line bundle. Recall that rank is output of linear map is dimensional 1.
Vector bundle, trivial	trivial if it is globally isomorphic to a product space X × R^n. This is the simplest type of vector bundle, and its continuous sections correspond to a free module.
Vector bundle, subbundle	sub-space of a vector bundle that is itself a vector bundle. Its continuous sections form a submodule.
Vector bundle, pullback bundle	pullback of a vector bundle along a map f: Y → X is a new vector bundle over the space Y, which gives a way to "transport" the bundle's structure.
Vector bundle, Whitney sum	two vector bundles E1​ and E2​ over the same base space X is a new vector bundle E1​ ⊕ E2​ whose fibers are the direct sums of the fibers of the original bundles.
Vector bundle, classification	Vector bundles of rank n on a space X are classified by homotopy classes of maps from X to the Grassmannian manifold G_n​(R^∞).
Vector bundle, locally free sheaf	algebraic analog of a vector bundle is a locally free sheaf. A sheaf of modules is locally free if every point in the scheme has a neighborhood where the sheaf is isomorphic to a free sheaf of finite rank.
Vector bundle, Serre-Swan	compact topological space X, the category of continuous vector bundles on X is equivalent to the category of finitely generated projective modules over the ring of continuous functions C(X).
Vector bundle, projective module	Swan's theorem provides an algebraic definition of a vector bundle: it's a finitely generated projective module. This allows us to use the tools of commutative algebra to study geometric objects.
Vector bundle, flat modules	vector bundle corresponds to a finitely presented flat module. This is a weaker condition than projective, and it is the correct algebraic counterpart for schemes that are not regular.
Vector bundle, on schemes	vector bundle over a scheme is defined as a locally free sheaf of modules of constant finite rank. This directly translates the topological definition into the language of algebraic geometry.
Vector bundle, perfect complex	chain complex of modules that is locally quasi-isomorphic to a finite complex of free modules. This object captures the "homotopical" nature of vector bundles.
Vector bundle, line bundle	vector bundle of rank 1 is a line bundle. In algebraic geometry, these correspond to invertible sheaves, which are key to studying divisors and rational maps.
Vector bundle, torsor	vector bundle is a torsor under a group scheme. For a line bundle, this is an algebraic version of a principal bundle.
Vector bundle, algebraic	algebraic vector bundle on a scheme is a coherent sheaf that is locally free.
Vector bundle, Grothendieck group	set of isomorphism classes of vector bundles over a topological space X forms an abelian group called the topological K-theory group K_0​(X) under the Whitney sum operation. The algebraic counterpart is the Grothendieck group K_0​(R) of a ring, which is generated by finitely generated projective modules.
Vector bundle, torsors in algebraic geometry, vector bundle as a scheme, vectors floating above circle and seen as torsors, vectors can be reached by other linear transformations	vector bundle is a scheme E over a base scheme X together with a map π: E → X such that for any point x ∈ X, the fiber π−1(x) is a vector space, and locally, E is isomorphic to a product of X and a vector space. A torsor is a principal homogeneous space for a group scheme G. A vector bundle can be viewed as a torsor for the general linear group scheme, GLn​.  Imagine a base space (e.g., a circle) and over each point of the circle, a vector space "floating" above it. This forms a vector bundle. This bundle can be seen as a torsor for the group of linear transformations of the fiber. This means that if we are at a point on the base circle and we pick a vector in the fiber, any other vector in the same fiber can be reached by a unique linear transformation from the general linear group.
Vector bundles, via transition functions, curved surface is base schemes, each vector bundle is a single product space or a trivial bundle, transition functions give gluing	A vector bundle can be defined by an open cover of the base space and a set of transition functions (automorphisms of the fiber) on the overlaps. These functions satisfy the cocycle condition. Imagine a curved surface (the base scheme) covered by flat patches. Over each patch, the vector bundle is a simple product space (a trivial bundle). The transition functions are the "instructions" for how to glue the patches together. This gluing process is a group action, specifically by GLn​.
Fibration, cylinder E=S1× cross mapped to a circle B=S1 by the projection p(x,t)=x. The fibers are the vertical line segments {x} cross I above each point x on the circle. If you have a path on the circle (the base) and a starting point on the cylinder above it, you can "lift" the path smoothly up to the cylinder. This ability to lift any path from the base to a unique path in the total space makes it a fibration	fibration is a continuous map p:E to B between topological spaces, satisfying the homotopy lifting property. This means that for any space X, any map f:X to E, and any homotopy H: X cross I to B of the base map p * f, there is a unique homotopy lift H~: X cross I→E such that p * H~ is equal to H and H~(x,0)=f(x). Intuitively, a fibration is a map that "projects" a more complex space E onto a simpler space B in a way that allows us to lift paths from the base to the total space.
Fibration, a family of elliptic curves over the projective line P1. Each point of the base space P1 corresponds to an elliptic curve, which is the fiber. A map from a curve C to our family of elliptic curves on the base can be "lifted" to a map from C to the total space. This means that if we continuously move a point on the base, the corresponding elliptic curve (the fiber) will also vary smoothly	a projective morphism of schemes f: X to Y is a fibration in a geometric sense. It is a scheme-theoretic analogue of a fibration in topology, where the fibers are projective varieties. This implies that for a suitable base space, the fibers over its points are all "the same," and we can "move" a fiber over one point to a fiber over another point.
Fibration, the map from the 2-sphere S2 to the projective plane RP^2 that identifies antipodal points. The fiber over a point in RP^2 consists of two points. This map is not a fibration in the strict sense, but it is a quasi-fibration. We can't lift every path uniquely, but it still induces a long exact sequence of homotopy groups, which tells us about the structure of the spaces	a quasi-fibration is a continuous map p : E to B with the property that the induced map on homotopy groups P_n​(p): P_n​(E, F_b​) to P_n​(B,b) is an isomorphism for all n more than or equal to 0, where F_b​ is the fibre over the base point b. This is a weaker condition than the homotopy lifting property but is often sufficient for constructing long exact sequences of homotopy groups.
Fibration, the ring R as a space of "algebraic objects." We want to "zoom in" on a specific prime ideal P. The localization R_P​ is a "local neighborhood" around P. The map from R to R_P​ is like a projection. The "fibers" are the sets of all elements in R that are not in P. This process "lifts" a global property (the ring R) to a local one (R+P​) in a way that preserves all information about the ideal P	the process of localization of a non-commutative ring R at a prime ideal P can be viewed as a fibration. The map from the ring R to the localized ring R_P​ is an algebraic fibration. The "fibers" are the rings of endomorphisms of modules, and the fibration is a way to understand the module as a "sheaf" over the spectrum of the ring.
Fibration, the module M as a central object. We build a tower of projective modules P0​,P1​,P2​,... that "cover" it. The map from the tower to the module is a projection. The "fibers" are the submodules that are "killed" at each step. This process allows us to lift properties from the module to its resolution, and the properties of the fibration ensure that this is a well-behaved process. For example, to find the Ext groups, we use a projective resolution, which is a fibration in this sense	A resolution of a module M by projective modules, ... to P1​ to P0​ to M to 0, can be seen as a fibration. The map from the chain complex of projective modules to the module M is a fibration in the context of chain complexes. The "fibers" are the kernels of the maps in the complex.
Fibration, a flow on a torus T^2 = S^1 × S^1. We can project this flow onto one of the circles, say S1. The fiber over each point of the base circle is the other circle. The map is a fibration. A path on the torus can be projected onto a path on the base circle, and the fibration property means we can lift a path from the base to a path on the torus. This allows us to understand the complex dynamics on the torus by studying the simpler dynamics on the base circle and the fiber	for a dynamical system, a fiber bundle is a manifold E with a projection map p: E to B such that for every point x in the base space B, there is a neighborhood U of x and a homeomorphism from p−1(U) to U × F, where F is the fiber. This describes how a dynamical system (like a flow on a manifold) can be decomposed into a base flow and a flow on the fiber.
Fibration, a map from the spectrum of the ring of integers of a number field K, Spec(O_K​), to the spectrum of the integers, Spec(Z). The fibers over prime ideals in Z are the prime ideals in OK​ that lie above them. This is an étale fibration. The fibration property means that locally, the map looks like a product. For example, the map from Spec(Z[i]) to Spec(Z) is an étale fibration over primes p congruent 1(mod4). The fiber over such a prime p consists of two points, corresponding to the two prime ideals above it	a étale morphism of schemes f: X to Y is a flat, unramified morphism of finite type. It is a fibration in the context of schemes, where the fibers are finite sets. The map is a local isomorphism for the étale topology.
Fibration, a sphere S2. The set of all tangent vectors of length 1 is a manifold called the tangent bundle T1S2. There is a map from T1S2 to S2 that sends a vector to the point where it is attached. The fiber over each point is a circle S1. This is a principal S1-bundle. The fibration property says that we can "lift" a path on the sphere to a path of unit tangent vectors. The group action allows us to "rotate" the fibers	A principal G-bundle is a fibration p:E to B with a right action of a topological group G on the total space E such that the map E × G to E×B given by (e,g) mapped to (eg,p(e)) is a homeomorphism, and the fibers are homeomorphic to the group G.
Fibration, is like a projection, where we "collapse" a space down to a simpler one. A cofibration is like an inclusion, where we "build" a larger space by including a smaller one. For example, the map from the cylinder to the circle is a fibration. The map from the boundary of a disk to the disk itself is a cofibration. They are "opposite" but related concepts	Eckmann-Hilton duality is a concept that relates products and coproducts, and it can be applied to fibrations and cofibrations. A fibration is a map that has the homotopy lifting property, while a cofibration is a map that has the homotopy extension property. These two concepts are dual.
Fibration, imagine  the number field Q as a line. The "base" is the set of all prime numbers and the point at infinity. The fiber over each prime p is the field of p-adic numbers Qp​, and the fiber over infinity is the real numbers R. The fibration property means we can "lift" a path from the base to the arithmetic curve. This allows us to study the number field by looking at its local behavior	In Arakelov geometry, a number field is treated as a 1-dimensional arithmetic curve. This curve can be thought of as a fibration over a "base" that is the set of all places of the field. The fibers are the completions of the field at each place.
Fibration, imagine a functor F that maps modules to other modules. We can think of this as a projection. A derived functor Extn is a way to "lift" this projection to a higher dimension. The fibration property means that we can lift a chain map to a homotopy class of chain maps. This provides a way to compute the "failure" of an exact sequence to remain exact after applying a functor	A derived functor, like Ext or Tor, is a fibration of functors. The derived category is a categorical way to deal with resolutions, which are fibrations. The maps between objects in the derived category are "homotopy classes of chain maps."
Fibration, consider a family of conics in the plane. We can parameterize this family by a base space, say the real line. The fiber over each point is a conic. For example, the fiber over a point t could be the conic x^2 + y^2 = t. As we move the parameter t, the conic changes. The fibration property means that this change is smooth and well-behaved	A flat morphism f: X to Y is a family of varieties. The fibers over the points of the base Y are the varieties of the family. A flat morphism is a fibration in the sense that the fibers are all "the same" in some sense, and they vary smoothly with the base.
Fibration, a quiver as a directed graph. A representation is a set of vector spaces attached to the vertices and linear maps attached to the arrows. A map from one representation to another is a collection of maps between the corresponding vector spaces. The fibration property means that we can "lift" a map on the quiver to a map on the vector spaces	A quiver representation is a collection of vector spaces and linear maps between them. A map between two quiver representations can be seen as a fibration. The fibers are the vector spaces that are "killed" by the map.
Fibration, a map from a number field to a smaller number field. The map on the spectra is a fibration. The fibers are the prime ideals that lie above a given prime. This map induces a fibration of fundamental groups. The fibration property means we can lift a "path of prime ideals" in the base to a "path of prime ideals" in the total space	The fundamental group of a scheme is a pro-finite group. A map of schemes can induce a fibration of fundamental groups. The fibration property means we can lift a path from the base group to the total group.
Cofibration, imagine a hollow sphere A=S2 and a solid ball X=D3. The inclusion map i	S2 to D3 is a cofibration. If we have a map from the ball to another space, and we start to deform the sphere (the boundary of the ball), we can always deform the whole ball in a consistent way. The boundary is "stuck" to the ball in a way that allows us to push any deformation from the boundary into the interior. This is the dual concept to a fibration, which allows us to "lift" homotopies from a base space: A cofibration is a continuous map i: Ato X between topological spaces that satisfies the homotopy extension property. This means that for any space Y, any map f: X to Y, and any homotopy H:A cross I to Y of the restricted map f∣A​, there exists a homotopy lift H~:X cross I to Y that extends H. In other words, any homotopy defined on the subspace A can be "extended" to a homotopy on the entire space X.
Cofibration, a space A and two maps, f	A to B and g: A to C. The pushout of this diagram is a space P that "glues" B and C together along the image of A. If the map A to B is a cofibration, the pushout is well-behaved. For example, if we glue two disks together along a circle, the resulting space is a sphere. The inclusion of the circle into the disk is a cofibration, and this property ensures that the gluing is well-behaved:  The homotopy extension property can be formulated in terms of a pushout square. A cofibration is a map A to X such that a specific pushout square is a pullback square.
Cofibration, the inclusion of the origin in the affine plane. This is a closed immersion. The map from Spec(k[x,y]/(x,y)) to Spec(k[x,y]) is a closed immersion. This is a geometric "cofibration," where a smaller space is "stuck" inside a larger one in a very rigid way. The embedding is a cofibration because any map from the origin to a scheme can be extended to the entire plane	A closed immersion of schemes f:X→Y is a morphism that is a homeomorphism onto its image, and the induced map on sheaves of rings is a surjective map. A closed immersion is a "cofibration" in the geometric sense, as it embeds one scheme as a closed subscheme of another.
Cofibration, a free module F and a submodule N. The inclusion of N into F is a cofibration. A free module is a "cofibrant" object, and this is a key property in homological algebra. It means that the module can be "built" from a free module	In the category of modules over a non-commutative ring, a cofibration is a module homomorphism that is an injective map with a projective cokernel. This is a "dual" concept to a fibration, which is a surjective map with an injective kernel.
Cofibration, consider field F_p​ as a single point. The field F_{p^n}​ is a larger field with more points. The inclusion map is a cofibration. This is a way of "embedding" a smaller algebraic object into a larger one. This is a fundamental construction in arithmetic geometry	In the context of number theory, a cofibration can be seen through the lens of a Frobenius map. The inclusion of a finite field into a larger finite field can be seen as a cofibration.
Cofibration, the group algebra F_p ​_Cp​. The simple module F_p​ is not projective. However, we can find a projective module P and a map from P to F_p​. The kernel of this map is a submodule. The inclusion of the kernel into the projective module is a "cofibration." This is a way of "building" a simple module from a projective one	In the category of modules over a group algebra, a cofibration is a module homomorphism that is an injective map with a projective cokernel. This is a key property for understanding the structure of modules and their relationships.
Cofibration, building a 2-sphere by starting with a point, attaching two lines (a "figure eight"), and then attaching a disk. At each step, the inclusion of the subcomplex is a cofibration. This is a way of "building" a complex space from simpler pieces in a well-behaved way. The cofibration property guarantees that the attachment is "non-trivial."	A CW complex is a space built up by attaching cells of increasing dimension. The inclusion of a subcomplex into a CW complex is a cofibration. This is a powerful property that makes CW complexes well-behaved in homotopy theory.
Cofibration, formal scheme is a "germ" of a scheme along a closed subscheme. The inclusion of the formal scheme of the origin in the formal scheme of the affine line is a cofibration. This is a way of "embedding" a local object into a larger one	A closed immersion of formal schemes is a cofibration in the category of formal schemes. This is a way of embedding a formal scheme as a closed subscheme of another.
Cofibration, a ring of integers Z is a principal ideal domain, so every ideal is free, and thus projective. The inclusion of an ideal, say 2Z, into Z is a cofibration. This is a way of "embedding" a module into a larger one in a well-behaved way	A ring R is left hereditary if every left ideal is a projective module. This means that every inclusion of a left ideal into the ring is a cofibration. This is a very strong property that is a key to understanding the homological properties of the ring.
Cofibration, inclusion of a compact manifold into a larger one is a proper morphism. For example, the inclusion of a sphere into R3 is a proper morphism. This is a way of "embedding" a compact object into a larger one	A proper morphism of schemes is a morphism that is separated, of finite type, and universally closed. A proper morphism is a "cofibration" in a strong sense. It is a map that is a closed embedding.
Cofibration, the ring of integers Z. The inclusion of Z into the ring of rational numbers Q is a cofibration. This is a way of "embedding" a ring into a field	The inclusion of a ring into its localization at a prime ideal is a cofibration in a sense. The localization process is a way of "embedding" a ring into a larger one.
CW complex, combinatorical construction for computation of homology and cohomology by induction	combinatorics mean induction, a CW complex is a topological space with a discrete set of 0-cells, attaching n-dimensional disks with continuous maps from the circle S^{n-1} to X^{n-1} where (n-1) skeleton X^{n-1}. The space is the union of all skeleta with the weak topology, a subset A in X is closed if intersections of A with X^n is closed in all X^n for all n.
Chain complexes, algebra to capture modules with boundary like operators whose successive applications vanish	the definition is based on the principle that the boundary of a boundary is empty, a chain complex over a ring R is a sequence of R-modules connected by homomorphisms C_n to C_{n-1} such that the product of two adjacenet homomorphisms are zero. The homology is the quotient of the kernel ker(d_n) quotiented out by the image at d_{n+1}.
Trace of a chain complex, alternating due to homology maps, generalising usual matrix trace	the trace of a chain complex is the alternating sum (comes from definition of homology) of the ordinary trace of chain maps on each degree.
Lefschetz's fixed point principle, help traces encode information about fixed point	The Lefschetz number is defined as the trace of chain maps in homology with rational coefficients, the data input is a continuous map of a CW complex. The fixed point theorem states that if the Lefschetz number is nonzero, then the continuous map has a fixed point.
Graph and diagonal of a finite CW complex, intersection theory of graph and diagonal corresponds to fixed points	this is the primary insight of why one constructs the graph. The intersection number of the graph and diagonal of the CW complex gives the Lefschetz number. Diagonal means fixed point. The graph of a space is simply pairs of (x, f(x)) such that x is in X, the graph is contained in the cartesian product X * Y, f(x) is in Y. The diagonal is the case where f(x) = x, so it is in the cartesian product X * X.
Ontology, reinvention	example, groups, how did the original person reinvent it (permutation group of roots), what is the slickest modern reinvention of this (group as one object groupoid)
Ontology, Bongard problem	find commonality of six images. Problem is to figure out what the problem is. Look at reality repeatedly, less directly. Lower description level, pattern pops out. Model of Science.
Ontology, nebulosity	fluid character of meanings. Eternalism is denial of nebulosity. Corollary: eternal ordering principle.
Ontology, lens control	lens distort to make ugly or beautiful.
Ontology, ontological splitting	distinguish properties to rebuild it. Suitable generalities for suitable purposes. Negative thinking.
Ontology, right definitions	mathematicians put work in making the right definitions or the right ontology. See history of mathematics. Find bad definitions and alternative ontologies.
Ontology, NEDERA and Gendlin focusing	use NEDERA to get labels once you experience the ontology of the pain. In Gendlin focusing, this is felt understanding, or felt sense. Felt sense is physical, felt understanding is unconscious understanding of detail.
Ontology, (IMPORTANT) set of all things tracked	set of all things tracked by you consciously or unconsciously. Goal: increase set by reading more, mostly consists of things you are not tracking consciously, only subconsciously and things you do not have words for. Building skill is learning what to track or ontology building. Teaching is setting up of experiences that let students track the proper ontology of a skill.
Ontology, ontology building	as relation sense what main objects are, how they relate to each other, and make it actionable. Build it yourself.
Ontology, avoid ontological cons	sidestepping issues in lack of understanding or failure to split, example 0.9999 = 1, lots of ontological gaslighting, explicit splitting needs to be tracked or knowledge to help track these subconscious issues helps.
Ontology, remodelling	reconfiguration of individuation criteria, categories, properties, and relationships, advanced meta-rational activity. Ideally, we build up conceptual prerequisites before discussion.
Ontology, three outcomes	(1) disappears when nothing in it, (2) stubbornly nebulous for formality since it is heuristically useful, third, (3) new formal proper definition. Spectrum also, focus on second since it is nearly useless due to imprecision.
Ontology, against the correct answer	fails in math, fails in classifying planets, meta rationalities means all categories (or definitions) as inherently purpose laden. Therefore, what does this definition do, why is this definition is more important. Example, why Poincare define homology as relations with linear combinations. This denies the existence of a general theory of truths.
Elliptic curves, smooth cubics with a group law	the most interesting part is that it has a group law in it, in the Weierstrass form it is a curve of the form y^2 = x^3 + ax + b.
Torsion points, finite-order elements of the group	points such that n * point = origin for positive integer n. This is classified over Q by Mazur's theorem. The fact that torsion points exist is interesting.
j-invariant, classifies isomorphic elliptic curves over C	it is given by this strange relation j(elliptic curve) = 1728 * (4a^3)/(4a^3 + 27b^3), This is already the easiest example of something moonshine like going on. Two elliptic curves over C are isomorphic if and only if they have the same j-invariant.
Rational points, solutions in a given field	E(K) is the set of all points (x,y) in K^2 such that the points are on the elliptic curve union the origin. This forms a finitely generated abelian group by Mordell's theorem.
Origin, point at infinity when you think what is unaffected by the group law in the chord and tangent process	define the identity of the group law by the point at infinity if you think about the chord and tangent process.
Isogeny, nontrivial morphism preserving group structure	a surjective morphism f from two elliptic curves with finite kernel respective the abelian group law.
L-function, turn point counts into product formula	consider ellipctive curve over the field of rationals, then the L-function L(E,s) is the product over prime p prod_p (1 - a_p p^{-s} + p^{1 - 2s})^{-1}, where a_p = p + 1 - rank(E(F_p)) over finite field F_p. This is because we used a Dirichlet series to get the L-function.
Yoneda's lemma, probe function perspective	One perspective one can take on the Yoneda lemma is to look at probes. I think Vakil made this analogy where you basically understand all morphisms of the form Hom(-, M) when you want to study object M, and - can represent any object related to object M in the category. The particle collider (assuming complete knowledge of all particles. This is akin how Cayley's theorem invoking the closure of groups) can test an unknown particle with every other particle. If you know this result, then you basically fully determine the particle. This set of morphisms (morphisms are important here since composition of morphisms are morphisms) is a representation (a representation is thought of as a functor) of the object M.
Yoneda's lemma, definition of right Kan extensions	one can take about the Yoneda lemma is to define the right Kan extension of a functor F from a category C to a category E along a functor K. We start by needing the definition of a pointwise Kan extension. The motivation if a pointwise Kan extension is to preserve representable functors. The motivation of representable functors is to have the functor of points analogy. Then, the right Kan extension is pointwise if this limit exists and is isomorphic to a morphism d in category C.
Ideals, Yoneda embedding for posets	Dedekind constructed the reals from the rationals, one embeds the rationals in its power set by defining the representative set (known as a Dedekind cut) using the least upper bound of the rationals as the Yoneda embedding on the poset of the rationals. This is an order preserving injection, you can work with these sets instead of the original rational numbers. The similar idea is to consider ideal sets where you have powers of rationals bounded by an integer, then embed the divisibility relation. For example, define the analogous Dedekind cut S_x by elements a in the integers adjoined the square root of negative 5 such that x divides a. Now take the kernel under homomorphisms from this field extension into an integral domain. One obtains ideals this way. See Qiaochu Yuan's blog post on primes and ideals.
Yoneda's lemma, category of schemes have all fibre products	here is a proof sketch from Hartshorne with two key steps. Recall that this statement is to check that the fibre product of the scheme Spec A and scheme Spec B (think of these as prime spectra) over a base scheme Spec R, where R is a commutative ring is isomorphic to the scheme of the tensor product over the ring R for commutative rings A and B. The proof follows two steps, the case of affines schemes, one can appeal to the universal property of the fibre product of schemes, and pass it through to the tensor product of rings via the algebra-geometry duality, and then use Yoneda's lemma to show that this is a unique representing object given the fibres. Next, on the level of schemes, consider at least affine covers (we did not state the nature of the covers here) of schemes X, Y, and affine scheme S, (other schemes to consider the fibre product of X and Y), then cover them the fibre products of S and S_j indexed. These are affine, the fibre product exists and unique, due to the nature of sheafification, descent, and glueing, one can construct the unique fibre product for arbitrary schemes over the base scheme Spec S.
Cayley's theorem, the Yoneda embedding	the symmetric group is the cofinal object for the indexed collection of its subgroups. Once you understand Cayley's Theorem, you understand the basic idea of the proof for the Yoneda embedding and Yoneda's lemma. Note, not trivial, requires key step. Consider underlying element of group x, mapping to left action gx. It is important to note tht groups are closed under the group law, so this is bijection, since this is a bijection on the same set. It is a permutation, so groups must be isomorphic to permutation groups (or subgroups of symmetric groups) under composition of permutations. Yoneda's lemma is similar, considering homset(b, a) mapping to natural transformations nat(hom(a, -), hom(b, -)). This must be an isomorphism, since compositions of morphisms are morphisms (we used the assumption of a locally small category here, this is large enough to only form a set). Therefore, define this as an Yoneda embedding (if on sets), and all small categories are embed into the category of functors of defined on that categories, which are represented by pre-sheaves or representable functors.
Row operations, naturality comes from Yoneda's lemma	the requirement that it must be elementary row operations, these are the natural transformations between matrices i.e. swapping two columns, multiplication by scalars, scalar multiples of one column to another are invertible since corresponding elementary matrices are invertible. An non-example includes appending a column to 1s. Applying this to identity matrix fails, then right multiplication defines different column operation, this is because this is not an elementary row operation, fails invertibility.
Functor of points, in contrast to Yoneda's lemma	classically, the functor of points, denoted  Hom(-, X), is a functor from (Affine schemes)^op to Set, sending affine scheme Y to set of scheme maps Y -> X. Therefore, a scheme is the representing object of the functor of points, the functor of points is a representable functor. The Yoneda lemma is, in contrast, weaker, consider the case where Hom(-, X), Schemes^op -> Set, where X is a scheme. The functor of points requires it sufficient to be an isomorphism to functor of points, and not necessarily the natural transformations. This functor Hom(-, X) classifies geometric objects over Y given by F. The notion is analogous to classifying space.
Isomorphisms, cardinality as a consideration in the Yoneda lemma	naturality concerns how to preserve cardinality. This is why the Yoneda lemma is a forgetful functor into the category of sets. More details can be found in Lawvere's book on Conceptual Mathematics.
Yoneda's lemma, presheaves as a generalised object	Yoneda's lemma enable this powerful interpretation of a presheaf as some form of a generalised object. Recall that a presheaf is a contravariant functor from the opposite category C^op to the category of sets. A generalised object is an object that can be probed by ordinary objects. We can consider a presheaf as something that assigns each test object U in the category C, to a set of U-points of F(U), this is not dissimilar to thinking about functionals. Each object X in the category C determines a representable presheaf (with the object X in the category C a representing object), we have h_x = Hom_C(-, X) from the opposite category C^op to the category of sets. The Yoneda's lemma guarantees that h_x and X are the same objects. This functoriality is fully faithful, distinct objects and maps in the category C remain distinct as presheaves. The next important assertion is that presheaves freely add all colimits (free cocomplete category), therefore any functor from category C to category D with category D cocomplete extends uniquely up to isomorphism a colimit preserving functor. The Yoneda lemma is a categorification of the statement that the canonical map from a set S to its free commutative monoid N(S) is injective (distinct generators remain distinct in the free object).
Field extensions (Galois theory), Yoneda extensions as left Kan extension along a Yoneda embedding	the idea is you have a smaller field in a larger field, Galois theory uses this to define field extensions. Similarly, a Yoneda extension is the left Kan extension along a Yoneda embedding.
Projective object, statement of the Yoneda lemma in terms of projective objects	the definition lends itself to a neat restatement of the Yoneda lemma, a projective object is an object for which every epimorphism and morphism there exists a lift, or Hom(P, -) preserves epimorphisms. Apply this to presheaves and Hom(h_X, -) is known as the the evaluation functor on X, this preserves epimorphisms (as a projective object) and we think about epimorphisms in a presheaf category as pointwise surjective natural transformations, the conclusion is therefore representables in the functor category are projective objects. An intuition: projective objects are the “free generators” of a category since morphisms out of them are easy to define, and they detect surjectivity. Yoneda's lemma then says that every natural transformation out of a representable is completely determined by its value on the objects. Replacing the category of sets here enable definitions of projective resolutions from representables and considerations about the derived categories.
Points of sets, clarified with the Yoneda's lemma	this is a very number theory flavoured argument when one consider the natural numbers (excluding 0, including initial object 1) as a poset, there is natural transformation from the constant functor to Hom(-, X) or 1 -> X in this clearer notation, Nat(1 -> X, !) is canonically isomorphic to hom-set of hom-sets Hom(Hom(1, X), !). Therefore, a point of set X is a map from the initial object 1 to X. This example clarifies that much of category theory rests on poset structure on the natural numbers.
Representations, an intepretation of the Yoneda's lemma in terms of the representing homset of homsets	Yoneda's lemma and representation theory, simply says that natural transformations are represented by the homset of homsets from objects to functors i.e. Nat(h_A, F) is represented by Hom(Hom(A, -), F), for object A in category C, F any functor. So natural transformations are always representable by the algebra of hom-sets under any functor from (LOCALLY SMALL) category from C to Set, locally small means set's worth of arrows locally, there is no monkey business with large cardinalities.
Yoneda's lemma, defining set level isomorphisms	Yoneda's lemma implies a composition of two morphisms between two sets of objects whose composition and inverse identify in their respective sets of objects called a isomorphism. This isomorphism is canonical and unique, and is between the value of a presheaf X at a morphism c and the collection of all morphisms (hom-set) of presheaf homomorphisms from the representable presheaf y(c) to the presheaf X. This means Hom_{Set^{C^op}}(y(c), X) is isomorphic to X(c).
Yoneda lemma, a scheme can be thought of as a geometric space, but one that is best described not by its "points" in the classical sense, but by all the possible ways to "map into it" from other simpler spaces. Imagine a scheme X as a complex, geometric object. Instead of trying to define its points directly, we describe it by its "blueprint for observation." This blueprint tells us, for any simple 'probe' space like the affine line A1, what the set of all possible maps from that probe to our scheme X looks like. The Yoneda lemma guarantees that this collection of maps from all possible probe spaces uniquely and completely defines the original scheme X. For example, the affine line A1 is fully characterized by the functor that sends a ring R to the set of elements in R, which corresponds to the set of morphisms from Spec(R) to A1	The Yoneda lemma provides the foundation for the "functor of points" perspective. A scheme X can be fully understood by the functor it represents, namely the functor Hom(_,X):Sch^op to Set, which maps a scheme T to the set of morphisms of schemes from T to X. The Yoneda lemma says that knowing the functor of points is equivalent to knowing the scheme itself.
Yoneda lemma, a module M as a vector space over a non-commutative ring R. Instead of looking at the elements of M directly, we can understand M by observing how it "interacts" with all other modules. Imagine a module M as a black box. The only way to probe this box is by sending in homomorphisms from other modules, say N_1​,N_2​,…. The set of all possible maps from a module N to M is Hom_R​(N,M). The Yoneda lemma says that the entire collection of these sets, for all possible N, gives us a complete and unique "fingerprint" of the module M. For example, the left ideal R itself (as a left R-module) is uniquely determined by the functor Hom_R​(R,−) which is just the identity functor	for a non-commutative ring R, the category of left R-modules, R-Mod, is a fundamental object of study. The Yoneda lemma applied to R-Mod states that for any left R-module M, the contravariant functor HomR​(M,_):R-Mod→Set uniquely determines M up to isomorphism.
Yoneda lemma, for an object A and an object B. We are building a new, "extended" object E that sits in the middle of a short exact sequence 0 to B to E to A to 0. We can visualize this sequence as building a composite object E by "gluing" B to A in a particular way. The Yoneda lemma provides a way to classify these different "gluing" methods. It says that the collection of all possible extensions of A by B is uniquely determined by the "maps out of A" in a higher-order sense, specifically by the functor that assigns to each module X the group Ext^1(A,X). This perspective shifts the focus from the individual object E to the entire family of all possible extensions. The Yoneda lemma is the reason we can interpret Ext^1 in this geometric way	The Yoneda lemma is crucial for defining and understanding Ext groups. The Ext group Ext^1(A,B) classifies extensions of A by B. The Yoneda lemma provides a powerful lens: Ext^1(A,B) can be interpreted as the set of isomorphism classes of exact sequences 0 to B to E to A to 0.
Yoneda lemma, imagine a topological space X as a piece of rubber. Instead of describing its points and how they're connected, we can understand it by how it "receives" other shapes. For example, we can test it by seeing how many ways a circle, a sphere, or a torus can be continuously mapped into it. The Yoneda lemma guarantees that the entire collection of these test maps, for every possible simple shape, gives us a full and complete description of our original rubber shape, up to continuous deformation. This is why we can study spaces by studying their "probes." For example, the homotopy groups of a space pi_(X) are defined as maps from the sphere S^n to X, and the Yoneda lemma gives us a reason why studying these maps is a powerful way to understand the space X	In homotopy theory, the Yoneda lemma states that a space X is completely determined by the collection of all continuous maps from other spaces into it, i.e., by its functor of points Hom_{Top}​(_,X):Top^op→Set. The homotopy category, where objects are topological spaces and morphisms are homotopy classes of maps, also provides a key application. The Yoneda lemma in this context asserts that the homotopy type of a space X is determined by the functor it represents.
Yoneda lemma, arithmetic number theory, imagine a ring of integers O_K​ of a number field K as an "arithmetic space." We can understand this space not by directly listing its elements, but by seeing how it "looks" through the lens of other rings. For example, if we probe it with the ring of integers Z, the maps are just the inclusions of Z into O_K​. If we probe it with a finite field F_p​, the maps reveal the prime ideals of O_K​ lying over p. The Yoneda lemma says that this collection of "probe results," from all possible rings, completely defines the arithmetic structure of OK​. For example, the ring of integers Z[root(−5)] is uniquely defined by its functor of points which maps a ring R to the set of elements x in R such that x^2 + 5 = 0	In number theory, the Yoneda lemma is implicitly used in the study of schemes and their points. For a number field K, the ring of integers O_K​ is an object in the category of rings. The scheme Spec(O_K​) is then studied via its functor of points, which maps a ring R to the set of ring homomorphisms Hom(O_K​,R). The Yoneda lemma assures us that this functor uniquely defines the ring of integers.
Yoneda lemma, a group G acting on a vector space V over a field k. This action is a representation. We can think of this representation not as the specific vector space V, but as a "recipe" for how G can act. The Yoneda lemma tells us that this recipe is fully encoded by how V "connects" to every other representation. For example, if we have a simple representation S, the maps from S to V (which form the set Hom_{kG​}(S,V)) tell us about the composition factors of V. The Yoneda lemma guarantees that by knowing all these maps for all possible representations, we know our original representation V completely	in modular representation theory, we study representations of a finite group G over a field k of characteristic p (where pdivides the order of G). A key tool is the category of kG-modules. The Yoneda lemma states that a kG-module M is uniquely determined by the functor Hom_{kG​}(M, _): kG-Mod to Set.
Yoneda lemma, imagine a smooth manifold as a geometric object that is locally Euclidean. The Yoneda lemma says that we can understand this manifold completely by looking at all the possible smooth maps from other simpler manifolds into it. For example, to understand a 2-sphere S^2, we don't just look at its points. We can fully describe it by considering all the smooth maps from the real line R, which correspond to smooth curves on the sphere. The collection of all possible smooth curves on the sphere, for instance, gives us a complete "database" of how the sphere behaves smoothly, and the Yoneda lemma guarantees this is enough to define the sphere itself	in differential geometry, the category of smooth manifolds can be studied using the Yoneda lemma. A smooth manifold M is determined by the functor of points Hom(_,M):Man^{op} to Set, where we consider smooth maps.
Yoneda lemma, imagine a commutative ring A as a collection of properties (its elements, its ideals, its prime ideals). The Yoneda lemma says we can understand this ring entirely by observing how it "maps into" other rings. For instance, we can map A into the field of fractions Frac(A), which tells us about its invertible elements. We can map it into a finite ring Z_n​, which tells us about its characteristic and zero-divisors. The Yoneda lemma says that if we have a complete record of all these maps, we have a unique and complete description of the ring A itself	The Yoneda lemma is fundamental to the category-theoretic view of commutative algebra. A ring A is uniquely determined by the functor it represents, Hom_{CRing}​(A,_). This functor maps a ring B to the set of ring homomorphisms from A to B.
Yoneda lemma, a vector bundle can be visualized as a manifold with a vector space attached to each point. For example, the tangent bundle of a sphere is the collection of all tangent planes at every point. The Yoneda lemma says that we can understand this object completely by considering all possible "sections" of it from other manifolds. For example, to understand the tangent bundle of a sphere, we can consider smooth vector fields on the sphere. These are maps from the sphere to its tangent bundle, a specific type of section. The Yoneda lemma suggests that studying the totality of all possible "vector fields" on the sphere (and from other manifolds) is equivalent to studying the tangent bundle itself	A vector bundle E to M over a manifold M can be understood in terms of its functor of points. The Yoneda lemma implies that the isomorphism class of the vector bundle is determined by the functor that assigns to each manifold N the set of vector bundle maps from the trivial bundle over N to the bundle E.
Yoneda lemma, a group scheme as a geometric space (like an elliptic curve) that also has a group law on its points. For an elliptic curve, this group law corresponds to adding points on the curve. The Yoneda lemma says that we can understand this geometric-group object by looking at how its points interact with points from other spaces. For example, for an elliptic curve E, the set of points with coordinates in a field k (the set E(k)) forms an abelian group. The Yoneda lemma says that the collection of these groups for all possible fields k (and other rings) perfectly defines the elliptic curve itself, including its group structure	a group scheme is a scheme G together with morphisms (multiplication, inverse, identity) that make the functor of points Hom(−,G) a functor to the category of groups. The Yoneda lemma ensures that this functorial structure precisely determines the geometric structure of the group scheme.
Yoneda lemma, for a simple discrete dynamical system on a finite set X={1,2,3,4} with the map f(x)=x^2(mod5). We can visualize this as a directed graph where an arrow from x to y means f(x)=y. The Yoneda lemma says that we can understand this entire graph structure by looking at how it "probes" other sets with a similar structure. For example, we can map our system to another one. The Yoneda lemma says that this is the same as mapping a single point of our original graph, which is the starting point of a trajectory. The entire dynamical system is determined by where this "single starting point" can go	in a discrete dynamical system, we have a set X and a map f: X to X. We can view this as a category with objects being elements of X and a single morphism from x to f(x). The Yoneda lemma can be used to understand the structure of this system by examining the functor it represents.
Yoneda lemma, a sheaf can be visualized as a collection of "local data" (sections) that are glued together in a consistent way. For example, the sheaf of regular functions on an affine scheme is given by the ring itself. The Yoneda lemma says that we can understand this complex, glued-together object by looking at all its "global sections." For example, the global sections of a sheaf on an affine scheme X = Spec(A) give us back the ring A itself. The Yoneda lemma guarantees that this process of "probing" the sheaf with open sets and looking at its sections is equivalent to knowing the entire sheaf	a quasi-coherent sheaf of modules F on a scheme X can be fully understood by the functor it represents, which maps an open set U in X to the set of sections F(U). The Yoneda lemma ensures that this functor uniquely determines the sheaf.
Yoneda lemma, imagine two simple representations, S_1​ and S_2​, as two completely "irreducible" and "indivisible" geometric shapes. Schur's Lemma says that the only way to map one of these shapes into the other is to either scale it perfectly (an isomorphism) or to collapse it to a single point (the zero map). The Yoneda lemma gives a deep reason for this	because S1_​ and S_2​ are so fundamental, they only "see" each other in the simplest possible ways. If a map from S_1​ to S_2​ exists, it is determined by where the single "identity" element of S_1​ goes. This one point either maps to zero or to a non-zero point, which by the simplicity of S_2​ must generate the whole space. This forces the map to be either zero or an isomorphism:  for simple representations, Schur's Lemma states that any homomorphism between two simple modules is either an isomorphism or the zero map. This can be viewed as a consequence of the Yoneda lemma. The Yoneda lemma says that the set of homomorphisms from a simple module S to any module M, Hom_{kG​}(S,M), can be understood as the set of "probe points" of M corresponding to S.
Yoneda lemma, for cohomology groups of a topological space are like a set of "holes" of different dimensions. For example, a torus has one 1-dimensional hole and one 2-dimensional hole. The Yoneda lemma says that we can understand these "holes" not by just looking at the space itself, but by looking at how other spaces can "wrap around" these holes. The Yoneda lemma guarantees that the functor that sends a group A to the cohomology group H^n(X,A) uniquely determines the "n-dimensional holes" of X	in algebraic topology, the cohomology of a space X with coefficients in an abelian group A, H^∗(X,A), is defined using a cochain complex built from X. The Yoneda lemma provides a way to see that the cohomology functor H^n(X,−) is uniquely determined by the object it represents in the homotopy category of chain complexes, which is the cochain complex of X.
Asymptotic equipartition theorem, linking Kolmogorov complexity to storytelling	the story with the minimum Kolmogorov complexity compared to the entropy of typical stories will be written in an atypical way and appeal to humanity (minimum model length in humans as a approximation of a Turing machine). So, write weird stories that appeal to humanity.
Lossy compression, themes and handwaving	an analysis of a media piece will definitely have very lossy compression and need not faithfully capture all aspects of the work. Unless one can show that it is the completion of all analyses with all possible probes / morphisms, an analysis cannot be a faithful representation of the work, especially since the scope of human nature is large
Cross entropy reduction, definition of intelligence	reduce the entropy directly to the Kolmogorov complexity.
1D Ising Model, magnetisation model used to illustrate either the metropolis cutoff or Glauber dynamics	idea is to have (-1,1)^N for magnetisation spin, decompose Hamiltonian into two components. Metropolis cutoff considers the minimum of (1, exp(- B H(x))), where B is the inverse temperature and cool to infinity.
Carathedory extension theorem, to measure a "nasty" set A, you "cover" it with simple, measurable shapes (like intervals). You add up their measures. You do this for all possible covers and take the smallest sum. This gives you the "outer measure" of A. Then, to define a "good" set, you demand that it "splits" any other set into two pieces such that the outer measure of the whole is the sum of the outer measures of the parts. This property is like a perfect, clean cut. It's a fundamental criterion for a set to be "measurable."	the key step in the proof is the construction of an outer measure m. For any set A, m(A) is defined as the infimum of the sums of the pre-measures of all countable covers of A by sets from the semi-ring. A set E is then considered "measurable" if for any set A, m(A)= m(A intersect E)+ m(A intersect E_c). The measure M is the restriction of mto these measurable sets.
Fubini's theorem, Imagine a three-dimensional solid object with a variable density given by the function f(x,y). The double integral represents the total mass of the object. Fubini's theorem says you can calculate this total mass in two different ways	by slicing the object into thin slabs parallel to the yz-plane, finding the mass of each slab (the inner integral), and then summing up the masses of all the slabs (the outer integral); or by slicing the object into slabs parallel to the xz-plane. For a function like f(x,y)= x^2 y on the unit square [0,1]×[0,1], you can compute the volume by integrating with respect to y first, and then x, or vice versa, and the answer will be the same:
Fubini's theorem, prob. surface over the xy-plane. The total volume under this surface must be 1. To find the probability distribution of just X, you "squash" the entire landscape onto the x-axis by summing up the probability density at each point on the x-axis for all possible y values. Fubini's theorem guarantees that this "squashing" process is well-defined and that the total volume of 1 can be found by either squashing onto the x-axis first, or onto the y-axis first	
Radon-Nikodym, a joint probability distribution over two variables, X and Y. The Radon-Nikodym theorem allows us to "slice" this distribution at a specific value of Y=y. The probability distribution along this slice is then a new, conditional probability distribution on X. The Radon-Nikodym derivative is the density of this new distribution, and it is precisely the conditional probability density function	The theorem provides the rigorous foundation for the existence of conditional probability density functions and conditional expectation. For two random variables X and Y, the conditional expectation E[X | Y=y] is a function of y that can be formally defined using the Radon-Nikodym derivative of a measure with respect to a marginal measure.
Radon-Nikodym, measure as a function and a function as a measure. The theorem provides a precise way to go back and forth between these two concepts. It's a powerful tool for bridging the gap between abstract measure theory and more concrete functional spaces	The theorem establishes a duality between measures and functions. The space of all absolutely continuous measures with respect to a given measure is isomorphic to the space of all integrable functions with respect to that measure.
Radon-Nikodym, contrast it with Riesz theorem tells us that a "probe" (functional) on a space of continuous functions can be thought of as an integral. The Radon-Nikodym theorem adds to this by saying that if the measure is "nice" (absolutely continuous), we can replace the measure with a simple weighting function	The Riesz representation theorem states that every continuous linear functional on a space of continuous functions can be represented as an integral with respect to a measure. The Radon-Nikodym theorem connects these measures to functions.
Radon-Nikodym, weak derivative is a very general concept. The theorem provides a way to show that if this weak derivative is "well-behaved" (e.g., it is a function in L1), then it must coincide with the classical derivative wherever the function is differentiable	In the theory of Sobolev spaces, the weak derivative is defined as a distribution. The Radon-Nikodym theorem can be used to show that if a function's weak derivative is a regular function, then the weak derivative is also the classical derivative almost everywhere.
Lebesgue decomposition, Lebesgue decomposition is like separating a complex object into two parts	a "smooth" part that can be described by a density function (the absolutely continuous part) and a "bumpy" part that cannot (the singular part). The Radon-Nikodym theorem is about understanding only the smooth part:  The Lebesgue decomposition theorem states that any measure can be decomposed into two parts: a part that is absolutely continuous with respect to another measure and a part that is singular. The Radon-Nikodym theorem only deals with the absolutely continuous part.
Radon-Nikodym, μ as a standard way of measuring "mass" or "volume," like a standard ruler. The measure ν is a different way of measuring, but it never gives a non-zero mass to a set that has zero mass under the standard ruler. For example, if μ is the standard length measure on the real line, ν might be a measure where points at the origin are "heavier" and have a higher density. The Radon-Nikodym derivative f is a density function that tells you how much "denser" the measure ν is compared to μ at each point. It's the "scaling factor" at every location	Let (X,M) be a measurable space and μ,ν be two σ-finite measures on it. If ν is absolutely continuous with respect to μ(i.e., ν(A)=0 for any set A where μ(A)=0), then there exists a measurable function f:X→[0,∞) such that ν(A)=∫A​fdμ for every measurable set A. The function f is called the Radon-Nikodym derivative of ν with respect to μ, denoted f=dν/dμ.
Radon-Nikodym derivative, "difference" between the two distributions. The KL divergence is a way of "averaging" this difference to get a single number	In information theory, the Kullback-Leibler divergence is a measure of how one probability distribution is different from a second, reference distribution. It is defined as an integral with respect to the reference distribution, and the integrand is the logarithm of the Radon-Nikodym derivative.
Radon-Nikdoym, convex body with a variable density. The Radon-Nikodym theorem provides the density function, which allows us to find the precise center of mass	The theorem can be used to define a notion of "center of mass" for a measure. The center of mass is a point that is the average of the coordinates, weighted by the Radon-Nikodym derivative.
Martingales, a point moving on a 2D grid. At each step, the point moves to a new position, but the expected position in the future, given its current location, is exactly where it is now. This isn't about the point not moving; it's about the average of its potential next moves balancing out, so there's no overall drift or bias. For example, consider a simple random walk on the integers, where at each step, a particle moves one unit to the right with probability p and one unit to the left with probability 1−p. The position Xn​ at time n is a martingale if and only if p=1/2. If p=1/2, the expected position after the next step is E[Xn+1​∣Xn​]=Xn​+(1/2)(1)+(1/2)(−1)=Xn	A martingale is a sequence of random variables Xn​ adapted to a filtration Fn​ such that for all n, the conditional expectation of the next value Xn+1​ given all past information Fn​ is simply the current value Xn​. In simpler terms, E[Xn+1​∣Fn​]=Xn​.
Martingales, heat distribution on a plate that is also being randomly "kicked" at every point. The "kicking" part is the white noise. The solution at any point (x,t) is a random variable. The solution at a point can be seen as a martingale in time if the underlying noise term is integrated in a specific way. For example, the stochastic integral from 0 to t of ​Φ(s) dWs​ for an appropriate process Φ(s) is a martingale Ws is Wiener process. This integral can be visualized as a random walk in an infinite-dimensional space, where the "steps" are continuously being taken according to the Wiener process. The expected displacement from the origin at any time is zero	A martingale is a component of the solution to a stochastic partial differential equation (SPDE). For example, the solution to a stochastic heat equation ut​=Δu+W˙ (where W˙ is space-time white noise) can be expressed in terms of a stochastic integral, which is a martingale.
Measure convexity, measure as a way to assign "size" to a set, like area. The area of two non-overlapping regions added together is the same as the area of their union. If they overlap, the area of their union is less. This subadditivity is a fundamental property of measures	A measure m is convex if for any two measurable sets A and B, m(A union B) less than or equal to m(A)+ m(B). This is subadditivity. The convexity of measures is related to the property that the "size" of the union of two sets is no more than the sum of their sizes.
Convexity, graph of a convex function looks like a bowl. Minimizing the function means finding the bottom of the bowl. Because the bowl has a single bottom, there is only one minimum, and it can be found easily. This is not true for a non-convex function, which can have many local minima. Convexity guarantees that any local minimum is also a global minimum, making the problem tractable	A problem is a convex programming problem if it is the minimization of a convex function over a convex set.
Convexity, polar is a way of "dualizing" a convex set. Imagine a convex set. Its polar is another convex set that can be thought of as a "dual" or "inverse" of the original. For a circle, its polar is another circle. For a square, its polar is a diamond. The polar operation is a geometric transformation that preserves convexity	The polar of a convex set is another convex set. The polar of a set C is the set of all vectors y such that inner product of all x,y <= 1 for all x in C.
Convexity, non-convex function, for example, a sine wave. The convex envelope is the function that is obtained by "stretching a rubber band" under the graph. The resulting function is convex. It is a way to "convexify" a non-convex function, which is useful in optimization	The convex envelope of a function is the largest convex function that is less than or equal to the original function. It is the "tightest" convex function that "fits under" the given function.
Convexity, circle and a line segment. Their Minkowski sum is a shape that can be traced by "sliding" the line segment around the circle. The resulting shape is a stadium-like shape, which is also convex. The convexity is preserved under this operation	The Minkowski sum of two convex sets is another convex set. The Minkowski sum of two sets A and B is the set of all sums a+b where a in A and b in B.
Convexity, function whose graph is a bowl. The highest point of the bowl must be on its rim, not in the interior. This is a very powerful property that relates the value of a function in the interior of a domain to its values on the boundary	A function is convex if it satisfies the maximum principle for elliptic operators. For example, for a convex function u with Laplacian of u is nonnegative, its maximum value is attained on the boundary of the domain.
Convexity, Krein-Milman theorem says that a compact, convex set is "built" from its extreme points. The extreme points are the points that cannot be expressed as a convex combination of two other points in the set. For a solid cube, the extreme points are its 8 vertices. The entire cube is the convex hull of these 8 vertices. The theorem guarantees that for any compact, convex set, such a finite or infinite set of "building blocks" exists	A compact convex set in a locally convex topological vector space is the convex hull of its extreme points.
Weak law of large numbers, a dartboard with a bullseye. Each dart throw is a random variable. The WLLN states that if you throw enough darts, the average position of your throws will be very close to the bullseye, which is the expected value of the throws. The throws can be scattered, but their average position will be concentrated near the bullseye	Sample mean converges to probability in measure for sequence of iid random varaibles with bounded mean.
Convexity, convex set is a "blob" without any dents or indentations. Imagine a 2D set. If you pick any two points inside it, you can "walk" a straight line between them without leaving the set. For a square, any straight line between two points on the boundary or interior stays inside the square. A crescent shape, however, is not convex because a straight line between two points in the "horns" would leave the shape. This is the most fundamental and intuitive definition	A set is convex in R^n if for any two points in the set, the line segment connecting them is contained entirely withn C, formally for parameters in the unit interval, convex combinations are closed within C.
Convex functions, convex function is a function whose graph "cups upwards." Any straight line segment connecting two points on the graph of the function must lie on or above the graph. For the function f(x)=x2, the parabola "cups upwards." If you draw a line from (1,1) to (2,4), the line lies above the parabola. A function like f(x)=sin(x) is not convex on a large interval because it oscillates, and a line segment can pass below its graph. The visual intuition is that a convex function has a unique minimum, making it easy to optimize	A function f: R^n→R is convex if for any two points x,y in its domain and any p in [0,1], the function value at the weighted average of the points is less than or equal to the weighted average of the function values. Formally, f(px+(1−p)y) is less than or equal to pf(x)+(1−p)f(y).
Convexity, a random variable X as a set of points on the x-axis, each with a certain probability. The expected value E[X] is the weighted average of these points. Jensen's inequality says that the average of the function's values at these points is greater than or equal to the function's value at the average point. For the function f(x)=x^2, the variance formula E[X^2]≥(E[X])^2 is a direct result of this. This visually means that the "spread" of the random variable increases the average value of the convex function	a function f is convex if for any random variable X, the expected value of the function of the random variable is greater than or equal to the function of the expected value of the random variable. Formally, E[f(X)] is more hthan or equal to f(E[X]).
Convexity, convex polygon in R^2. The set of its vertices are the extreme points. Any point inside the polygon can be written as a convex combination of its vertices. This means we can "build" the entire convex set by taking weighted averages of its extreme points. This is not true for a non-convex set. For a square, the vertices are the extreme points. A point (1/2,1/2) can be written as (1/4,1/4,1/4,1/4) times the vertices	A set is convex if it is a "convex combination" of its extreme points. A convex set can be uniquely characterized by its extreme points.
Convexity, "local" part refers to the fact that we can zoom in around any point and find a small, convex neighborhood. This is a crucial property for doing analysis in these spaces. The space itself isn't necessarily convex, but it can be "approximated" by convex sets. Imagine a space where every point has a small, convex "bubble" around it. The space of all continuous functions on [0,1] with the topology of uniform convergence is locally convex	A topological vector space is locally convex if its topology is defined by a family of seminorms. A seminorm is a function that is similar to a norm but can be zero for non-zero vectors. The topology is generated by a basis of convex sets, namely the open balls defined by the seminorms.
Convexity, geometric realisation as a polyhedron, half-space is a region of space on one side of a hyperplane (a line in 2D, a plane in 3D). A convex polyhedron is the shape you get by taking the intersection of many such half-spaces. For a cube, it is the intersection of 6 half-spaces, defined by the planes of its faces. This shows that a convex set can be defined by its "boundaries."	A polyhedron is the intersection of a finite number of half-spaces. A bounded polyhedron is a polytope. This definition is a dual perspective to the one using extreme points
Weak law of large numbers, study of random matrices, the WLLN is used to show that the empirical spectral distribution of a large random matrix converges to a deterministic distribution. This is a way of saying that the average of the eigenvalues of a large random matrix is well-behaved and predictable	
Weak law of large numbers, probability distribution of the sample mean Xˉn​ is a measure. The WLLN states that as n tends to infinity, this measure becomes more and more concentrated at the point m, effectively converging to a Dirac delta measure at m	
Weak law of large numbers, information theory, the entropy of a sequence of random variables is their average information content. The WLLN guarantees that the average information content converges to the true entropy	The WLLN is used to analyze the average behavior of a sequence of random variables.
Weak law of large numbers, the macroscopic properties of a system (e.g., temperature) are the average of the microscopic properties of the particles. The WLLN guarantees that these averages are well-defined and predictable	The WLLN is a fundamental principle of statistical mechanics.
Strong law of large numbers, an infinite sequence of coin flips. The SLLN states that the proportion of heads will eventually settle down and become exactly 0.5. Although any finite sequence may not have exactly 50% heads, as the number of flips goes to infinity, the proportion almost surely approaches the true mean. It is the "long-term certainty" of the average	For a sequence of i.i.d. random variables X1​,X2​,… with mean E[X1​]=μ bounded, the sample mean ​converges almost surely to the mean
Strong law of large numbers, study of large random matrices (e.g., Wigner matrices), the SLLN guarantees that the distribution of the eigenvalues will almost surely converge to a deterministic distribution (the Wigner semicircle law). It’s a statement about the almost sure regularity of the eigenvalues of a large random matrix	The SLLN is used to analyze the convergence of the empirical spectral distribution of random matrices.
Strong law of large numbers, sequence of probability distributions of the sample mean converges almost surely to a Dirac delta measure. This means that for a given sequence of random variables, the measure becomes a point mass at the true mean	
Strong law of large numbers, WLLN says the probability of the average being far from the mean goes to zero. The SLLN says that for any specific sequence of outcomes, the average will almost surely converge to the mean. It's the difference between "likely to be close" and "almost certain to converge."	The SLLN is a deeper and more profound result than the Weak Law of Large Numbers.
Strong law of large numbers, distribution of the sample mean converges to a Dirac delta distribution at the true mean. The SLLN states that this convergence happens almost surely	The SLLN is a statement about the almost sure convergence of a sequence of random variables to a constant distribution.
Strong law of large numbers, system with random perturbations, the SLLN can be used to show that the singularities of the solution will almost surely propagate along a deterministic path. It's a way of saying that the random perturbations don't change the overall behavior of the system in the long run	The SLLN is related to the almost sure propagation of singularities in random systems.
Strong law of large numbers, entropy of a random sequence is its average information content. The SLLN guarantees that the average information content will almost surely converge to the true entropy	The SLLN is used to analyze the almost sure convergence of the average information content of a random sequence.
Martingales, sequential analysis, you collect data until you have enough evidence to make a decision. The sum of the log-likelihood ratios is a martingale. The martingale property ensures that the test doesn't have a bias	Martingales are used in sequential analysis and hypothesis testing.
Regret analysis, imagine a company trying to set prices for its products to minimize costs. The company's pricing strategy is the algorithm. The regret is the difference between the total cost incurred by the company and the total cost if they had known the optimal price from the beginning and kept it fixed	In online convex optimization, regret is the difference between the cumulative cost of the algorithm's decisions and the cost of the best single fixed decision in hindsight.
Maximum entropy, a continuous probability distribution on the interval [0,1] with a given mean. The family of all such distributions is a convex set. The entropy functional is concave. The maximum entropy distribution is the one that corresponds to the point in this convex set where the concavity of the entropy functional is maximized. For example, if the only constraint on a distribution on [0,1] is that its mean is 1/2, the maximum entropy distribution is the uniform distribution, which is a flat line. This line represents the distribution that is "least informative" or "most spread out," making no assumptions about any specific point being more likely than another. ]	The maximum entropy principle in probability theory states that among all probability distributions that satisfy a given set of constraints (e.g., specified means, variances, or other moments), the one with the largest entropy is the most reasonable choice. This is because it makes the fewest assumptions beyond the given constraints.
Maximum entropy principle, space of all possible probability distributions as a landscape, with the altitude at any point representing the entropy of that distribution. The known constraints define a "path" or a "region" in this landscape. The maximum entropy principle tells us to find the highest point on this path. For example, consider the space of all probability distributions on a finite set of outcomes. The maximum entropy distribution (the uniform one) corresponds to the highest point in this landscape, a "flat plateau." Adding a constraint (e.g., specifying the mean) restricts us to a lower-dimensional slice of this landscape, and we then find the highest point on that slice	From an information theory perspective, the maximum entropy principle is a method for constructing the least-informative probability distribution given some constraints. The entropy of a distribution, H(P), quantifies the uncertainty or information content of a random variable. Maximizing entropy means choosing the distribution that retains the maximum possible uncertainty, given the known information.
Maximum entropy principle, space of all possible probability distributions, the set of distributions satisfying linear constraints forms a convex set. The entropy function defines a "bowl" opening downwards (a concave function). The solution to the maximum entropy problem is the unique point where the bowl's surface touches the "highest" part of the convex constraint set. For example, for a discrete probability distribution, the set of all distributions forms a simplex. The maximum entropy distribution (the uniform one) is the center of this simplex. Constraining the mean is like intersecting the simplex with a hyperplane, and the solution is the point on this new intersection that is closest to the center	The maximum entropy principle can be formulated as a convex optimization problem. The entropy function is concave, and the constraints (often expectations of certain functions) are typically linear, defining a convex feasible set. Maximizing the concave entropy function over a convex set is a standard convex optimization problem.
Maximum entropy principle, density operator ρ is a positive semidefinite operator with trace 1. Its eigenvalues pi​ form a probability distribution over the system's energy eigenstates. Maximizing the von Neumann entropy S(p) is equivalent to maximizing the Shannon entropy of the eigenvalue distribution. The "least biased" state is the one where the eigenvalues are as "spread out" as possible, which corresponds to the identity operator (or a multiple thereof) if there are no constraints. The identity operator is "maximally mixed" as it assigns equal probability to all eigenstates. Constraining the expectation value of an observable means that we must choose a density operator whose eigenvalues are arranged in a specific way, and we find the arrangement that is most "uniform" while satisfying the constraint	In quantum mechanics, the state of a system is described by a density operator p. The von Neumann entropy S(p)=−Tr(p log p) is the quantum mechanical analogue of Shannon entropy. The maximum entropy principle states that the density operator describing a system, given some constraints on expectation values of observables, is the one that maximizes the von Neumann entropy. This is a direct application of the principle to a non-commutative setting.
Maximum entropy principle, space of all probability measures on a space like a vast sea. Each point in the sea is a measure. The constraints define a specific "island" in this sea. The maximum entropy principle states that the "most natural" or "least structured" measure is the one at the highest elevation on this island, where elevation is measured by entropy. For example, the maximum entropy measure on R with a fixed variance is the Gaussian measure. A Gaussian distribution visually "spreads out" the probability mass as much as possible while maintaining a fixed amount of dispersion (variance). The entropy of a measure m with respect to a base measure v is defined as H(m ) = - integral log(dm/dv​)dμ	The maximum entropy principle can be generalized to the space of all probability measures on a given measurable space. Given a class of measures that satisfy certain moment constraints, the principle selects the measure with the maximum entropy. The entropy of a measure m with respect to a base measure v is defined as H(m ) = - integral log(dm/dv​)dμ
Maximum entropy principle, dynamical system on a compact manifold, like a torus. There can be many invariant measures. The maximum entropy principle would select the one that is "most uniform" or "least structured," such as the Haar measure on a Lie group. The Haar measure on a torus is simply the uniform measure. This measure is "as spread out as possible" over the torus, making no preference for any specific region. This "uniformity" is what we would intuitively expect for a system at equilibrium	In global analysis, the maximum entropy principle can be related to the study of measures on manifolds. For example, in the study of dynamical systems, one is interested in invariant measures. The principle can be used to select a "natural" invariant measure. This is particularly relevant in the context of statistical mechanics on manifolds.
Maximum entropy principle, fluid diffusing in a container. The diffusion process tends to "spread out" the fluid, increasing its "entropy" or "disorder." The maximum entropy principle provides the mathematical framework for this. A solution to a diffusion equation, like the heat equation, describes a probability distribution that evolves from a localized state to a more uniform, high-entropy state over time. The "entropic force" that drives the system to a state of maximum entropy can be seen as the underlying mechanism described by the PDE	In the context of partial differential equations, the maximum entropy principle can be used to derive certain PDEs. For example, the Fokker-Planck equation, which describes the time evolution of the probability density function of a random process, can be derived by maximizing entropy subject to a certain rate of change constraint. The principle gives a variational framework for understanding the evolution of a probability distribution.
Maximum entropy principle, Wiener process (Brownian motion) is a prime example of a maximum entropy process. It's the "most random" continuous-time process whose increments are independent and normally distributed. The path of a Wiener process is a "random walk" that is "as wiggly as possible" while remaining continuous. The maximum entropy principle can be used to derive this process by finding the path measure that maximizes entropy subject to the constraint that the increments are independent	The maximum entropy principle is fundamental in stochastic analysis for constructing prior probability distributions for stochastic processes. For example, one can apply the principle to find the probability distribution of a path of a stochastic process, given constraints on its moments or other properties. The maximum entropy path distribution is the one that is "most random" while satisfying the constraints.
Maximum entropy principle, blob of ink dropped into a glass of water. The ink particles are a probability distribution. The time evolution is a semigroup of operators that describes the diffusion of the ink. As time goes on, the ink spreads out and becomes uniform, reaching a state of maximum entropy. The semigroup "pushes" the system towards this state. The maximum entropy state is the fixed point of this semigroup	The maximum entropy principle can be linked to semigroup theory through the evolution of probability distributions. A semigroup of operators can describe the time evolution of a system. The principle suggests that this evolution should be "entropy-increasing" and should drive the system towards a maximum entropy state (equilibrium). For example, the heat semigroup, generated by the Laplacian operator, "smears out" any initial heat distribution towards a uniform, high-entropy state.
Maximum entropy distribution, a system of gas particles in a box. At equilibrium, the particles are not all moving at the same speed; rather, their speeds are distributed according to the Maxwell-Boltzmann distribution. This distribution is the one that maximizes the "disorder" or entropy of the system while maintaining a fixed total energy. The particles are as "random" as they can be, given the constraint on their average energy. The exponential form of the distribution means that lower-energy states are more probable, but higher-energy states are still possible, which is the most "unbiased" arrangement	the maximum entropy principle provides a foundation for the Gibbs and Boltzmann distributions. It states that the probability distribution over the microstates of a system in thermal equilibrium is the one that maximizes entropy subject to the constraint of a fixed average energy. This leads directly to the Gibbs distribution P(x) proportional to exp(−bE(x)).
Differential entropy, integral whose kernel is the -log p(X). Note that this is not corect. p(x) fails dimensional analysis. Jaynes fixed this by defining the invariant measure N discrete points lim ([number of points in a < x < b]/N) = integral m(x) over support [a, b], then the differential entropy lim N_\infty H_N(X) = log(N) - integral p(x) log [p(x) / m(x)]	Entropy, integral whose kernel is the -log p(X).
Additive / abelian categories, nice properties on monomorphisms	on monomorphisms, very nice to have kernels, monomorphisms and monics be basically the same on some level in additive / abelian categories, see Weibel's Homological Algebra. Furthermore, the existence of zero object very important, Hom functor is right adjoint, preserving limits, need something like AB4 i.e. cocompleteness to have direct sums preserved as well.
Additive / abelian categories, nice exactness correspondence	let C and D be abelian categories, F be functor from C to D, G be functor from D to C, additive functor given isomorphism of bifunctors, Hom_D(FX, Y) = Hom_C(X, GY), F is left adjoint to G, G is right adjoint of F, then F is right exact and G is left exact (see Gelfand and Manin's Homological Algebra). I am not sure if you need abelian categories to establish this.
Adjoints, clarifying relationship between right shift and left shift operators	adjunction of right shift operator gives left shift operator, suppose we have s_r x = (0, x1, x2, ...) and maps s_r from l^2 to l^2 discretised Hilbert spaces, then we have s_r^* = s_l since we can see that s_r^* y = (y2, y3, y4, ...). We have that (s_r x, y) = (x, s_r^* y) or that the the right shift operator x is left adjoint to the left shift operator on y.
Adjoints, limit preservations	the proof is from nlab, start with the natural isomorphism of adjoint functors (intuition comes from integration, Riesz representation, but with homs). Use the definition of adjunction, we have for a category C and D, a functor L and R (left and right adjoint functors), and objects c and d, HomC(L(d), c) is naturally isomorphic to HomD(d, R(c)) by definition. You will want to show c to be the limit, since R is the right adjoint. The second thing is that Hom functors preserve limits. Lastly, apply Yoneda's lemma, the natural isomorphism of Hom sets of objects give isomorphism of objects. Apply the first definition of natural isomorphism, to second to somehow take out the limit c as a representing object. Apply Yoneda's lemma in reverse, the limits are preserved and are naturally isomorphic under action of right adjoints. This theorem is formally dual for colimits, so left adjoints must preserve colimits. Note that due to much thought devoted to the Yoneda embedding, it is more customary to see the right adjoint version due to the application (and then reversal) of Yoneda's lemma here.
Kernel, inverse image of identity in group	inverse image of identity element
Kernel, equivalence class of zero	Kernel is set of all elements mapped to 0 in codomain
Kernel, as a fibre	Kernel is fibre of identity element
Kernel, normal subgroup	Only subgroup that is the kernel of a group homomorphism
Kernel, set of trivial elements	Set of elements trivial with respect to the given group homomorphism, losing distinctiveness mapping to identity
Kernel, basis of partition	Cosets of kernel form a partition of the domain group, each coset is fibre of homomorphism
Kernel, quotient group generator	Quotient group G/ ker(f) is isomorphic to image of homomorphism
Kernel, morphism induced subgroup	Kernel is subgroup induced solely by a group homomorphism
Kernel, object in category	Captures the difference between a morphism and identity morphism
Kernel, for a free group	Kernel of a homomorphism from a free group is a set of all relations that must be satisfied by its generators
Kernel, information loss	Measure of information loss from domain to image group, larger the kernel, the more information is lost.
Cokernel, unreachable elements	represents the set of elements in the codomain that cannot be expressed as the image of any element in the domain.
Cokernel, codomain partition	cokernel, partition of codomain W into disjoint affine subspaces, cosets of the image subspace Im(f)
Cokernel, equivalence class	Equivalence classes of elements where elements are equivalent if their difference is in the image of the map
Cokernel, fibre for space of fibres of projection map W to W/Im(f)	consider the space of fibres of the projection map W to W/Im(f) we have each element of the cokernel is a fibre (a coset)
Cokernel, quotient space	Quotient space measures how far the map is from being surjective
Cokernel, final object	Final object in a commutative diagram
Cokernel, codomain of canonical projection	codomain of canonical projection map p: W -> coker(f)
Cokernel, information gain	Kernel measures info loss from domain, cokernel measures information gain in domain that is not explained by the group homomorphism
Cokernel, homomorphic collapse	Collapse image to single point (zero vector), residue of codomain is cokernel
Colimit, generative ontology	colimit is the most general object that can be constructed from a given diagram. It contains all the information from the diagram without adding any new relations.
Colimit, free object	colimit is a free object subject to a set of relations. It is the most general solution to a given set of constraints.
Colimit, disjunction	colimit models a logical disjunction or "or" condition. For example, a coproduct of two objects can be thought of as a way to "either have this or that."
Colimit, opposite category	colimit in a category C is a limit in the opposite category Cop. This powerful duality allows you to use intuition about limits (like products and equalizers) to understand colimits.
Colimit, sum or union	colimit is a generalization of the disjoint union of sets or the direct sum of abelian groups. The colimit "ignores" the shared structure and puts everything together.
Colimit, quotient	Generalisation for quotient, example coequalisers models a quotient.
Colimit, final object	A colimit is a final object in the category of all cocones over a given diagram.
Colimit, glue	colimit is the formal way to "glue" together a collection of objects and the maps between them into a single, cohesive object.
Limit, intersection of sets	limit is a generalization of the intersection of sets. For example, a product is a kind of limit that acts like a Cartesian product, and a pullback acts like an intersection.
Limit, generalisation of product	limit is a generalization of the Cartesian product of sets, the direct product of groups, or the product of topological spaces.
Limit, conjunction	limit models a logical conjunction or "and" condition. For example, a product of two objects can be thought of as a way to have "this and that" simultaneously.
Limit, fixed point	limit can be seen as a kind of fixed point for an iterative process of converging to a final, stable object.
Limit, abstraction	limit is the ultimate tool for abstraction. It allows us to forget the internal structure of objects and diagrams and focus only on the universal relationship to the limit object.
Limit, projective property	limit is an object that has a projective property with respect to the diagram. Every object that has a map to all the objects in the diagram must have a unique map that factors through the limit.
Limit, canonical representative object	limit is the canonical object that represents a family of objects and morphisms. Any two limits of the same diagram are uniquely isomorphic, highlighting its canonicity.
Limit, representable cone functor	limit can be understood as an object that represents a functor (the cone functor) from the category of diagrams to the category of sets. This perspective is foundational in higher category theory.
Internal hom, object in category	set of morphisms from A to B
Internal hom, universal property of relevant adjunction	Tensor hom adjunction is universal property
Internal hom, representable functor	Functor Hom(A * -, B) is represented by Hom(A, B), natural isomorphism between object C to Hom(A,B) and the set of morphisms from A * C to B,
Internal hom, exponential object in Cartesian closed category	exponential object, denoted B^A
Internal hom, function object	object of functions from A to B within the category
Internal hom, hom module over a ring R	the hom module Hom_R(M,N) set of R-linear maps from module M to module N
Internal hom, as module of homomorphisms over a ring R	Hom_R(M,N) is an R-module, defined by (rf)(m) = r(f(m))
Internal hom, functorial hom	Bifunctor Hom_R(-,-) is product category of R-modules to category of R-modules, contravariant in the first variable, covariant in second
Internal hom, enriched category theory	an internal hom value of hom functor in an enriched category, it is a hom object
Internal hom, morphism space	space of morphism between two objects in a category
Internal hom, local hom-functor	sheaf of hom-modules for sheaves of modules on a scheme
Internal hom, local Hom-functor	a local Hom-functor is a sheaf of Hom-modules for sheaves of modules on a scheme, local version of global internal hom
Internal hom, exponential law	(B^C)^A is isomorphic to (B^{C tensor A}}, holds for internal hom
Internal hom, closed	category is closed if it has an internal hom
Internal hom, dual of hom module	dual of module M is Hom_R(M, R)
Internal hom, inner product	Hom can be treated like an inner product Hom_R(R, M) = M is dual to Hom_R(M, R)
Internal hom, corepresenting object	Hom(A-B) corepresents functor Hom(A * -, B)
Pushout, gluing roads at starting point	pushout of two morphisms f:S→X and g:S→Y is an object P together with morphisms p1​:X→P and p2​:Y→P that satisfy a universal property. Imagine two roads, X and Y, both starting from a common point, S. The pushout is the space you get by gluing the two roads together at their starting point.
Pushout, gluing of disjoint unions in the category of Set	category of sets, the pushout is the quotient of the disjoint union of X and Y by the equivalence relation generated by f(s)∼g(s). Visual Intuition: You're taking two sets and "gluing" them together at a common sub-set.
Pushout, gluing of common boundary	pushout is a quotient of the disjoint union space. Visual Intuition: You're taking two spaces and "gluing" them together along a common boundary.
Pushout, pushforward local data	pushout of a sheaf is a way to "push forward" the local data of a sheaf from one space to another. Visual Intuition: You're taking a sheaf on one space and creating a new sheaf on another space that is compatible with the original one.
Pullback, addresses in third subspace for topology given a product space in category of topological space	category of topological spaces, a pullback is a subspace of the product space, with the subspace topology.
Pullback, fibre product of two roads	pullback (or fiber product) of two morphisms f:  X →  S and g: Y → S is an object P together with morphisms p1​: P → X and p2​: P → Y that satisfy a universal property. Visual Intuition: Imagine two roads, X and Y, both leading to a city, S. The pullback is the intersection of these roads. It's the set of all pairs of points (x,y) such that f(x)=g(y).
Pullback, transportation of bundles pullback of vector bundles	pullback of a vector bundle is a way to "transport" a bundle from one space to another. Imagine a bundle of lines on a surface. If you have a map from a circle to the surface, the pullback bundle is a bundle of lines on the circle. You're pulling the geometry of the bundle back to the circle.
Pullback, restriction and pulling back to scalar multiplication of R via a ring homomorphism	ring homomorphism ϕ: R → S, the pullback of an S-module M is an R-module. Visual Intuition: You're taking an S-module and making it an R-module by "restricting" the scalar multiplication to R.
Filtered colimit, limit over directed set, sequence of nested intervals on the real line	I1​=[0,1], I2​=[0,1.5], I3​=[0,1.75], and so on, with the maps being the inclusion maps. The filtered colimit of this system is the interval [0,2]:  In category theory, a filtered colimit (or direct limit) is a construction that takes a "directed system" of objects and maps and produces a single object that is, in a sense, the "union" of all the objects in the system. The index set of the system must be a filtered category, meaning for any two objects, there is a third object that can be reached from both via a map. Visual Intuition: Consider a sequence of nested intervals on the real line: I1​=[0,1], I2​=[0,1.5], I3​=[0,1.75], and so on, with the maps being the inclusion maps. The filtered colimit of this system is the interval [0,2]. . The filtered colimit is the object that "contains" all the objects in the sequence, just like the interval [0,2] contains all the In​. It's the "ultimate" object that everything in the system maps into.
Filtered colimit, system of spheres S0 in S1 in S2 in … where the inclusions are defined by mapping the sphere of dimension n to the "equator" of the sphere of dimension n+1. The filtered colimit of this system is the infinite-dimensional sphere Sinfty	In topology, a filtered colimit of a filtered system of topological spaces is a topological space whose points are the equivalence classes of the disjoint union of the spaces, and whose topology is the final topology. Visual Intuition: Consider the system of spheres S0 in S1 in S2 in… where the inclusions are defined by mapping the sphere of dimension n to the "equator" of the sphere of dimension n+1. The filtered colimit of this system is the infinite-dimensional sphere Sinfty. . The infinite sphere is a space that is "built up" by taking the union of all finite-dimensional spheres.
Filtered colimit, sequence of affine schemes Xn​=Spec(k[x]/x^n), which are "thickenings" of the origin in the affine line. The maps are the natural inclusions. The filtered colimit of this system is the formal scheme Spec(k[[x]])	In algebraic geometry, a filtered colimit of a filtered system of schemes is a new scheme whose coordinate ring is the filtered colimit of the coordinate rings of the schemes in the system. Visual Intuition: Consider a sequence of affine schemes X^n​=Spec(k[x]/x^n), which are "thickenings" of the origin in the affine line. The maps are the natural inclusions. The filtered colimit of this system is the formal scheme Spec(k[[x]]). . The formal scheme is a "microscopic" neighborhood of the origin that is "built up" by taking the limit of all its finite thickenings.
Filtered colimit, system of modules Z/2Z→Z/4Z→Z/8Z→… where the maps are the natural inclusions. The filtered colimit of this system is the group of 2-adic integers Z2​	In homological algebra, a filtered colimit of a filtered system of modules is a new module whose elements are equivalence classes of elements from the original modules. Visual Intuition: Consider the system of modules Z/2Z→Z/4Z→Z/8Z→… where the maps are the natural inclusions. The filtered colimit of this system is the group of 2-adic integers Z2​. . The 2-adic integers can be seen as the "ultimate" object that "absorbs" all the Z/2nZ. It is a way of "completing" the system.
Filtered colimit, system of matrix rings M2​(C) to M4​(C) to M8​(C) to … where the maps are block-diagonal inclusions. The filtered colimit of this system is the infinite-dimensional matrix algebra	In non-commutative ring theory, a filtered colimit of a filtered system of rings is a new ring whose elements are equivalence classes of elements from the original rings. Visual Intuition: Consider the system of matrix rings M2​(C) to M4​(C) to M8​(C) to … where the maps are block-diagonal inclusions. The filtered colimit of this system is the infinite-dimensional matrix algebra. This infinite matrix algebra is the "ultimate" object that contains all finite-dimensional matrix algebras as a subalgebra.
Filtered colimit, sequence of modules M1​ in M2​ in M3​ in … over a group algebra Fp​[G]	In modular representation theory, a filtered colimit can be a way to describe the "ultimate" module that is a direct limit of a system of modules over a group ring. Visual Intuition: Consider a sequence of modules M1​ in M2​ in M3​⊂… over a group algebra Fp​[G]. The filtered colimit is a new module M∞​ that is the union of all the modules in the sequence. This is a way of "building up" a large, complicated module from smaller, simpler ones.
Filtered colimit, system of polynomial rings k[x] to k[x,y] to k[x,y,z] to …. The filtered colimit of this system is the polynomial ring in infinitely many variables k[x1​,x2​,…]	In commutative algebra, a filtered colimit of a filtered system of commutative rings is a new ring whose elements are equivalence classes of elements from the original rings. Visual Intuition: Consider the system of polynomial rings k[x] to k[x,y] to k[x,y,z] to …. The filtered colimit of this system is the polynomial ring in infinitely many variables k[x1​,x2​,…]. This is a way of "building up" a huge ring from a sequence of smaller ones.
Cofiltered limit, sequence of nested intervals on the real line	I1​=[0,1], I2​=[0,1/2], I3​=[0,1/4], and so on, with the maps being the inclusion maps. The cofiltered limit of this system is the single point {0}:  In category theory, a cofiltered limit (or inverse limit) is a construction that takes a "directed system" of objects and maps and produces a single object that is, in a sense, the "intersection" of all the objects in the system. The index set of the system must be a cofiltered category, meaning for any two objects, there is a third object that has a map to both. Visual Intuition: Consider a sequence of nested intervals on the real line: I1​=[0,1], I2​=[0,1/2], I3​=[0,1/4], and so on, with the maps being the inclusion maps. The cofiltered limit of this system is the single point {0}. The cofiltered limit is the object that is "contained" within all the objects in the sequence, just like the point {0} is contained in all the In​. It's the "ultimate" object that everything in the system maps from.
Cofiltered limit, system of spheres with a fixed point Sn where the maps are the constant maps from Sn+1 to Sn. The cofiltered limit of this system is the infinite-dimensional sphere S∞ with a fixed point	In topology, a cofiltered limit of a cofiltered system of topological spaces is a topological space whose points are coherent sequences of points from the original spaces. Visual Intuition: Consider the system of spheres with a fixed point Sn where the maps are the constant maps from Sn+1to Sn. The cofiltered limit of this system is the infinite-dimensional sphere S∞ with a fixed point. This is a way of "building up" a space by taking the intersection of all the spheres. It's the "ultimate" object that everything in the system maps into.
Functor of points, imagine the affine line A1 as a set of points. The functor of points view says, don't look at the points, look at all the maps into the line. A map from a scheme T to A1 is just a function on T. The functor of points for A1 is the rule that says, for any ring R, give me the set of all polynomials with coefficients in R. This is a "generalized" way of viewing the line	The functor of points perspective views a scheme X not as a set of points, but as a rule that assigns a set of maps to X from any other scheme T. This rule is a functor from the category of schemes to the category of sets, denoted as Hom(−,X). This allows one to study a scheme by studying its relationship with all other schemes, providing a more robust and flexible definition of a "geometric object." For example, the affine line A1 is the functor that assigns to each ring R the set of its elements.
Functor of points, group Z as a number line. The functor of points view says, don't look at the numbers, look at all the maps into the number line. A map from a group H to Z is a homomorphism. This is a "generalized" way of viewing the group	In group theory, a group G can be viewed as a functor of points. This functor assigns to each group H the set of all group homomorphisms from H to G. This generalizes the idea of a group as a set with a multiplication rule. It is a more abstract way of thinking about groups. For example, the group Z is the functor that assigns to each group H the set of its elements.
Functor of points, a chain complex as a tower of vector spaces. The functor of points view says, don't look at the spaces, look at all the maps into the tower. A map from a chain complex D*​ to C*​ is a chain map. This is a "generalized" way of viewing the chain complex	In homological algebra, a chain complex C*​ can be viewed as a functor of points. This functor assigns to each chain complex D*​ the set of all chain maps from D*​ to C*​. This generalizes the idea of a chain complex as a sequence of modules with maps between them.
Functor of points, ring as a space with a non-commutative multiplication rule. The functor of points view says, don't look at the points, look at all the maps into the space. A map from a ring S to R is a ring homomorphism. This is a "generalized" way of viewing the ring	In non-commutative ring theory, a ring R can be viewed as a functor of points. This functor assigns to each ring S the set of all ring homomorphisms from S to R. This generalizes the idea of a ring as a set with two operations.
Functor of points, a group algebra as a geometric object. The functor of points view says, don't look at the points, look at all the maps into the object. A map from an algebra A to kG is an algebra homomorphism	In modular representation theory, a group algebra kG can be viewed as a functor of points. This functor assigns to each algebra A the set of all algebra homomorphisms from A to kG. This generalizes the idea of a group algebra as a ring with an action of a group.
Functor of points, sphere. The functor of points view says, don't look at the points, look at all the maps into the sphere. A map from a space Y to the sphere is a continuous map. This is a "generalized" way of viewing the sphere	In homotopy theory, a topological space X can be viewed as a functor of points. This functor assigns to each topological space Y the set of all continuous maps from Y to X. This generalizes the idea of a topological space as a set with a topology.
Functor of points, a number field as a space of numbers. The functor of points view says, don't look at the numbers, look at all the maps into the space. A map from a field L to K is a field homomorphism. This is a "generalized" way of viewing the number field	In arithmetic number theory, a number field K can be viewed as a functor of points. This functor assigns to each field L the set of all field homomorphisms from L to K. This generalizes the idea of a number field as a field extension of Q.
Functor of points, a dynamical system as a flow on a manifold. The functor of points view says, don't look at the flow, look at all the maps that preserve the flow. A map from a dynamical system (Y,g) to (X,f) is a map that commutes with the dynamics. This is a "generalized" way of viewing the dynamical system	In dynamics, a dynamical system (X,f) can be viewed as a functor of points. This functor assigns to each dynamical system (Y,g) the set of all maps that preserve the dynamics. This generalizes the idea of a dynamical system as a space with a map.
Functor of points, projective space as a space of lines through the origin. The functor of points view says, don't look at the lines, look at all the maps into the space. A map from a scheme T to Pn is a line bundle on T. This is a "generalized" way of viewing projective space	The functor of points for projective space Pn assigns to each ring R the set of all "line bundles with a basis" on Spec(R). This is a very abstract way of defining projective space.
Functor of points, derived functor is a functor that is a "homological" version of a normal functor. The functor of points view is a way of "seeing" this	The concept of a functor of points can be used to define derived functors. A derived functor is a functor that is "homological." The functor of points view is a way of "seeing" the derived functors.
Functor of points, a module as a vector space with a ring action. The functor of points view says, don't look at the points, look at all the maps into the space. A map from a module N to M is a module homomorphism	In non-commutative ring theory, a module M can be viewed as a functor of points. This functor assigns to each module N the set of all module homomorphisms from N to M. This generalizes the idea of a module as a vector space with a ring action.
Functor of points, a module as a geometric object. The functor of points view says, don't look at the points, look at all the maps into the object. A map from a module N to M is a module homomorphism	In modular representation theory, a module M over a group algebra kG can be viewed as a functor of points. This functor assigns to each kG-module N the set of all module homomorphisms from N to M.
