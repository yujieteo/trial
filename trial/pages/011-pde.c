/* Integral equation, motivating problem in PDEs:   we do not understand integral equations, therefore we can try to use functional analysis and distribution theory to answer questions about this. */
/* Functional analysis, extension of spectral theory to PDEs:  spectral theory and duality are two key areas of study to consider for PDEs. Spectral theory is basically about eigenfunctions and expansions, takes 60 years to extend to PDEs. Spectral theory matured wit an understanding of linear duality (or the uncertainty principle). */
/* Schwartz space, definition of objects that capture automorphisms:  one big idea to capture simple objects in mathematics is to capture objects that are invariant under automorphisms of important operations. For example, Schwartz spaces are based on automorphisms of the Fourier transforms, algebraic stacks are objects that capture automorphisms of moduli spaces for classification purposes. The capturing of automorphisms lend themselves to simplicity, since they retain the same properties under automorphic actions. */
/* Sobolev parameters, Imagine a 1D function u(x) on the interval [0,1]. Its L2 norm, ||u||L2â€‹, measures its overall "size" or area under the curve (squared). The W1,2 norm, ||u||_W1,2â€‹ = sqrt (iunit ntegral of u(x)^2 + unit integral of u'(x)^2) measures its "size" and its "slope" or "wiggliness." Consider the function u(x) = sin(2Ï€x). It has a moderate L2 norm. The function v(x) = sin(20Ï€x) has the same L2 norm, but is much "wiggier," so its derivative is larger, and hence its W1,2 norm is much larger. The parameter k determines how many derivatives you are including in the "wigginess" measure. The parameter p determines the type of averaging. For p=2, we have the Hilbert space Hk=Wk,2, which is particularly important:  The norm is defined by the sum of functions on a domain with integral of the |D^a u(x)| p dx 1/p, so k is for the maximum partial derivative, p is the exponent of the norm root, Roughly speaking, if a function has amplitude A, is supported on a set of volume ð‘‰, and has frequency N, then the W^k,p norm is going to be about A N^k V^(1/p). */
/* Sobolev norm, consider the Laplace operator del on a bounded domain. The domain of del as an unbounded operator on L2 is not L2 itself but a dense subspace of L2. The Sobolev space H2 is the most natural domain for the Laplacian. An eigenfunction of the Laplacian, u(x), satisfies del u = eu. The Sobolev norm ||u||_H2â€‹ is proportional to the eigenvalue, e. For example, for a vibrating drumhead, the fundamental mode of vibration (the eigenfunction with the smallest eigenvalue) is smooth and has a small H2 norm. Higher-frequency modes, which have more "wiggles" and oscillations, have larger eigenvalues and therefore larger H2 norms. The Sobolev norm precisely quantifies this relationship between "wigginess" and eigenvalue:  In the Spectral Theory of Operators, the Hilbert space H^k(omega) (where p=2) is the natural domain for studying differential operators, such as the Laplacian. The Sobolev norm provides a way to define the domain of an operator and to analyze its spectral properties. The operator's action is bounded from a Sobolev space to a simpler space. */
/* Sobolev norm, fractal, like the Sierpinski gasket. It is a set with a non-integer dimension and has no traditional derivatives. However, we can define a notion of a "weak gradient" and a measure on it. The Sobolev norm on the Sierpinski gasket would measure the "energy" of a function on the gasket. A function that is "smooth" or "well-behaved" on the gasket would have a small Sobolev norm, while a function that is "bumpy" or "singular" would have a large Sobolev norm. The Sobolev norm is a way of extending calculus to these non-classical geometric objects:  In Measure Theory, Sobolev spaces can be defined on metric measure spaces, not just on Euclidean space. This extends the concept of "differentiability" to more general settings, such as fractals or graphs. The Sobolev norm is then defined using a suitable notion of a weak gradient and an underlying measure. */
/* Sobolev norm, Imagine a stock price over time, represented as a random path. The L2 norm measures the overall deviation from a mean value. The Sobolev norm of order k=1 (recall that k is the max order of the partial derivative), however, measures the "jerkiness" of the path. The path of a random walk is very "jerky" and has an infinite Sobolev norm because its derivative is infinite at every point. The Sobolev norm provides a way to quantify this roughness:  In Probability Theory, Sobolev norms are used to study the regularity of paths of stochastic processes. For example, the paths of a Wiener process (Brownian motion) are almost surely continuous but nowhere differentiable. While the classical derivative doesn't exist, a notion of a Sobolev space can be defined, and the Sobolev norm can be used to analyze the "roughness" of the paths. */
/* Sobolev norm, The Dirac delta function, Î´(x), is a highly singular distribution that is zero everywhere except at x=0, where it is "infinite." Its derivative is also a distribution. We can't talk about its classical differentiability, but we can talk about its Sobolev norm. The Sobolev norm of the delta function is infinite because it represents an infinite "concentration" of a singularity at a single point. In contrast, a smooth Gaussian function has a finite Sobolev norm because it is a "spread out" singularity. The Sobolev norm provides a way to quantify the degree of singularity of a distribution:  In Distribution Theory, the Sobolev space W^(k,p) can be defined as the set of distributions whose derivatives (in the sense of distributions) are functions in Lp. The Sobolev norm is then defined on these distributions. This allows us to talk about the "smoothness" of objects that are not functions, like the Dirac delta function. */
/* Sobolev norm, a function that is smooth everywhere except for a sharp crease along a line. The Sobolev wave front set would be a "line" in the cotangent bundle that "points" in the direction of the crease. The Sobolev norm of the function would be infinite, but the wave front set would tell us precisely where the singularity is and what "type" it is. A different type of singularity, like a single point, would have a different wave front set. The Sobolev norm is the "metric" we use to identify these singularities:  In Microlocal Analysis, the Sobolev norm is a fundamental tool for defining the Sobolev wave front set, which describes the "singularities" of a function in both position and frequency. The wave front set of a distribution u is a subset of the cotangent bundle Tâˆ—R^n, which describes the points and directions where u is not smooth. */
/* Sobolev norm, imagine the surface of a sphere. We can define Sobolev spaces of functions on the sphere. The Sobolev norm of a function on the sphere would measure its "smoothness" or "wrinkliness." A function that is constant on the sphere has a small Sobolev norm. A function that has many "peaks" and "valleys," like the surface of a golf ball, would have a large Sobolev norm. The Sobolev norm provides a way to quantify the geometric complexity of a function on a curved surface:  In Global Analysis, Sobolev spaces are defined on manifolds, not just on Euclidean space. This allows us to study the regularity of functions and sections of vector bundles on curved spaces, which is crucial for the study of geometry and general relativity. The Sobolev norm is defined using local charts and partitions of unity. */
/* Sobolev norm, thin vibrating membrane with a concentrated force acting at a single point. The displacement of the membrane, u(x,y), would not be a classical solution to the wave equation because its derivative would be infinite at the point of the force. However, it would be a weak solution in a Sobolev space. The Sobolev norm measures the "energy" of the membrane's displacement, which includes the energy of the "infinite derivative" at the point of force. This allows us to find a "generalized" solution that accurately describes the physical system:  In the study of Partial Differential Equations (PDEs), Sobolev spaces provide the natural setting for defining and studying weak solutions. A weak solution to a PDE is a function in a Sobolev space that satisfies the PDE in a generalized sense, often by integration by parts. */
/* Sobolev norm, a problem where we want to find a function that minimizes an "energy" functional. We can start with a sequence of functions whose energy is getting closer and closer to the minimum value. Since the Sobolev space is complete, we are guaranteed that this sequence converges to a function that is also in the space and is a minimizer. The Sobolev norm provides the "ruler" we use to measure the distance between functions, and its completeness ensures that there are no "holes" in the space:  In Nonlinear Functional Analysis, the Sobolev space W^{k,p} is a complete normed vector space (a Banach space), which is crucial for proving the existence of solutions to nonlinear problems. The direct method of the calculus of variations relies on the fact that a minimizing sequence has a convergent subsequence, and this requires the space to be complete. */
/* Sobolev norm, imagine a blob of ink diffusing in a glass of water. The concentration of the ink is described by the heat equation. The initial concentration can be very "spiky" or non-smooth, but over time, it will become very smooth as it diffuses. The Sobolev norm of the concentration function will decrease over time, reflecting this smoothing process. The Sobolev norm is a "smoothness metric" that decreases as the system evolves:  In Semigroup Theory, Sobolev spaces are used to study the well-posedness and regularity of solutions to evolution equations, such as the heat equation. The solution to the heat equation can be described by a semigroup of operators, and the Sobolev norm provides a way to measure the "smoothing effect" of the semigroup. */
/* Sobolev norm, consider the group of rotations in 3D, SO(3), acting on a function on the sphere. The smooth functions on the sphere are the "smooth vectors" in this representation. The Sobolev norm on the sphere measures the "smoothness" of these functions. The action of the Lie algebra (the angular momentum operators) on these functions can be described by their derivatives, which are well-defined on the Sobolev space:  In Representational Theoretic Harmonic Analysis, Sobolev norms are used to define spaces of "smooth vectors" in representations of Lie groups. Smooth vectors are crucial for the study of the action of the Lie algebra on the representation space. The Sobolev norm provides a way to quantify this smoothness. */
/* Sobolev norm, imagine a function that is "smooth" in one direction but "rough" in another. The standard Sobolev norm cannot distinguish between these two directions. However, the HÃ¶rmander spaces, with their additional parameters, can. For example, a function that is smooth along the x-axis but rough along the y-axis would have a small Sobolev norm in the x-direction but a large one in the y-direction. These parameters allow us to "zoom in" on the smoothness in different directions:  In Microlocal Analysis, more general Sobolev spaces, called "HÃ¶rmander spaces," are used to study the regularity of solutions to a wider range of PDEs. These spaces are defined using additional parameters a and r, which allow for a more precise analysis of the smoothness of a function. */
/* Sobolev norm, uncertainty principle, Sobolev norms are trying to measure a combination of three aspects of a function: height (amplitude), width (measure of the support), and frequency (inverse wavelength). Roughly speaking, if a function has amplitude ð´, is supported on a set of volume ð‘‰, and has frequency ð‘, then the ð‘Š^{ð‘˜,ð‘} norm is going to be about ð´ð‘^{ð‘˜}ð‘‰^{1/ð‘}. The uncertainty principle tells us that if a function has frequency ð‘, then it must be spread out on at least a ball of radius comparable to the wavelength 1/ð‘, and so its support must have measure at least 1/ð‘^ð‘‘ or so: ð‘‰ more than or equal to 1/ð‘^ð‘‘:  This relation already encodes most of the content of the Sobolev embedding theorem, except for endpoints. It is also consistent with dimensional analysis, of course, which is another way to derive the conditions of the embedding theorem. */
/* Sobolev space, one can classify the integrability and regularity of a function space norm by testing that norm against a bump function of amplitude ð´ on a ball of volume ð‘‰, modulated by a frequency of magnitude ð‘. Typically the norm will be of the form ð´ð‘ð‘˜ð‘‰1/ð‘ for some exponents ð‘, ð‘˜ (at least in the high frequency regime ð‘‰â‰³1/ð‘^ð‘‘). One can then plot these exponents 1/ð‘, ð‘˜ on a two-dimensional diagram as mentioned by Jitse to get a crude "map" of various function spaces (e.g. Sobolev, Besov, Triebel-Lizorkin, Hardy, Lipschitz, Holder, Lebesgue, BMO, Morrey, ...) The relationship ð‘‰ â‰³ 1/ð‘^ð‘‘ lets one trade in regularity for integrability (with an exchange rate determined by the ambient dimension - integrability becomes more expensive in high dimensions), but not vice versa:  Classification */
/* Sobolev space, For an operator like the Laplacian, its domain is not the set of all functions, but a subspace where the operator is "well-behaved." The Sobolev space is precisely this subspace. The eigenfunctions of the Laplacian (e.g., sine waves on an interval) are in a Sobolev space. The space is a "safe ground" where the operator can act without causing a function to blow up:  Sobolev spaces are the domains of unbounded operators, like the Laplacian. */
/* Sobolev space, function in a Sobolev space has a "measure-like" derivative. For a function with a jump, its classical derivative is infinite.Its weak derivative is a Dirac delta measure, which is not a function. But in a Sobolev space, the weak derivative is a function, not a measure. The space is a subset of the functions whose "measure-like" derivative is nice enough to be a function: A function in a Sobolev space has a distributional derivative that is a function in an L^p space. */
/* Sobolev space, In stochastic analysis, we deal with random functions, like a random walk. The Malliavin derivative, a form of weak derivative, is used to study the properties of these random functions. Sobolev spaces are the spaces where these derivatives live. This provides a rigorous way to define and study "smoothness" for random functions:  Sobolev spaces are used in the analysis of stochastic processes, especially in Malliavin calculus. */
/* Sobolev space, distribution is a generalized function. A Sobolev space is the set of all distributions whose weak derivatives are also functions. This gives us a hierarchy of spaces, from the space of all distributions to the space of smooth functions, with Sobolev spaces in between:  Sobolev spaces are the spaces of distributions that are functions. */
/* Sobolev space, regularity of a function can be measured by its Sobolev norm. A higher Sobolev norm means a smoother function. Microlocal analysis studies the "local smoothness" of a function at different points and in different directions. Sobolev spaces provide a way to quantify this smoothness and understand how it changes:  Sobolev spaces are a natural setting for studying the regularity of solutions to PDEs. */
/* Sobolev space, Sobolev norm of a function is related to the decay of its Fourier transform. A function is in a Sobolev space W^{k,p} if its Fourier transform decays fast enough. This is a way of seeing that a smooth function in the time domain corresponds to a rapidly decaying function in the frequency domain:  Sobolev spaces are related to the decay of the Fourier transform. */
/* Sobolev space, Banach space is a complete normed vector space. The Sobolev space is a Banach space, which means that any Cauchy sequence of functions in the space converges to a function that is also in the space. This makes it a "good" space to do analysis, as it doesn't have "holes" in it:  Sobolev spaces are a primary example of a Banach space. */
/* Sobolev space, optimal control, you are trying to find a control function that minimizes a cost functional. The control function and the state of the system are often in a Sobolev space. This provides a way to ensure that the control function is "well-behaved" and the system's state is "smooth enough.":  Sobolev spaces are the natural setting for optimal control problems. */
/* Sobolev embedding, W(1,1) p = 1, k = 1 is in L^\infty(R), first derivative, so the norm is the actual value, therefore this is the fundamental theorem of calculus:  Fundamental theorem of calculus */
/* Sobolev embedding, W(d,1) p = 1, k = d is in L^\infty(R^d), d-th derivative, p = 1 so the norm is the actual value, therefore this is the iterated fundamental theorem of calculus + Fubini:  Therefore this is the iterated fundamental theorem of calculus + Fubini. */
/* Sobolev embedding, W(0, p) (R^d), k is the 0th derivative, so not derivative, this gives L^p(R^d), this is trivial:  Trivial case */
/* Regularity in Sobolev norms,  of functions, like a landscape with hills and valleys. The Lp norm measures the "flatness" or overall size of the function; for example, a function with a small L2 norm is generally "low" or close to zero. The Sobolev norm, however, also accounts for the "smoothness" or "steepness" of the landscape. A function with a high Sobolev norm is not only "large" but also has "steep" slopes (large derivatives) up to a certain order. The Sobolev embedding theorems are like a rule that says if your landscape is "smooth enough" and "steep enough" in a certain way, then it must also have a specific property, like being "bounded" or continuous, which is a stronger property. For example, the Sobolev embedding theorem W1,2(R) into L^\infty(R) for 1D functions says that if a function and its derivative have finite L2 norms, then the function must be bounded. This is visualized as a function with finite "energy" (from the L2 norm of the derivative) being constrained from "blowing up" to infinity:  Regularity in the context of Sobolev embedding and norms refers to the property of a function having a certain number of weak derivatives that are also in a given Lp space. The Sobolev norm ||f||_Wk,p(Î©)â€‹ quantifies this regularity by combining the Lp norm of the function itself with the Lp norms of its weak derivatives up to order k. Sobolev embedding theorems establish conditions under which a function with high regularity (i.e., a high Sobolev norm) can be guaranteed to have better properties, such as being continuous or belonging to a different Lq space, providing a link between differentiability and continuity. */
/* Regularity, random walk on a graph. The walk's path is a sequence of points. If the walk is a simple one, it just jumps from one point to another, and its path is "jagged" and discontinuous. A more "regular" process, like a Brownian motion, can be thought of as a continuous random path. While it's continuous, it's also highly "wrinkled" and "fractal," with infinite wiggles at any point. This corresponds to its non-differentiability. The regularity of this path (i.e., its continuity) is a guaranteed property of the process, even though its "smoothness" in the classical sense is low. The norm here might be related to the maximum displacement or the variation of the path over time, which quantifies its "size" or "jaggedness" in a probabilistic sense. For example, the quadratic variation of a Brownian motion is deterministic (t), which tells us something about the process's overall regularity, even though the sample paths are not smooth:  In probability theory, especially for stochastic processes, regularity can be understood as the smoothness of sample paths. A stochastic process is a collection of random variables indexed by time. The regularity of the process refers to the properties of its realizations, or sample paths, as functions of time. For example, a Brownian motion has continuous but nowhere-differentiable sample paths, while other processes might have smoother paths. */
/* Regularity, imagine the graph of a function as a surface, and a PDE as a set of physical constraints on that surface. For example, the Laplace equation Î”u=0 says that the surface has no local maxima or minima and that it is "harmonic" or "smooth." A weak solution to the Laplace equation might be a surface that's "close" to being smooth but could have sharp corners or edges.  Elliptic regularity theory for the Laplace equation states that if a function satisfies the equation in a weak sense and has a certain level of smoothness, then it must be infinitely differentiable. This is like a principle that says the physical law of a "harmonic surface" is so strong that it forces any function that satisfies it to be perfectly smooth. The Sobolev embedding theorem here is a tool that helps to translate the "weak smoothness" from the equation into "strong smoothness" of the solution:  In the context of partial differential equations (PDEs), regularity refers to the smoothness of a solution. A solution to a PDE is a function that satisfies the equation. The regularity of this solution is measured by how many continuous derivatives it has. A weak solution might only be in a Sobolev space and not have classical derivatives, but a regularity theory for a PDE provides conditions under which a weak solution is also a classical (smooth) solution. This is a crucial concept, as it allows us to prove that solutions we find in a weak sense are actually "well-behaved" enough to be physically meaningful. */
/* Regularity, Laplacian operator Î” on a domain Î©. The eigenfunctions of the Laplacian, unâ€‹, satisfying âˆ’Î”unâ€‹=Î»nâ€‹unâ€‹, are often sine and cosine functions or Bessel functions, which are very smooth. The regularity of these eigenfunctions is a natural property. The spectral theorem states that any function in the domain can be decomposed into a sum of these eigenfunctions. For example, a "rough" or "jagged" function on a disk can be represented as a weighted sum of smooth Bessel functions. The Sobolev norm measures how many of these smooth eigenfunctions are needed to approximate the function. A function with high regularity (high Sobolev norm) is a sum of only a few smooth eigenfunctions, while a low-regularity function requires a sum of many high-frequency eigenfunctions (which correspond to higher eigenvalues) to approximate it:  In the spectral theory of operators, regularity can be viewed as the smoothness of functions in the domain of an operator. An operator A:D(A)â†’H maps elements from a domain D(A) to a Hilbert space H. The regularity of the functions in the domain is related to the operator itself. For example, a differential operator like dxdâ€‹ acts on functions, and its domain is often a Sobolev space, where functions have a certain degree of regularity. The spectral theorem for a self-adjoint operator, for instance, decomposes the Hilbert space into a sum of eigenspaces, with each eigenvector having a certain regularity. */
/* Regularity, Consider a nonlinear map F:Xâ†’Y between Banach spaces. We can visualize this as a "stretching and bending" of the space X. The FrÃ©chet derivative at a point is a linear approximation of this map, like a tangent plane to the curved surface. If this linear approximation is non-degenerate (i.e., an invertible map), then the nonlinear map locally behaves like a linear map. The regularity of the map, such as its continuous differentiability, ensures that this local linear approximation exists and varies smoothly from point to point. Sobolev embedding theorems are used here to show that a solution to a nonlinear PDE, which is a fixed point of some nonlinear operator, has a certain regularity. For example, if we have a nonlinear equation that we know has a weak solution, we might use a Sobolev embedding to show that the solution is continuous, which then allows us to apply more powerful tools from calculus:  In nonlinear functional analysis, regularity is concerned with the smoothness of solutions to nonlinear equations or the properties of nonlinear operators. A key concept is the inverse function theorem for Banach spaces, which states that if a nonlinear operator is "well-behaved" (i.e., its FrÃ©chet derivative is a bounded linear isomorphism), then it has a local inverse, and the inverse is also smooth. Regularity is thus a property that allows us to transfer smoothness from one space to another. */
/* Regularity, a distribution can be visualized as a "linear machine" that takes a smooth function and outputs a number. A regular distribution is a machine that does this by simply integrating the smooth function against a "nice" function. For example, the Dirac delta distribution, Î´, is an irregular distribution. It doesn't correspond to any function, but it acts on a test function by just picking out its value at zero: âŸ¨Î´,Ï•âŸ©=Ï•(0). Sobolev embedding theorems say that if a distribution and its weak derivatives are "close enough" to be regular functions in a certain sense (i.e., they are in an Lp space), then the distribution itself must also be a regular function with better properties, like being continuous. This is a powerful result that provides a bridge between the abstract world of distributions and the concrete world of classical functions:  In distribution theory, a regularity can be interpreted as the property of a distribution being a function. A distributionis a generalized function that acts on test functions (infinitely smooth functions with compact support). A distribution is said to be regular if it can be represented by a locally integrable function. The Sobolev spaces are spaces of distributions that have "weak derivatives" that are also distributions. */
/* Regularity, process of heat diffusion on a metal rod. The temperature distribution at time t is the result of a semigroup acting on the initial temperature profile. Even if the initial temperature profile is "jagged" (e.g., a discontinuous function), the heat equation is so "smoothing" that the temperature profile becomes infinitely differentiable for any time t>0. This is the regularizing effect of the semigroup. The Sobolev norm here can measure the smoothness of the temperature profile at any given time. The regularity theory for the heat equation says that even if the initial state u_0â€‹ is only in L^2, the solution u(t) will be in C\infty for any t>0. The Sobolev embedding theorem is the tool that tells us that once the solution is in a high-enough Sobolev space (which it is for any t>0), it must be continuous and even infinitely differentiable:  Semigroup theory studies families of operators that describe the evolution of a system over time. A regularity propertyof a semigroup, {T(t)}_t nonnegativityâ€‹, refers to the smoothness of the solution u(t)=T(t) u_0â€‹ as a function of time, for an initial condition u_0â€‹. A key concept is the analytic semigroup, where the solution not only is continuous in time but also can be extended to an analytic function in a sector of the complex plane. This implies that the solution is infinitely differentiable with respect to time for t>0. */
/* Regularity, very jagged function. We can "smooth it out" by taking a weighted average of its values in a small neighborhood. This is exactly what convolution with a mollifier does. The resulting function is smooth, even though the original one wasn't. The Sobolev norm measures how "close" a function is to a smooth function. A function in a high Sobolev space is "close" to a smooth function, and the Sobolev embedding theorem says that this "closeness" implies a better property, like continuity. For example, a function in W1,2 can be approximated by a sequence of smooth functions, and the embedding theorem tells us that the limit of this sequence must be a continuous function:  Regularity can be seen as the result of a smoothing process. For example, convolution with a smooth function (like a Gaussian kernel) can turn a "rough" function into a "smooth" one. The mollifier is a family of smooth functions with compact support that can be used to approximate any function in an L^p space with a sequence of smooth functions. The regularity of the function is then the property that it can be approximated by smooth functions in some sense. */