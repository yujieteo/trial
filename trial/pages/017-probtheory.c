/* Asymptotic equipartition theorem, linking Kolmogorov complexity to storytelling:  the story with the minimum Kolmogorov complexity compared to the entropy of typical stories will be written in an atypical way and appeal to humanity (minimum model length in humans as a approximation of a Turing machine). So, write weird stories that appeal to humanity. */
/* Lossy compression, themes and handwaving:  an analysis of a media piece will definitely have very lossy compression and need not faithfully capture all aspects of the work. Unless one can show that it is the completion of all analyses with all possible probes / morphisms, an analysis cannot be a faithful representation of the work, especially since the scope of human nature is large */
/* Cross entropy reduction, definition of intelligence:  reduce the entropy directly to the Kolmogorov complexity. */
/* 1D Ising Model, magnetisation model used to illustrate either the metropolis cutoff or Glauber dynamics:  idea is to have (-1,1)^N for magnetisation spin, decompose Hamiltonian into two components. Metropolis cutoff considers the minimum of (1, exp(- B H(x))), where B is the inverse temperature and cool to infinity. */
/* Carathedory extension theorem, to measure a "nasty" set A, you "cover" it with simple, measurable shapes (like intervals). You add up their measures. You do this for all possible covers and take the smallest sum. This gives you the "outer measure" of A. Then, to define a "good" set, you demand that it "splits" any other set into two pieces such that the outer measure of the whole is the sum of the outer measures of the parts. This property is like a perfect, clean cut. It's a fundamental criterion for a set to be "measurable.":  the key step in the proof is the construction of an outer measure m. For any set A, m(A) is defined as the infimum of the sums of the pre-measures of all countable covers of A by sets from the semi-ring. A set E is then considered "measurable" if for any set A, m(A)= m(A intersect E)+ m(A intersect E_c). The measure M is the restriction of mto these measurable sets. */
/* Fubini's theorem, Imagine a three-dimensional solid object with a variable density given by the function f(x,y). The double integral represents the total mass of the object. Fubini's theorem says you can calculate this total mass in two different ways: by slicing the object into thin slabs parallel to the yz-plane, finding the mass of each slab (the inner integral), and then summing up the masses of all the slabs (the outer integral); or by slicing the object into slabs parallel to the xz-plane. For a function like f(x,y)= x^2 y on the unit square [0,1]×[0,1], you can compute the volume by integrating with respect to y first, and then x, or vice versa, and the answer will be the same:   */
/* Fubini's theorem, prob. surface over the xy-plane. The total volume under this surface must be 1. To find the probability distribution of just X, you "squash" the entire landscape onto the x-axis by summing up the probability density at each point on the x-axis for all possible y values. Fubini's theorem guarantees that this "squashing" process is well-defined and that the total volume of 1 can be found by either squashing onto the x-axis first, or onto the y-axis first:   */
/* Radon-Nikodym, a joint probability distribution over two variables, X and Y. The Radon-Nikodym theorem allows us to "slice" this distribution at a specific value of Y=y. The probability distribution along this slice is then a new, conditional probability distribution on X. The Radon-Nikodym derivative is the density of this new distribution, and it is precisely the conditional probability density function:  The theorem provides the rigorous foundation for the existence of conditional probability density functions and conditional expectation. For two random variables X and Y, the conditional expectation E[X | Y=y] is a function of y that can be formally defined using the Radon-Nikodym derivative of a measure with respect to a marginal measure. */
/* Radon-Nikodym, measure as a function and a function as a measure. The theorem provides a precise way to go back and forth between these two concepts. It's a powerful tool for bridging the gap between abstract measure theory and more concrete functional spaces:  The theorem establishes a duality between measures and functions. The space of all absolutely continuous measures with respect to a given measure is isomorphic to the space of all integrable functions with respect to that measure. */
/* Radon-Nikodym, contrast it with Riesz theorem tells us that a "probe" (functional) on a space of continuous functions can be thought of as an integral. The Radon-Nikodym theorem adds to this by saying that if the measure is "nice" (absolutely continuous), we can replace the measure with a simple weighting function:  The Riesz representation theorem states that every continuous linear functional on a space of continuous functions can be represented as an integral with respect to a measure. The Radon-Nikodym theorem connects these measures to functions. */
/* Radon-Nikodym, weak derivative is a very general concept. The theorem provides a way to show that if this weak derivative is "well-behaved" (e.g., it is a function in L1), then it must coincide with the classical derivative wherever the function is differentiable:  In the theory of Sobolev spaces, the weak derivative is defined as a distribution. The Radon-Nikodym theorem can be used to show that if a function's weak derivative is a regular function, then the weak derivative is also the classical derivative almost everywhere. */
/* Lebesgue decomposition, Lebesgue decomposition is like separating a complex object into two parts: a "smooth" part that can be described by a density function (the absolutely continuous part) and a "bumpy" part that cannot (the singular part). The Radon-Nikodym theorem is about understanding only the smooth part:  The Lebesgue decomposition theorem states that any measure can be decomposed into two parts: a part that is absolutely continuous with respect to another measure and a part that is singular. The Radon-Nikodym theorem only deals with the absolutely continuous part. */
/* Radon-Nikodym, μ as a standard way of measuring "mass" or "volume," like a standard ruler. The measure ν is a different way of measuring, but it never gives a non-zero mass to a set that has zero mass under the standard ruler. For example, if μ is the standard length measure on the real line, ν might be a measure where points at the origin are "heavier" and have a higher density. The Radon-Nikodym derivative f is a density function that tells you how much "denser" the measure ν is compared to μ at each point. It's the "scaling factor" at every location:  Let (X,M) be a measurable space and μ,ν be two σ-finite measures on it. If ν is absolutely continuous with respect to μ(i.e., ν(A)=0 for any set A where μ(A)=0), then there exists a measurable function f:X→[0,∞) such that ν(A)=∫A​fdμ for every measurable set A. The function f is called the Radon-Nikodym derivative of ν with respect to μ, denoted f=dν/dμ. */
/* Radon-Nikodym derivative, "difference" between the two distributions. The KL divergence is a way of "averaging" this difference to get a single number:  In information theory, the Kullback-Leibler divergence is a measure of how one probability distribution is different from a second, reference distribution. It is defined as an integral with respect to the reference distribution, and the integrand is the logarithm of the Radon-Nikodym derivative. */
/* Radon-Nikdoym, convex body with a variable density. The Radon-Nikodym theorem provides the density function, which allows us to find the precise center of mass:  The theorem can be used to define a notion of "center of mass" for a measure. The center of mass is a point that is the average of the coordinates, weighted by the Radon-Nikodym derivative. */
/* Martingales, a point moving on a 2D grid. At each step, the point moves to a new position, but the expected position in the future, given its current location, is exactly where it is now. This isn't about the point not moving; it's about the average of its potential next moves balancing out, so there's no overall drift or bias. For example, consider a simple random walk on the integers, where at each step, a particle moves one unit to the right with probability p and one unit to the left with probability 1−p. The position Xn​ at time n is a martingale if and only if p=1/2. If p=1/2, the expected position after the next step is E[Xn+1​∣Xn​]=Xn​+(1/2)(1)+(1/2)(−1)=Xn: A martingale is a sequence of random variables Xn​ adapted to a filtration Fn​ such that for all n, the conditional expectation of the next value Xn+1​ given all past information Fn​ is simply the current value Xn​. In simpler terms, E[Xn+1​∣Fn​]=Xn​. */
/* Martingales, heat distribution on a plate that is also being randomly "kicked" at every point. The "kicking" part is the white noise. The solution at any point (x,t) is a random variable. The solution at a point can be seen as a martingale in time if the underlying noise term is integrated in a specific way. For example, the stochastic integral from 0 to t of ​Φ(s) dWs​ for an appropriate process Φ(s) is a martingale Ws is Wiener process. This integral can be visualized as a random walk in an infinite-dimensional space, where the "steps" are continuously being taken according to the Wiener process. The expected displacement from the origin at any time is zero: A martingale is a component of the solution to a stochastic partial differential equation (SPDE). For example, the solution to a stochastic heat equation ut​=Δu+W˙ (where W˙ is space-time white noise) can be expressed in terms of a stochastic integral, which is a martingale. */
/* Measure convexity, measure as a way to assign "size" to a set, like area. The area of two non-overlapping regions added together is the same as the area of their union. If they overlap, the area of their union is less. This subadditivity is a fundamental property of measures: A measure m is convex if for any two measurable sets A and B, m(A union B) less than or equal to m(A)+ m(B). This is subadditivity. The convexity of measures is related to the property that the "size" of the union of two sets is no more than the sum of their sizes. */
/* Convexity, graph of a convex function looks like a bowl. Minimizing the function means finding the bottom of the bowl. Because the bowl has a single bottom, there is only one minimum, and it can be found easily. This is not true for a non-convex function, which can have many local minima. Convexity guarantees that any local minimum is also a global minimum, making the problem tractable: A problem is a convex programming problem if it is the minimization of a convex function over a convex set. */
/* Convexity, polar is a way of "dualizing" a convex set. Imagine a convex set. Its polar is another convex set that can be thought of as a "dual" or "inverse" of the original. For a circle, its polar is another circle. For a square, its polar is a diamond. The polar operation is a geometric transformation that preserves convexity:  The polar of a convex set is another convex set. The polar of a set C is the set of all vectors y such that inner product of all x,y <= 1 for all x in C. */
/* Convexity, non-convex function, for example, a sine wave. The convex envelope is the function that is obtained by "stretching a rubber band" under the graph. The resulting function is convex. It is a way to "convexify" a non-convex function, which is useful in optimization:  The convex envelope of a function is the largest convex function that is less than or equal to the original function. It is the "tightest" convex function that "fits under" the given function. */
/* Convexity, circle and a line segment. Their Minkowski sum is a shape that can be traced by "sliding" the line segment around the circle. The resulting shape is a stadium-like shape, which is also convex. The convexity is preserved under this operation:  The Minkowski sum of two convex sets is another convex set. The Minkowski sum of two sets A and B is the set of all sums a+b where a in A and b in B. */
/* Convexity, function whose graph is a bowl. The highest point of the bowl must be on its rim, not in the interior. This is a very powerful property that relates the value of a function in the interior of a domain to its values on the boundary: A function is convex if it satisfies the maximum principle for elliptic operators. For example, for a convex function u with Laplacian of u is nonnegative, its maximum value is attained on the boundary of the domain. */
/* Convexity, Krein-Milman theorem says that a compact, convex set is "built" from its extreme points. The extreme points are the points that cannot be expressed as a convex combination of two other points in the set. For a solid cube, the extreme points are its 8 vertices. The entire cube is the convex hull of these 8 vertices. The theorem guarantees that for any compact, convex set, such a finite or infinite set of "building blocks" exists: A compact convex set in a locally convex topological vector space is the convex hull of its extreme points. *//* Weak law of large numbers, a dartboard with a bullseye. Each dart throw is a random variable. The WLLN states that if you throw enough darts, the average position of your throws will be very close to the bullseye, which is the expected value of the throws. The throws can be scattered, but their average position will be concentrated near the bullseye:  Sample mean converges to probability in measure for sequence of iid random varaibles with bounded mean. */
/* Convexity, convex set is a "blob" without any dents or indentations. Imagine a 2D set. If you pick any two points inside it, you can "walk" a straight line between them without leaving the set. For a square, any straight line between two points on the boundary or interior stays inside the square. A crescent shape, however, is not convex because a straight line between two points in the "horns" would leave the shape. This is the most fundamental and intuitive definition: A set is convex in R^n if for any two points in the set, the line segment connecting them is contained entirely withn C, formally for parameters in the unit interval, convex combinations are closed within C. */
/* Convex functions, convex function is a function whose graph "cups upwards." Any straight line segment connecting two points on the graph of the function must lie on or above the graph. For the function f(x)=x2, the parabola "cups upwards." If you draw a line from (1,1) to (2,4), the line lies above the parabola. A function like f(x)=sin(x) is not convex on a large interval because it oscillates, and a line segment can pass below its graph. The visual intuition is that a convex function has a unique minimum, making it easy to optimize: A function f: R^n→R is convex if for any two points x,y in its domain and any p in [0,1], the function value at the weighted average of the points is less than or equal to the weighted average of the function values. Formally, f(px+(1−p)y) is less than or equal to pf(x)+(1−p)f(y). */
/* Convexity, a random variable X as a set of points on the x-axis, each with a certain probability. The expected value E[X] is the weighted average of these points. Jensen's inequality says that the average of the function's values at these points is greater than or equal to the function's value at the average point. For the function f(x)=x^2, the variance formula E[X^2]≥(E[X])^2 is a direct result of this. This visually means that the "spread" of the random variable increases the average value of the convex function: a function f is convex if for any random variable X, the expected value of the function of the random variable is greater than or equal to the function of the expected value of the random variable. Formally, E[f(X)] is more hthan or equal to f(E[X]). */
/* Convexity, convex polygon in R^2. The set of its vertices are the extreme points. Any point inside the polygon can be written as a convex combination of its vertices. This means we can "build" the entire convex set by taking weighted averages of its extreme points. This is not true for a non-convex set. For a square, the vertices are the extreme points. A point (1/2,1/2) can be written as (1/4,1/4,1/4,1/4) times the vertices: A set is convex if it is a "convex combination" of its extreme points. A convex set can be uniquely characterized by its extreme points. */
/* Convexity, "local" part refers to the fact that we can zoom in around any point and find a small, convex neighborhood. This is a crucial property for doing analysis in these spaces. The space itself isn't necessarily convex, but it can be "approximated" by convex sets. Imagine a space where every point has a small, convex "bubble" around it. The space of all continuous functions on [0,1] with the topology of uniform convergence is locally convex: A topological vector space is locally convex if its topology is defined by a family of seminorms. A seminorm is a function that is similar to a norm but can be zero for non-zero vectors. The topology is generated by a basis of convex sets, namely the open balls defined by the seminorms. */
/* Convexity, geometric realisation as a polyhedron, half-space is a region of space on one side of a hyperplane (a line in 2D, a plane in 3D). A convex polyhedron is the shape you get by taking the intersection of many such half-spaces. For a cube, it is the intersection of 6 half-spaces, defined by the planes of its faces. This shows that a convex set can be defined by its "boundaries.": A polyhedron is the intersection of a finite number of half-spaces. A bounded polyhedron is a polytope. This definition is a dual perspective to the one using extreme points */
/* Weak law of large numbers, study of random matrices, the WLLN is used to show that the empirical spectral distribution of a large random matrix converges to a deterministic distribution. This is a way of saying that the average of the eigenvalues of a large random matrix is well-behaved and predictable:   */
/* Weak law of large numbers, probability distribution of the sample mean Xˉn​ is a measure. The WLLN states that as n tends to infinity, this measure becomes more and more concentrated at the point m, effectively converging to a Dirac delta measure at m:   */
/* Weak law of large numbers, information theory, the entropy of a sequence of random variables is their average information content. The WLLN guarantees that the average information content converges to the true entropy:  The WLLN is used to analyze the average behavior of a sequence of random variables. */
/* Weak law of large numbers, the macroscopic properties of a system (e.g., temperature) are the average of the microscopic properties of the particles. The WLLN guarantees that these averages are well-defined and predictable:  The WLLN is a fundamental principle of statistical mechanics. */
/* Strong law of large numbers, an infinite sequence of coin flips. The SLLN states that the proportion of heads will eventually settle down and become exactly 0.5. Although any finite sequence may not have exactly 50% heads, as the number of flips goes to infinity, the proportion almost surely approaches the true mean. It is the "long-term certainty" of the average:  For a sequence of i.i.d. random variables X1​,X2​,… with mean E[X1​]=μ bounded, the sample mean ​converges almost surely to the mean */
/* Strong law of large numbers, study of large random matrices (e.g., Wigner matrices), the SLLN guarantees that the distribution of the eigenvalues will almost surely converge to a deterministic distribution (the Wigner semicircle law). It’s a statement about the almost sure regularity of the eigenvalues of a large random matrix:  The SLLN is used to analyze the convergence of the empirical spectral distribution of random matrices. */
/* Strong law of large numbers, sequence of probability distributions of the sample mean converges almost surely to a Dirac delta measure. This means that for a given sequence of random variables, the measure becomes a point mass at the true mean:   */
/* Strong law of large numbers, WLLN says the probability of the average being far from the mean goes to zero. The SLLN says that for any specific sequence of outcomes, the average will almost surely converge to the mean. It's the difference between "likely to be close" and "almost certain to converge.":  The SLLN is a deeper and more profound result than the Weak Law of Large Numbers. */
/* Strong law of large numbers, distribution of the sample mean converges to a Dirac delta distribution at the true mean. The SLLN states that this convergence happens almost surely:  The SLLN is a statement about the almost sure convergence of a sequence of random variables to a constant distribution. */
/* Strong law of large numbers, system with random perturbations, the SLLN can be used to show that the singularities of the solution will almost surely propagate along a deterministic path. It's a way of saying that the random perturbations don't change the overall behavior of the system in the long run:  The SLLN is related to the almost sure propagation of singularities in random systems. */
/* Strong law of large numbers, entropy of a random sequence is its average information content. The SLLN guarantees that the average information content will almost surely converge to the true entropy:  The SLLN is used to analyze the almost sure convergence of the average information content of a random sequence. */
/* Martingales, sequential analysis, you collect data until you have enough evidence to make a decision. The sum of the log-likelihood ratios is a martingale. The martingale property ensures that the test doesn't have a bias:  Martingales are used in sequential analysis and hypothesis testing. */
/* Regret analysis, imagine a company trying to set prices for its products to minimize costs. The company's pricing strategy is the algorithm. The regret is the difference between the total cost incurred by the company and the total cost if they had known the optimal price from the beginning and kept it fixed:  In online convex optimization, regret is the difference between the cumulative cost of the algorithm's decisions and the cost of the best single fixed decision in hindsight. */
/* Maximum entropy, a continuous probability distribution on the interval [0,1] with a given mean. The family of all such distributions is a convex set. The entropy functional is concave. The maximum entropy distribution is the one that corresponds to the point in this convex set where the concavity of the entropy functional is maximized. For example, if the only constraint on a distribution on [0,1] is that its mean is 1/2, the maximum entropy distribution is the uniform distribution, which is a flat line. This line represents the distribution that is "least informative" or "most spread out," making no assumptions about any specific point being more likely than another. ]: The maximum entropy principle in probability theory states that among all probability distributions that satisfy a given set of constraints (e.g., specified means, variances, or other moments), the one with the largest entropy is the most reasonable choice. This is because it makes the fewest assumptions beyond the given constraints. */
/* Maximum entropy principle, space of all possible probability distributions as a landscape, with the altitude at any point representing the entropy of that distribution. The known constraints define a "path" or a "region" in this landscape. The maximum entropy principle tells us to find the highest point on this path. For example, consider the space of all probability distributions on a finite set of outcomes. The maximum entropy distribution (the uniform one) corresponds to the highest point in this landscape, a "flat plateau." Adding a constraint (e.g., specifying the mean) restricts us to a lower-dimensional slice of this landscape, and we then find the highest point on that slice:  From an information theory perspective, the maximum entropy principle is a method for constructing the least-informative probability distribution given some constraints. The entropy of a distribution, H(P), quantifies the uncertainty or information content of a random variable. Maximizing entropy means choosing the distribution that retains the maximum possible uncertainty, given the known information. */
/* Maximum entropy principle, space of all possible probability distributions, the set of distributions satisfying linear constraints forms a convex set. The entropy function defines a "bowl" opening downwards (a concave function). The solution to the maximum entropy problem is the unique point where the bowl's surface touches the "highest" part of the convex constraint set. For example, for a discrete probability distribution, the set of all distributions forms a simplex. The maximum entropy distribution (the uniform one) is the center of this simplex. Constraining the mean is like intersecting the simplex with a hyperplane, and the solution is the point on this new intersection that is closest to the center:  The maximum entropy principle can be formulated as a convex optimization problem. The entropy function is concave, and the constraints (often expectations of certain functions) are typically linear, defining a convex feasible set. Maximizing the concave entropy function over a convex set is a standard convex optimization problem. */
/* Maximum entropy principle, density operator ρ is a positive semidefinite operator with trace 1. Its eigenvalues pi​ form a probability distribution over the system's energy eigenstates. Maximizing the von Neumann entropy S(p) is equivalent to maximizing the Shannon entropy of the eigenvalue distribution. The "least biased" state is the one where the eigenvalues are as "spread out" as possible, which corresponds to the identity operator (or a multiple thereof) if there are no constraints. The identity operator is "maximally mixed" as it assigns equal probability to all eigenstates. Constraining the expectation value of an observable means that we must choose a density operator whose eigenvalues are arranged in a specific way, and we find the arrangement that is most "uniform" while satisfying the constraint:  In quantum mechanics, the state of a system is described by a density operator p. The von Neumann entropy S(p)=−Tr(p log p) is the quantum mechanical analogue of Shannon entropy. The maximum entropy principle states that the density operator describing a system, given some constraints on expectation values of observables, is the one that maximizes the von Neumann entropy. This is a direct application of the principle to a non-commutative setting. */
/* Maximum entropy principle, space of all probability measures on a space like a vast sea. Each point in the sea is a measure. The constraints define a specific "island" in this sea. The maximum entropy principle states that the "most natural" or "least structured" measure is the one at the highest elevation on this island, where elevation is measured by entropy. For example, the maximum entropy measure on R with a fixed variance is the Gaussian measure. A Gaussian distribution visually "spreads out" the probability mass as much as possible while maintaining a fixed amount of dispersion (variance). The entropy of a measure m with respect to a base measure v is defined as H(m ) = - integral log(dm/dv​)dμ:  The maximum entropy principle can be generalized to the space of all probability measures on a given measurable space. Given a class of measures that satisfy certain moment constraints, the principle selects the measure with the maximum entropy. The entropy of a measure m with respect to a base measure v is defined as H(m ) = - integral log(dm/dv​)dμ */
/* Maximum entropy principle, dynamical system on a compact manifold, like a torus. There can be many invariant measures. The maximum entropy principle would select the one that is "most uniform" or "least structured," such as the Haar measure on a Lie group. The Haar measure on a torus is simply the uniform measure. This measure is "as spread out as possible" over the torus, making no preference for any specific region. This "uniformity" is what we would intuitively expect for a system at equilibrium:  In global analysis, the maximum entropy principle can be related to the study of measures on manifolds. For example, in the study of dynamical systems, one is interested in invariant measures. The principle can be used to select a "natural" invariant measure. This is particularly relevant in the context of statistical mechanics on manifolds. */
/* Maximum entropy principle, fluid diffusing in a container. The diffusion process tends to "spread out" the fluid, increasing its "entropy" or "disorder." The maximum entropy principle provides the mathematical framework for this. A solution to a diffusion equation, like the heat equation, describes a probability distribution that evolves from a localized state to a more uniform, high-entropy state over time. The "entropic force" that drives the system to a state of maximum entropy can be seen as the underlying mechanism described by the PDE:  In the context of partial differential equations, the maximum entropy principle can be used to derive certain PDEs. For example, the Fokker-Planck equation, which describes the time evolution of the probability density function of a random process, can be derived by maximizing entropy subject to a certain rate of change constraint. The principle gives a variational framework for understanding the evolution of a probability distribution. */
/* Maximum entropy principle, Wiener process (Brownian motion) is a prime example of a maximum entropy process. It's the "most random" continuous-time process whose increments are independent and normally distributed. The path of a Wiener process is a "random walk" that is "as wiggly as possible" while remaining continuous. The maximum entropy principle can be used to derive this process by finding the path measure that maximizes entropy subject to the constraint that the increments are independent:  The maximum entropy principle is fundamental in stochastic analysis for constructing prior probability distributions for stochastic processes. For example, one can apply the principle to find the probability distribution of a path of a stochastic process, given constraints on its moments or other properties. The maximum entropy path distribution is the one that is "most random" while satisfying the constraints. */
/* Maximum entropy principle, blob of ink dropped into a glass of water. The ink particles are a probability distribution. The time evolution is a semigroup of operators that describes the diffusion of the ink. As time goes on, the ink spreads out and becomes uniform, reaching a state of maximum entropy. The semigroup "pushes" the system towards this state. The maximum entropy state is the fixed point of this semigroup:  The maximum entropy principle can be linked to semigroup theory through the evolution of probability distributions. A semigroup of operators can describe the time evolution of a system. The principle suggests that this evolution should be "entropy-increasing" and should drive the system towards a maximum entropy state (equilibrium). For example, the heat semigroup, generated by the Laplacian operator, "smears out" any initial heat distribution towards a uniform, high-entropy state. */
/* Maximum entropy distribution, a system of gas particles in a box. At equilibrium, the particles are not all moving at the same speed; rather, their speeds are distributed according to the Maxwell-Boltzmann distribution. This distribution is the one that maximizes the "disorder" or entropy of the system while maintaining a fixed total energy. The particles are as "random" as they can be, given the constraint on their average energy. The exponential form of the distribution means that lower-energy states are more probable, but higher-energy states are still possible, which is the most "unbiased" arrangement:  the maximum entropy principle provides a foundation for the Gibbs and Boltzmann distributions. It states that the probability distribution over the microstates of a system in thermal equilibrium is the one that maximizes entropy subject to the constraint of a fixed average energy. This leads directly to the Gibbs distribution P(x) proportional to exp(−bE(x)). */
/* Differential entropy, integral whose kernel is the -log p(X). Note that this is not corect. p(x) fails dimensional analysis. Jaynes fixed this by defining the invariant measure N discrete points lim ([number of points in a < x < b]/N) = integral m(x) over support [a, b], then the differential entropy lim N_\infty H_N(X) = log(N) - integral p(x) log [p(x) / m(x)]:  Entropy, integral whose kernel is the -log p(X). */
